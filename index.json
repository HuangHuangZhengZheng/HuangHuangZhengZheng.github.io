[{"categories":["DATA100"],"content":"Cross Validation ","date":"2024-07-19","objectID":"/datal15/:0:0","tags":null,"title":"DATA100-L15: Cross Validation, Regularization","uri":"/datal15/"},{"categories":["DATA100"],"content":"the holdout method from sklearn.utils import shuffle training_set, dev_set = np.split(shuffle(data), [int(.8*len(data))]) 比较validation error和training error，选择最优的模型。 ","date":"2024-07-19","objectID":"/datal15/:1:0","tags":null,"title":"DATA100-L15: Cross Validation, Regularization","uri":"/datal15/"},{"categories":["DATA100"],"content":"K-fold cross validation K=1 is equivalent to holdout method. ","date":"2024-07-19","objectID":"/datal15/:2:0","tags":null,"title":"DATA100-L15: Cross Validation, Regularization","uri":"/datal15/"},{"categories":["DATA100"],"content":"Test sets provide an unbiased estimate of the model’s performance on new, unseen data. Regularization ","date":"2024-07-19","objectID":"/datal15/:3:0","tags":null,"title":"DATA100-L15: Cross Validation, Regularization","uri":"/datal15/"},{"categories":["DATA100"],"content":"L2 regularization (Ridge) the small the ball, the simpler the model 拉格朗日思想，$\\alpha$ 越大，约束越强，模型越简单。 岭回归 ","date":"2024-07-19","objectID":"/datal15/:4:0","tags":null,"title":"DATA100-L15: Cross Validation, Regularization","uri":"/datal15/"},{"categories":["DATA100"],"content":"scaling data for regularization 标准化数据，be on the same scale ","date":"2024-07-19","objectID":"/datal15/:5:0","tags":null,"title":"DATA100-L15: Cross Validation, Regularization","uri":"/datal15/"},{"categories":["DATA100"],"content":"L1 regularization (Lasso) ","date":"2024-07-19","objectID":"/datal15/:6:0","tags":null,"title":"DATA100-L15: Cross Validation, Regularization","uri":"/datal15/"},{"categories":["DATA100"],"content":"summary ","date":"2024-07-19","objectID":"/datal15/:6:1","tags":null,"title":"DATA100-L15: Cross Validation, Regularization","uri":"/datal15/"},{"categories":["DATA100"],"content":" $\\downarrow{shuffle}$ SGD: Stochastic Gradient Descent(but size == 1) ","date":"2024-07-19","objectID":"/datal13/:0:0","tags":null,"title":"DATA100-L13: Gradient Descent, Feature Engineering","uri":"/datal13/"},{"categories":["DATA100"],"content":"convexity (凹凸性) feature engineering 在于怎么使用transforming ","date":"2024-07-19","objectID":"/datal13/:1:0","tags":null,"title":"DATA100-L13: Gradient Descent, Feature Engineering","uri":"/datal13/"},{"categories":["DATA100"],"content":"feature function see website code ","date":"2024-07-19","objectID":"/datal13/:2:0","tags":null,"title":"DATA100-L13: Gradient Descent, Feature Engineering","uri":"/datal13/"},{"categories":["DATA100"],"content":"non-numeric features one-hot encoding ","date":"2024-07-19","objectID":"/datal13/:2:1","tags":null,"title":"DATA100-L13: Gradient Descent, Feature Engineering","uri":"/datal13/"},{"categories":["DATA100"],"content":"concat ","date":"2024-07-19","objectID":"/datal13/:2:2","tags":null,"title":"DATA100-L13: Gradient Descent, Feature Engineering","uri":"/datal13/"},{"categories":["DATA100"],"content":"high order polynomials ","date":"2024-07-19","objectID":"/datal13/:3:0","tags":null,"title":"DATA100-L13: Gradient Descent, Feature Engineering","uri":"/datal13/"},{"categories":["DATA100"],"content":"detect overfitting collect more data more see next lecture ","date":"2024-07-19","objectID":"/datal13/:4:0","tags":null,"title":"DATA100-L13: Gradient Descent, Feature Engineering","uri":"/datal13/"},{"categories":["DATA100"],"content":" Accuracy is a necessary, but not sufficient, condition for fair system. Fairness and transparency are context-dependent. Learn to work with contexts, and consider how your data analysis will reshape them. Keep in mind the power, and limits, of data analysis. ","date":"2024-07-19","objectID":"/datal14/:0:0","tags":null,"title":"DATA100-L14: Case Study (HCE): Fairness in Housing Appraisal","uri":"/datal14/"},{"categories":["DATA100"],"content":"开始调包！😏 from sklearn.linear_model import LinearRegression model = LinearRegression() model.fit(df[[\"total_bill\"]], df[\"tip\"]) df[\"predicted_tip\"] = model.predict(df[[\"total_bill\"]]) 所有的机器学习似乎都在最小化loss function，而梯度下降就是一种优化算法，它通过迭代的方式不断更新模型参数，使得loss function的值不断减小。 详情见NNDL栏目 ","date":"2024-07-19","objectID":"/datal12/:0:0","tags":null,"title":"DATA100-L12: Gradient Descent, sklearn","uri":"/datal12/"},{"categories":["DATA100"],"content":"linear in theta linear combination of parameters $\\theta$ ","date":"2024-07-19","objectID":"/datal11/:1:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"define multiple linear regression OLS problem formulation ordinary least squares (OLS) 用线性代数重写之 $$ \\mathbb{\\hat{Y}} = \\mathbb{X}\\theta $$ ","date":"2024-07-19","objectID":"/datal11/:2:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"multiple linear regression model ","date":"2024-07-19","objectID":"/datal11/:3:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"MSE $$ R(\\theta) = \\frac{1}{n}||\\mathbb{Y}-\\hat{\\mathbb{Y}}||_2^2 $$ geometric derivation ","date":"2024-07-19","objectID":"/datal11/:4:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"lin alg review: orthogonality, span $$ span(\\mathbb{A})是一个由列向量组成的space $$ 正交 ","date":"2024-07-19","objectID":"/datal11/:5:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"least squares estimate proof performance: residuals, multiple R-squared lec11.ipynb $$ R^2∈[0,1] $$ 越大拟合效果越好 OLS properties ","date":"2024-07-19","objectID":"/datal11/:6:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"residuals ","date":"2024-07-19","objectID":"/datal11/:7:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"the bias/intercept term ","date":"2024-07-19","objectID":"/datal11/:8:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"existence of a unique solution ","date":"2024-07-19","objectID":"/datal11/:9:0","tags":null,"title":"DATA100-L11: Ordinary Least Squares","uri":"/datal11/"},{"categories":["DATA100"],"content":"constant model + MSE 微积分是求最优化的一种方法 两种记法 constant model + MAE 绝对值求导新视角 $$ \\sum_{\\theta \u003cy_i} 1=\\sum_{\\theta \u003ey_i} 1 $$ 是计数！==\u003e中位数 loss的敏感性问题 revisiting SLR evaluation 画图before modeling！！！ transformations to fit linear model 经验之谈 introducing notation for multiple linear regression ","date":"2024-07-18","objectID":"/datal10/:0:0","tags":null,"title":"DATA100-L10: Constant Model, Loss, and Transformations","uri":"/datal10/"},{"categories":["DATA100"],"content":"regression line, correlation 高中最小二乘法(least squares regression)，线性回归 model $“all\\ models\\ are\\ wrong,\\ but\\ some\\ are\\ useful”$ trade between interpretability and accuracy 物理or统计模型 the modeling process: definitions SLR: Simple Linear Regression 明确input和parameter的区别 有些统计模型可以没有参数！ loss functions metric for good or bad minimizing average loss (Empirical Risk 期望风险？) 最优化！ interpreting SLR: slope, Anscombe’s quartet 解释参数意义 预测未知数据 evaluating the model: RMSE, Residual Plot ","date":"2024-07-18","objectID":"/datal9/:0:0","tags":null,"title":"DATA100-L9: Introduction to Modeling, Simple Linear Regression","uri":"/datal9/"},{"categories":["DATA100"],"content":"Kernel Density Functions ","date":"2024-07-16","objectID":"/datal8/:0:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"KDE Mechanics ","date":"2024-07-16","objectID":"/datal8/:1:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"smoothing in 1D（histograms） rug —\u003e histogram ","date":"2024-07-16","objectID":"/datal8/:1:1","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"smoothing in 2D（heatmaps/Hex Plot） ","date":"2024-07-16","objectID":"/datal8/:1:2","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"KDEs 代码实现： sns.distplot(data, kde=True) ","date":"2024-07-16","objectID":"/datal8/:1:3","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"Kernel Functions and Bandwidth $\\alpha$ 越大，曲线越平滑 当然也有其他的kernel函数，比如： triangular kernel epanechnikov kernel boxcar kernel Visualization Theory 注意可视化的目的！ 仅仅靠统计方法不够直观并且不够准确！ ","date":"2024-07-16","objectID":"/datal8/:2:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"Information Channels color, shape, size, position (coordinate), and orientation ","date":"2024-07-16","objectID":"/datal8/:3:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"Harnessing X/Y do not use different scales for x and y in the same visualization! 比例适中 ","date":"2024-07-16","objectID":"/datal8/:4:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"Harnessing Color 选颜色，jet, viridis主题等等 最好选择perceptually uniform的颜色！而jet不是！Inferno， Turbo可以 ","date":"2024-07-16","objectID":"/datal8/:5:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"Harnessing Markings 人更倾向于比较整齐的直方图（一维长度） 避免移动调整基线！ 取决于讲什么故事 ","date":"2024-07-16","objectID":"/datal8/:6:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"Harnessing Conditioning ","date":"2024-07-16","objectID":"/datal8/:7:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":"Harnessing Context Transformations linearize线性化处理 log transform对数变换 更多的代码参考jupyter notebook ","date":"2024-07-16","objectID":"/datal8/:8:0","tags":null,"title":"DATA100-L8: Visualizations Ⅱ","uri":"/datal8/"},{"categories":["DATA100"],"content":" # Initialize Otter import otter grader = otter.Notebook(\"lab02.ipynb\") ","date":"2024-07-15","objectID":"/datalab02/:0:0","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Lab 2: Pandas Overview 基础操作，注意numpy版本可能过高 To receive credit for a lab, answer all questions correctly and submit before the deadline. This lab is due Tuesday, Feb 1st at 11:59 PM. ","date":"2024-07-15","objectID":"/datalab02/:1:0","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Lab Walk-Through In addition to the lab notebook, we have also released a prerecorded walk-through video of the lab. We encourage you to reference this video as you work through the lab. Run the cell below to display the video. # from IPython.display import YouTubeVideo # YouTubeVideo(\"MLUNk_D7KW0\", list = 'PLQCcNQgUcDfoWO3WVtznI7CBJmtNUqbAN', listType = 'playlist') ","date":"2024-07-15","objectID":"/datalab02/:1:1","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Collaboration Policy Data science is a collaborative activity. While you may talk with others about the labs, we ask that you write your solutions individually. If you do discuss the assignments with others please include their names below. (That’s a good way to learn your classmates’ names.) Collaborators: list collaborators here Pandas is one of the most widely used Python libraries in data science. In this lab, you will review commonly used data wrangling operations/tools in Pandas. We aim to give you familiarity with: Creating DataFrames Slicing DataFrames (i.e. selecting rows and columns) Filtering data (using boolean arrays and groupby.filter) Aggregating (using groupby.agg) In this lab you are going to use several pandas methods. Reminder from lecture that you may press shift+tab on method parameters to see the documentation for that method. For example, if you were using the drop method in pandas, you couold press shift+tab to see what drop is expecting. Pandas is very similar to the datascience library that you saw in Data 8. This conversion notebook may serve as a useful guide! This lab expects that you have watched the pandas lectures. If you have not, this lab will probably take a very long time. Note: The Pandas interface is notoriously confusing for beginners, and the documentation is not consistently great. Throughout the semester, you will have to search through Pandas documentation and experiment, but remember it is part of the learning experience and will help shape you as a data scientist! import numpy as np import matplotlib.pyplot as plt import pandas as pd import plotly.express as px %matplotlib inline ","date":"2024-07-15","objectID":"/datalab02/:1:2","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Creating DataFrames \u0026 Basic Manipulations Recall that a DataFrame is a table in which each column has a specific data type; there is an index over the columns (typically string labels) and an index over the rows (typically ordinal numbers). Usually you’ll create DataFrames by using a function like pd.read_csv. However, in this section, we’ll discuss how to create them from scratch. The documentation for the pandas DataFrame class provides several constructors for the DataFrame class. Syntax 1: You can create a DataFrame by specifying the columns and values using a dictionary as shown below. The keys of the dictionary are the column names, and the values of the dictionary are lists containing the row entries. fruit_info = pd.DataFrame( data = {'fruit': ['apple', 'orange', 'banana', 'raspberry'], 'color': ['red', 'orange', 'yellow', 'pink'], 'price': [1.0, 0.75, 0.35, 0.05] }) fruit_info fruit color price 0 apple red 1.00 1 orange orange 0.75 2 banana yellow 0.35 3 raspberry pink 0.05 Syntax 2: You can also define a DataFrame by specifying the rows as shown below. Each row corresponds to a distinct tuple, and the columns are specified separately. fruit_info2 = pd.DataFrame( [(\"red\", \"apple\", 1.0), (\"orange\", \"orange\", 0.75), (\"yellow\", \"banana\", 0.35), (\"pink\", \"raspberry\", 0.05)], columns = [\"color\", \"fruit\", \"price\"]) fruit_info2 color fruit price 0 red apple 1.00 1 orange orange 0.75 2 yellow banana 0.35 3 pink raspberry 0.05 You can obtain the dimensions of a DataFrame by using the shape attribute DataFrame.shape. fruit_info.shape (4, 3) You can also convert the entire DataFrame into a two-dimensional NumPy array. fruit_info.values array([['apple', 'red', 1.0], ['orange', 'orange', 0.75], ['banana', 'yellow', 0.35], ['raspberry', 'pink', 0.05]], dtype=object) There are other constructors but we do not discuss them here. ","date":"2024-07-15","objectID":"/datalab02/:2:0","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"REVIEW: Selecting Rows and Columns in Pandas As you’ve seen in lecture and discussion, there are two verbose operators in Python for selecting rows: loc and iloc. Let’s review them briefly. Approach 1: loc The first of the two verbose operators is loc, which takes two arguments. The first is one or more row labels, the second is one or more column labels. The desired rows or columns can be provided individually, in slice notation, or as a list. Some examples are given below. Note that slicing in loc is inclusive on the provided labels. #get rows 0 through 2 and columns fruit through price fruit_info.loc[0:2, 'fruit':'price'] # 闭区间 fruit color price 0 apple red 1.00 1 orange orange 0.75 2 banana yellow 0.35 # get rows 0 through 2 and columns fruit and price. # Note the difference in notation and result from the previous example. fruit_info.loc[0:2, ['fruit', 'price']] # 离散的 fruit price 0 apple 1.00 1 orange 0.75 2 banana 0.35 # get rows 0 and 2 and columns fruit and price. fruit_info.loc[[0, 2], ['fruit', 'price']] # 更加离散的 fruit price 0 apple 1.00 2 banana 0.35 # get rows 0 and 2 and column fruit fruit_info.loc[[0, 2], ['fruit']] fruit 0 apple 2 banana Note that if we request a single column but don’t enclose it in a list, the return type of the loc operator is a Series rather than a DataFrame. 注意[ ]包裹问题 # get rows 0 and 2 and column fruit, returning the result as a Series fruit_info.loc[[0, 2], 'fruit'] 0 apple 2 banana Name: fruit, dtype: object If we provide only one argument to loc, it uses the provided argument to select rows, and returns all columns. fruit_info.loc[0:1] # 可以只给行， 不可以只给列 fruit color price 0 apple red 1.00 1 orange orange 0.75 Note that if you try to access columns without providing rows, loc will crash. # uncomment, this code will crash # fruit_info.loc[[\"fruit\", \"price\"]] # uncomment, this code works fine: fruit_info.loc[:, [\"fruit\", \"price\"]] fruit price 0 apple 1.00 1 orange 0.75 2 banana 0.35 3 raspberry 0.05 Approach 2: iloc iloc is very similar to loc except that its arguments are row numbers and column numbers, rather than row labels and labels names. A usueful mnemonic is that the i stands for “integer”. In addition, slicing for iloc is exclusive on the provided integer indices. Some examples are given below: 考虑此时变成python经典索引 # get rows 0 through 3 (exclusive) and columns 0 through 2 (exclusive) fruit_info.iloc[0:3, 0:3] fruit color price 0 apple red 1.00 1 orange orange 0.75 2 banana yellow 0.35 # get rows 0 through 3 (exclusive) and columns 0 and 2. fruit_info.iloc[0:3, [0, 2]] fruit price 0 apple 1.00 1 orange 0.75 2 banana 0.35 # get rows 0 and 2 and columns 0 and 2. fruit_info.iloc[[0, 2], [0, 2]] fruit price 0 apple 1.00 2 banana 0.35 #get rows 0 and 2 and column fruit fruit_info.iloc[[0, 2], [0]] fruit 0 apple 2 banana # get rows 0 and 2 and column fruit fruit_info.iloc[[0, 2], 0] # return a Series! 0 apple 2 banana Name: fruit, dtype: object Note that in these loc and iloc examples above, the row label and row number were always the same. Let’s see an example where they are different. If we sort our fruits by price, we get: fruit_info_sorted = fruit_info.sort_values(\"price\") fruit_info_sorted fruit color price 3 raspberry pink 0.05 2 banana yellow 0.35 1 orange orange 0.75 0 apple red 1.00 Observe that the row number 0 now has index 3, row number 1 now has index 2, etc. These indices are the arbitrary numerical index generated when we created the DataFrame. For example, banana was originally in row 2, and so it has row label 2. If we request the rows in positions 0 and 2 using iloc, we’re indexing using the row NUMBERS, not labels. 这里似乎并不是按照lab所说的那样？ fruit_info_sorted.iloc[[0, 2], 0] 3 raspberry 1 orange Name: fruit, dtype: object Lastly, similar to with loc, the second argument to iloc is optional. That is, if you provide only one argument to iloc, it treats the argument you provide as a set of desired row numbers, not column numbers. fruit_info.iloc[[0, 2]] fruit color price 0 apple red 1.","date":"2024-07-15","objectID":"/datalab02/:2:1","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 1(a) For a DataFrame d, you can add a column with d['new column name'] = ... and assign a list or array of values to the column. Add a column of integers containing 1, 2, 3, and 4 called rank1 to the fruit_info table which expresses your personal preference about the taste ordering for each fruit (1 is tastiest; 4 is least tasty). fruit_info['rank1'] = [1,2,3,4] fruit_info fruit color price rank1 0 apple red 1.00 1 1 orange orange 0.75 2 2 banana yellow 0.35 3 3 raspberry pink 0.05 4 grader.check(\"q1a\") q1a passed! 💯 ","date":"2024-07-15","objectID":"/datalab02/:2:2","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 1(b) You can also add a column to d with d.loc[:, 'new column name'] = .... As above, the first parameter is for the rows and second is for columns. The : means change all rows and the 'new column name' indicates the name of the column you are modifying (or in this case, adding). Add a column called rank2 to the fruit_info table which contains the same values in the same order as the rank1 column. fruit_info.loc[:, 'rank2'] = [1,2,3,4] fruit_info fruit color price rank1 rank2 0 apple red 1.00 1 1 1 orange orange 0.75 2 2 2 banana yellow 0.35 3 3 3 raspberry pink 0.05 4 4 grader.check(\"q1b\") q1b passed! 🍀 ","date":"2024-07-15","objectID":"/datalab02/:2:3","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 2 Use the .drop() method to drop both the rank1 and rank2 columns you created. Make sure to use the axis parameter correctly. Note that drop does not change a table, but instead returns a new table with fewer columns or rows unless you set the optional inplace parameter. Hint: Look through the documentation to see how you can drop multiple columns of a Pandas DataFrame at once using a list of column names. fruit_info_original = fruit_info.drop(labels=['rank1','rank2'],axis=1) fruit_info_original fruit color price 0 apple red 1.00 1 orange orange 0.75 2 banana yellow 0.35 3 raspberry pink 0.05 grader.check(\"q2\") q2 passed! 💯 ","date":"2024-07-15","objectID":"/datalab02/:2:4","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 3 Use the .rename() method to rename the columns of fruit_info_original so they begin with capital letters. Set this new DataFrame to fruit_info_caps. For an example of how to use rename, see the linked documentation above. fruit_info_caps = fruit_info_original.rename(columns={'fruit':'Fruit', 'color':'Color', 'price':'Price'}) fruit_info_caps Fruit Color Price 0 apple red 1.00 1 orange orange 0.75 2 banana yellow 0.35 3 raspberry pink 0.05 grader.check(\"q3\") q3 passed! 🎉 ","date":"2024-07-15","objectID":"/datalab02/:2:5","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Babynames Dataset For the new few questions of this lab, let’s move on to a real world dataset. We’ll be using the babynames dataset from Lecture 1. The babynames dataset contains a record of the given names of babies born in the United States each year. First let’s run the following cells to build the DataFrame baby_names. The cells below download the data from the web and extract the data into a DataFrame. There should be a total of 6215834 records. ","date":"2024-07-15","objectID":"/datalab02/:2:6","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"fetch_and_cache Helper The following function downloads and caches data in the data/ directory and returns the Path to the downloaded file. The cell below the function describes how it works. You are not expected to understand this code, but you may find it useful as a reference as a practitioner of data science after the course. import requests from pathlib import Path def fetch_and_cache(data_url, file, data_dir=\"data\", force=False): \"\"\" Download and cache a url and return the file object. data_url: the web address to download file: the file in which to save the results. data_dir: (default=\"data\") the location to save the data force: if true the file is always re-downloaded return: The pathlib.Path to the file. \"\"\" data_dir = Path(data_dir) data_dir.mkdir(exist_ok=True) file_path = data_dir/Path(file) if force and file_path.exists(): file_path.unlink() if force or not file_path.exists(): print('Downloading...', end=' ') resp = requests.get(data_url) with file_path.open('wb') as f: f.write(resp.content) print('Done!') else: import time created = time.ctime(file_path.stat().st_ctime) print(\"Using cached version downloaded at\", created) return file_path In Python, a Path object represents the filesystem paths to files (and other resources). The pathlib module is effective for writing code that works on different operating systems and filesystems. To check if a file exists at a path, use .exists(). To create a directory for a path, use .mkdir(). To remove a file that might be a symbolic link, use .unlink(). This function creates a path to a directory that will contain data files. It ensures that the directory exists (which is required to write files in that directory), then proceeds to download the file based on its URL. The benefit of this function is that not only can you force when you want a new file to be downloaded using the force parameter, but in cases when you don’t need the file to be re-downloaded, you can use the cached version and save download time. Below we use fetch_and_cache to download the namesbystate.zip zip file, which is a compressed directory of CSV files. This might take a little while! Consider stretching. data_url = 'https://www.ssa.gov/oact/babynames/state/namesbystate.zip' namesbystate_path = fetch_and_cache(data_url, 'namesbystate.zip') Using cached version downloaded at Fri Jul 12 20:04:41 2024 The following cell builds the final full baby_names DataFrame. It first builds one DataFrame per state, because that’s how the data are stored in the zip file. Here is documentation for pd.concat if you want to know more about its functionality. As before, you are not expected to understand this code. import zipfile zf = zipfile.ZipFile(namesbystate_path, 'r') column_labels = ['State', 'Sex', 'Year', 'Name', 'Count'] def load_dataframe_from_zip(zf, f): with zf.open(f) as fh: return pd.read_csv(fh, header=None, names=column_labels) states = [ load_dataframe_from_zip(zf, f) for f in sorted(zf.filelist, key=lambda x:x.filename) if f.filename.endswith('.TXT') ] baby_names = states[0] for state_df in states[1:]: baby_names = pd.concat([baby_names, state_df]) baby_names = baby_names.reset_index().iloc[:, 1:] len(baby_names) 6215834 baby_names.head() State Sex Year Name Count 0 AK F 1910 Mary 14 1 AK F 1910 Annie 12 2 AK F 1910 Anna 10 3 AK F 1910 Margaret 8 4 AK F 1910 Helen 7 ","date":"2024-07-15","objectID":"/datalab02/:2:7","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Selection Examples on Baby Names As with our synthetic fruit dataset, we can use loc and iloc to select rows and columns of interest from our dataset. baby_names.loc[2:5, 'Name']# Series 2 Anna 3 Margaret 4 Helen 5 Elsie Name: Name, dtype: object Notice the difference between the following cell and the previous one, just passing in 'Name' returns a Series while ['Name'] returns a DataFrame. baby_names.loc[2:5, ['Name']] #df Name 2 Anna 3 Margaret 4 Helen 5 Elsie The code below collects the rows in positions 1 through 3, and the column in position 3 (“Name”). baby_names.iloc[1:4, [3]] Name 1 Annie 2 Anna 3 Margaret ","date":"2024-07-15","objectID":"/datalab02/:2:8","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 4 Use .loc to select Name and Year in that order from the baby_names table. name_and_year = baby_names.loc[:, ['Name', 'Year']] name_and_year[:5] # 版本问题 Name Year 0 Mary 1910 1 Annie 1910 2 Anna 1910 3 Margaret 1910 4 Helen 1910 grader.check(\"q4\") q4 results: q4 - 1 result: ✅ Test case passedq4 - 2 result: ✅ Test case passedq4 - 3 result: ❌ Test case failed Trying: name_and_year.loc[0, \"Year\"] Expecting: 1910 ********************************************************************** Line 1, in q4 2 Failed example: name_and_year.loc[0, \"Year\"] Expected: 1910 Got: np.int64(1910) Now repeat the same selection using the plain [] notation. 接受一个list of column name_and_year = baby_names[['Name','Year']] name_and_year[:5] Name Year 0 Mary 1910 1 Annie 1910 2 Anna 1910 3 Margaret 1910 4 Helen 1910 ","date":"2024-07-15","objectID":"/datalab02/:2:9","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Filtering Data ","date":"2024-07-15","objectID":"/datalab02/:3:0","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Review: Filtering with boolean arrays Filtering is the process of removing unwanted material. In your quest for cleaner data, you will undoubtedly filter your data at some point: whether it be for clearing up cases with missing values, for culling out fishy outliers, or for analyzing subgroups of your data set. Example usage looks like df[df['column name'] \u003c 5]. For your reference, some commonly used comparison operators are given below. Symbol Usage Meaning == a == b Does a equal b? \u003c= a \u003c= b Is a less than or equal to b? \u003e= a \u003e= b Is a greater than or equal to b? \u003c a \u003c b Is a less than b? \u003e a \u003e b Is a greater than b? ~ ~p Returns negation of p | p | q p OR q \u0026 p \u0026 q p AND q ^ p ^ q p XOR q (exclusive or) In the following we construct the DataFrame containing only names registered in California ca = baby_names[baby_names['State'] == 'CA'] ca.head(5) State Sex Year Name Count 390635 CA F 1910 Mary 295 390636 CA F 1910 Helen 239 390637 CA F 1910 Dorothy 220 390638 CA F 1910 Margaret 163 390639 CA F 1910 Frances 134 ","date":"2024-07-15","objectID":"/datalab02/:3:1","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 5 Using a boolean array, select the names in Year 2000 (from baby_names) that have larger than 3000 counts. Keep all columns from the original baby_names DataFrame. Note: Note that compound expressions have to be grouped with parentheses. That is, any time you use p \u0026 q to filter the DataFrame, make sure to use df[(df[p]) \u0026 (df[q])] or df.loc[(df[p]) \u0026 (df[q])]. You may use either [] or loc. Both will achieve the same result. For more on [] vs. loc see the stack overflow links from the intro portion of this lab. result = baby_names[(baby_names['Year'] == 2000) \u0026 (baby_names['Count'] \u003e 3000)] result.head() State Sex Year Name Count 725638 CA M 2000 Daniel 4342 725639 CA M 2000 Anthony 3839 725640 CA M 2000 Jose 3804 725641 CA M 2000 Andrew 3600 725642 CA M 2000 Michael 3572 grader.check(\"q5\") # 依旧是版本问题 q5 results: q5 - 1 result: ✅ Test case passedq5 - 2 result: ❌ Test case failed Trying: result[\"Count\"].sum() Expecting: 39000 ********************************************************************** Line 1, in q5 1 Failed example: result[\"Count\"].sum() Expected: 39000 Got: np.int64(39000) q5 - 3 result: ❌ Test case failed Trying: result[\"Count\"].iloc[0] Expecting: 4342 ********************************************************************** Line 1, in q5 2 Failed example: result[\"Count\"].iloc[0] Expected: 4342 Got: np.int64(4342) Query Review Recall that pandas also has a query command. For example, we can get California baby names with the code below. ca = baby_names.query('State == \"CA\"') ca.head(5) State Sex Year Name Count 390635 CA F 1910 Mary 295 390636 CA F 1910 Helen 239 390637 CA F 1910 Dorothy 220 390638 CA F 1910 Margaret 163 390639 CA F 1910 Frances 134 Using the query command, select the names in Year 2000 (from baby_names) that have larger than 3000 counts. result_using_query = baby_names.query(\"Count \u003e 3000 and Year == 2000\") result_using_query.head(5) State Sex Year Name Count 725638 CA M 2000 Daniel 4342 725639 CA M 2000 Anthony 3839 725640 CA M 2000 Jose 3804 725641 CA M 2000 Andrew 3600 725642 CA M 2000 Michael 3572 ","date":"2024-07-15","objectID":"/datalab02/:3:2","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Groupby Let’s now turn to using groupby from lecture 4. Note: This slide provides a visual picture of how groupby.agg works if you’d like a reference. ","date":"2024-07-15","objectID":"/datalab02/:4:0","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 6: Elections Review: Let’s start by reading in the election dataset from the pandas lectures. # run this cell elections = pd.read_csv(\"data/elections.csv\") elections.head(5) Year Candidate Party Popular vote Result % 0 1824 Andrew Jackson Democratic-Republican 151271 loss 57.210122 1 1824 John Quincy Adams Democratic-Republican 113142 win 42.789878 2 1828 Andrew Jackson Democratic 642806 win 56.203927 3 1828 John Quincy Adams National Republican 500897 loss 43.796073 4 1832 Andrew Jackson Democratic 702735 win 54.574789 As we saw, we can groupby a specific column, e.g. “Party”. It turns out that using some syntax we didn’t cover in lecture, we can print out the subframes that result. This isn’t something you’ll do for any practical purpose. However, it may help you get an understanding of what groupby is actually doing. An example is given below for elections since 1980. # run this cell for n, g in elections.query(\"Year \u003e= 1980\").groupby(\"Party\"): print(f\"Name: {n}\") # by the way this is an \"f string\", a relatively new and great feature of Python display(g) Name: Citizens Year Candidate Party Popular vote Result % 127 1980 Barry Commoner Citizens 233052 loss 0.270182 Name: Constitution Year Candidate Party Popular vote Result % 160 2004 Michael Peroutka Constitution 143630 loss 0.117542 164 2008 Chuck Baldwin Constitution 199750 loss 0.152398 172 2016 Darrell Castle Constitution 203091 loss 0.149640 Name: Democratic Year Candidate Party Popular vote Result % 129 1980 Jimmy Carter Democratic 35480115 loss 41.132848 134 1984 Walter Mondale Democratic 37577352 loss 40.729429 137 1988 Michael Dukakis Democratic 41809074 loss 45.770691 140 1992 Bill Clinton Democratic 44909806 win 43.118485 144 1996 Bill Clinton Democratic 47400125 win 49.296938 151 2000 Al Gore Democratic 50999897 loss 48.491813 158 2004 John Kerry Democratic 59028444 loss 48.306775 162 2008 Barack Obama Democratic 69498516 win 53.023510 168 2012 Barack Obama Democratic 65915795 win 51.258484 176 2016 Hillary Clinton Democratic 65853514 loss 48.521539 178 2020 Joseph Biden Democratic 81268924 win 51.311515 Name: Green Year Candidate Party Popular vote Result % 149 1996 Ralph Nader Green 685297 loss 0.712721 155 2000 Ralph Nader Green 2882955 loss 2.741176 156 2004 David Cobb Green 119859 loss 0.098088 165 2008 Cynthia McKinney Green 161797 loss 0.123442 170 2012 Jill Stein Green 469627 loss 0.365199 177 2016 Jill Stein Green 1457226 loss 1.073699 181 2020 Howard Hawkins Green 405035 loss 0.255731 Name: Independent Year Candidate Party Popular vote Result % 130 1980 John B. Anderson Independent 5719850 loss 6.631143 143 1992 Ross Perot Independent 19743821 loss 18.956298 161 2004 Ralph Nader Independent 465151 loss 0.380663 167 2008 Ralph Nader Independent 739034 loss 0.563842 174 2016 Evan McMullin Independent 732273 loss 0.539546 Name: Libertarian Year Candidate Party Popular vote Result % 128 1980 Ed Clark Libertarian 921128 loss 1.067883 132 1984 David Bergland Libertarian 228111 loss 0.247245 138 1988 Ron Paul Libertarian 431750 loss 0.472660 139 1992 Andre Marrou Libertarian 290087 loss 0.278516 146 1996 Harry Browne Libertarian 485759 loss 0.505198 153 2000 Harry Browne Libertarian 384431 loss 0.365525 159 2004 Michael Badnarik Libertarian 397265 loss 0.325108 163 2008 Bob Barr Libertarian 523715 loss 0.399565 169 2012 Gary Johnson Libertarian 1275971 loss 0.992241 175 2016 Gary Johnson Libertarian 4489235 loss 3.307714 180 2020 Jo Jorgensen Libertarian 1865724 loss 1.177979 Name: Natural Law Year Candidate Party Popular vote Result % 148 1996 John Hagelin Natural Law 113670 loss 0.118219 Name: New Alliance Year Candidate Party Popular vote Result % 136 1988 Lenora Fulani New Alliance 217221 loss 0.237804 Name: Populist Year Candidate Party Popular vote Result % 141 1992 Bo Gritz Populist 106152 loss 0.101918 Name: Reform Year Candidate Party Popular vote Result % 150 1996 Ross Perot Reform 8085294 loss 8.408844 154 2000 Pat Buchanan Reform 448895 l","date":"2024-07-15","objectID":"/datalab02/:4:1","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 6a Using groupby.agg or one of the shorthand methods (groupby.min, groupby.first, etc.), create a Series best_result_percentage_only that returns a Series showing the entire best result for every party, sorted in decreasing order. Your Series should include only parties which have earned at least 10% of the vote in some election. Your result should look like this: Party Democratic 61.344703 Republican 60.907806 Democratic-Republican 57.210122 National Union 54.951512 Whig 53.051213 Liberal Republican 44.071406 National Republican 43.796073 Northern Democratic 29.522311 Progressive 27.457433 American 21.554001 Independent 18.956298 Southern Democratic 18.138998 American Independent 13.571218 Constitutional Union 12.639283 Free Soil 10.138474 Name: %, dtype: float64 A list of named groupby.agg shorthand methods is here (you’ll have to scroll down about one page). best_result_percentage_only = elections[elections['%']\u003e=10].groupby('Party')['%'].agg(max).sort_values(ascending=False) # put your code above this line best_result_percentage_only C:\\Users\\86135\\AppData\\Local\\Temp\\ipykernel_61736\\687541662.py:1: FutureWarning: The provided callable \u003cbuilt-in function max\u003e is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead. best_result_percentage_only = elections[elections['%']\u003e=10].groupby('Party')['%'].agg(max).sort_values(ascending=False) Party Democratic 61.344703 Republican 60.907806 Democratic-Republican 57.210122 National Union 54.951512 Whig 53.051213 Liberal Republican 44.071406 National Republican 43.796073 Northern Democratic 29.522311 Progressive 27.457433 American 21.554001 Independent 18.956298 Southern Democratic 18.138998 American Independent 13.571218 Constitutional Union 12.639283 Free Soil 10.138474 Name: %, dtype: float64 grader.check(\"q6a\") q6a results: q6a - 1 result: ✅ Test case passedq6a - 2 result: ❌ Test case failed Trying: best_result_percentage_only[\"Independent\"].sum() Expecting: 18.95629754 ********************************************************************** Line 1, in q6a 1 Failed example: best_result_percentage_only[\"Independent\"].sum() Expected: 18.95629754 Got: np.float64(18.95629754) q6a - 3 result: ❌ Test case failed Trying: best_result_percentage_only.iloc[0] Expecting: 61.34470329 ********************************************************************** Line 1, in q6a 2 Failed example: best_result_percentage_only.iloc[0] Expected: 61.34470329 Got: np.float64(61.34470329) ","date":"2024-07-15","objectID":"/datalab02/:4:2","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 6b Repeat Question 6a. However, this time, your result should be a DataFrame showing all available information rather than only the percentage as a series. This question is trickier than Question 6a. Make sure to check the Lecture 4 slides if you’re stuck! It’s very easy to make a subtle mistake that shows Woodrow Wilson and Howard Taft both winning the 2020 election. For example, the first 3 rows of your table should be: Party Year Candidate Popular Vote Result % Democratic 1964 Lyndon Johnson 43127041 win 61.344703 Republican 1972 Richard Nixon 47168710 win 60.907806 Democratic-Republican 1824 Andrew Jackson 151271 loss 57.210122 Note that the index is Party. In other words, don’t use reset_index. best_result = elections[elections['%']\u003e=10].sort_values(by='%',ascending=False).groupby(['Party']).agg(lambda x: x.iloc[0]).sort_values(by='%',ascending=False) # @ 52:03 in the video of Lecture 4 # put your code above this line best_result Year Candidate Popular vote Result % Party Democratic 1964 Lyndon Johnson 43127041 win 61.344703 Republican 1972 Richard Nixon 47168710 win 60.907806 Democratic-Republican 1824 Andrew Jackson 151271 loss 57.210122 National Union 1864 Abraham Lincoln 2211317 win 54.951512 Whig 1840 William Henry Harrison 1275583 win 53.051213 Liberal Republican 1872 Horace Greeley 2834761 loss 44.071406 National Republican 1828 John Quincy Adams 500897 loss 43.796073 Northern Democratic 1860 Stephen A. Douglas 1380202 loss 29.522311 Progressive 1912 Theodore Roosevelt 4122721 loss 27.457433 American 1856 Millard Fillmore 873053 loss 21.554001 Independent 1992 Ross Perot 19743821 loss 18.956298 Southern Democratic 1860 John C. Breckinridge 848019 loss 18.138998 American Independent 1968 George Wallace 9901118 loss 13.571218 Constitutional Union 1860 John Bell 590901 loss 12.639283 Free Soil 1848 Martin Van Buren 291501 loss 10.138474 grader.check(\"q6b\") q6b results: q6b - 1 result: ✅ Test case passedq6b - 2 result: ❌ Test case failed Trying: best_result[\"Popular vote\"].sum() Expecting: 135020916 ********************************************************************** Line 1, in q6b 1 Failed example: best_result[\"Popular vote\"].sum() Expected: 135020916 Got: np.int64(135020916) q6b - 3 result: ✅ Test case passed ","date":"2024-07-15","objectID":"/datalab02/:4:3","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 6c Our DataFrame contains a number of parties which have never had a successful presidential run. For example, the 2020 elections included candiates from the Libertarian and Green parties, neither of which have elected a president. # just run this cell elections.tail(5) Year Candidate Party Popular vote Result % 177 2016 Jill Stein Green 1457226 loss 1.073699 178 2020 Joseph Biden Democratic 81268924 win 51.311515 179 2020 Donald Trump Republican 74216154 loss 46.858542 180 2020 Jo Jorgensen Libertarian 1865724 loss 1.177979 181 2020 Howard Hawkins Green 405035 loss 0.255731 Suppose we were conducting an analysis trying to focus our attention on parties that had elected a president. The most natural approach is to use groupby.filter. This is an incredibly powerful but subtle tool for filtering data. As a reminder of how filter works, see this slide. The code below accomplishes the task at hand. It does this by creating a function that returns True if and only if a sub-dataframe (a.k.a. group) contains at least one winner. This function in turn uses the Pandas function “any”. # just run this cell def at_least_one_candidate_in_the_frame_has_won(frame): \"\"\"Returns df with rows only kept for parties that have won at least one election \"\"\" return (frame[\"Result\"] == 'win').any() winners_only = ( elections .groupby(\"Party\") .filter(at_least_one_candidate_in_the_frame_has_won) ) winners_only.tail(5) Year Candidate Party Popular vote Result % 171 2012 Mitt Romney Republican 60933504 loss 47.384076 173 2016 Donald Trump Republican 62984828 win 46.407862 176 2016 Hillary Clinton Democratic 65853514 loss 48.521539 178 2020 Joseph Biden Democratic 81268924 win 51.311515 179 2020 Donald Trump Republican 74216154 loss 46.858542 Alternately we could have used a lambda function instead of explicitly defining a named function using def. # just run this cell (alternative) winners_only = ( elections .groupby(\"Party\") .filter(lambda x : (x[\"Result\"] == \"win\").any()) ) winners_only.tail(5) Year Candidate Party Popular vote Result % 171 2012 Mitt Romney Republican 60933504 loss 47.384076 173 2016 Donald Trump Republican 62984828 win 46.407862 176 2016 Hillary Clinton Democratic 65853514 loss 48.521539 178 2020 Joseph Biden Democratic 81268924 win 51.311515 179 2020 Donald Trump Republican 74216154 loss 46.858542 For your exercise, you’ll do a less restrictive filtering of the elections data. Exercise: Using filter, create a DataFrame major_party_results_since_1988 that includes all election results starting in 1988, but only show a row if the Party it belongs to has earned at least 1% of the popular vote in ANY election since 1988. For example, in 1988, you should not include the New Alliance candidate, since this party has not earned 1% of the vote since 1988. However, you should include the Libertarian candidate from 1988 despite only having 0.47 percent of the vote in 1988, because in 2016 and 2020, the Libertarian candidates Gary Johnson and Jo Jorgensen exceeded 1% of the vote. For example, the first three rows of the table you generate should look like: Year Candidate Party Popular vote Result % 135 1988 George H. W. Bush Republican 48886597 win 53.5188 137 1988 Michael Dukakis Democratic 41809074 loss 45.7707 138 1988 Ron Paul Libertarian 431750 loss 0.47266 major_party_results_since_1988 = elections[(elections['Year']\u003e=1988)].groupby('Party').filter(lambda x: (x['%'] \u003e= 1).any()) major_party_results_since_1988.head() Year Candidate Party Popular vote Result % 135 1988 George H. W. Bush Republican 48886597 win 53.518845 137 1988 Michael Dukakis Democratic 41809074 loss 45.770691 138 1988 Ron Paul Libertarian 431750 loss 0.472660 139 1992 Andre Marrou Libertarian 290087 loss 0.278516 140 1992 Bill Clinton Democratic 44909806 win 43.118485 grader.check(\"q6c\") q6c results: q6c - 1 result: ✅ Test case passedq6c - 2 result: ❌ Test case failed Trying: major_party_results_since_1988[\"%\"].min() Expecting: 0.098088334 ***********************","date":"2024-07-15","objectID":"/datalab02/:4:4","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 7 Pandas provides special purpose functions for working with specific common data types such as strings and dates. For example, the code below provides the length of every Candidate’s name from our elections dataset. elections[\"Candidate\"].str.len() 0 14 1 17 2 14 3 17 4 14 .. 177 10 178 12 179 12 180 12 181 14 Name: Candidate, Length: 182, dtype: int64 Exercise: Using .str.split. Create a new DataFrame called elections_with_first_name with a new column First Name that is equal to the Candidate’s first name. See the Pandas str documentation for documentation on using str.split. Hint: Use [0] somewhere in your code. elections_with_first_name = elections.copy() # your code here elections_with_first_name['First Name'] = elections_with_first_name['Candidate'].str.split(' ').str[0].to_frame() # elections_with_first_name['First Name'] = # end your code elections_with_first_name Year Candidate Party Popular vote Result % First Name 0 1824 Andrew Jackson Democratic-Republican 151271 loss 57.210122 Andrew 1 1824 John Quincy Adams Democratic-Republican 113142 win 42.789878 John 2 1828 Andrew Jackson Democratic 642806 win 56.203927 Andrew 3 1828 John Quincy Adams National Republican 500897 loss 43.796073 John 4 1832 Andrew Jackson Democratic 702735 win 54.574789 Andrew ... ... ... ... ... ... ... ... 177 2016 Jill Stein Green 1457226 loss 1.073699 Jill 178 2020 Joseph Biden Democratic 81268924 win 51.311515 Joseph 179 2020 Donald Trump Republican 74216154 loss 46.858542 Donald 180 2020 Jo Jorgensen Libertarian 1865724 loss 1.177979 Jo 181 2020 Howard Hawkins Green 405035 loss 0.255731 Howard 182 rows × 7 columns grader.check(\"q7\") q7 passed! 🙌 ","date":"2024-07-15","objectID":"/datalab02/:4:5","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Question 8 The code below creates a table with the frequency of all names from 2020. # just run this cell baby_names_2020 = ( baby_names.query('Year == 2020') .groupby(\"Name\") .sum()[[\"Count\"]] .reset_index() ) baby_names_2020 Name Count 0 Aaden 15 1 Aadhira 6 2 Aadhvik 5 3 Aadhya 186 4 Aadi 14 ... ... ... 8697 Zymere 6 8698 Zymir 74 8699 Zyon 130 8700 Zyra 33 8701 Zyrah 5 8702 rows × 2 columns Exercise: Using the pd.merge function described in lecture, combine the baby_names_2020 table with the elections_with_first_name table you created earlier to form presidential_candidates_and_name_popularity. presidential_candidates_and_name_popularity = pd.merge(elections_with_first_name,baby_names_2020, left_on='First Name', right_on='Name') presidential_candidates_and_name_popularity Year Candidate Party Popular vote Result % First Name Name Count 0 1824 Andrew Jackson Democratic-Republican 151271 loss 57.210122 Andrew Andrew 5991 1 1824 John Quincy Adams Democratic-Republican 113142 win 42.789878 John John 8180 2 1828 Andrew Jackson Democratic 642806 win 56.203927 Andrew Andrew 5991 3 1828 John Quincy Adams National Republican 500897 loss 43.796073 John John 8180 4 1832 Andrew Jackson Democratic 702735 win 54.574789 Andrew Andrew 5991 ... ... ... ... ... ... ... ... ... ... 148 2016 Hillary Clinton Democratic 65853514 loss 48.521539 Hillary Hillary 20 149 2020 Joseph Biden Democratic 81268924 win 51.311515 Joseph Joseph 8349 150 2020 Donald Trump Republican 74216154 loss 46.858542 Donald Donald 407 151 2020 Jo Jorgensen Libertarian 1865724 loss 1.177979 Jo Jo 6 152 2020 Howard Hawkins Green 405035 loss 0.255731 Howard Howard 131 153 rows × 9 columns grader.check(\"q8\") q8 results: q8 - 1 result: ✅ Test case passedq8 - 2 result: ✅ Test case passedq8 - 3 result: ❌ Test case failed Trying: presidential_candidates_and_name_popularity[presidential_candidates_and_name_popularity[\"Candidate\"] == \"Jo Jorgensen\"].iloc[0][\"Count\"] Expecting: 6 ********************************************************************** Line 1, in q8 2 Failed example: presidential_candidates_and_name_popularity[presidential_candidates_and_name_popularity[\"Candidate\"] == \"Jo Jorgensen\"].iloc[0][\"Count\"] Expected: 6 Got: np.int64(6) Just for fun: Which historical presidential candidates have names that were the least and most popular in 2020? Note: Here you’ll observe a common problem in data science – one of the least popular names is actually due to the fact that one recent president was so commonly known by his nickname that he appears named as such in the database from which you pulled election results. # your optional code here ... ","date":"2024-07-15","objectID":"/datalab02/:4:6","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Bonus Exercises The following exercises are optional and use the ca_baby_names dataset defined below. # just run this cell ca_baby_names = baby_names.query('State == \"CA\"') ca_baby_names State Sex Year Name Count 390635 CA F 1910 Mary 295 390636 CA F 1910 Helen 239 390637 CA F 1910 Dorothy 220 390638 CA F 1910 Margaret 163 390639 CA F 1910 Frances 134 ... ... ... ... ... ... 784809 CA M 2020 Ziaan 5 784810 CA M 2020 Ziad 5 784811 CA M 2020 Ziaire 5 784812 CA M 2020 Zidan 5 784813 CA M 2020 Zymir 5 394179 rows × 5 columns Sorted Female Name Counts Create a Series female_name_since_2000_count which gives the total number of occurrences of each name for female babies born in California from the year 2000 or later. The index should be the name, and the value should be the total number of births. Your Series should be ordered in decreasing order of count. For example, your first row should have index “Emily” and value 52334, because 52334 Emilys have been born since the year 2000 in California. female_name_since_2000_count = female_name_since_2000_count Counts for All Names Using groupby, create a Series count_for_names_2020 listing all baby names from 2020 in California, in decreasing order of popularity. The result should not be broken down by sex! If a name is used by both male and female babies, the number you provide should be the total. Note: In this question we are now computing the number of registered babies with a given name. For example, count_for_names_2020[\"Noah\"] should be the number 2631 because in 2018 there were 2631 Noahs born (23 female and 2608 male). ... count_for_names_2020 ","date":"2024-07-15","objectID":"/datalab02/:5:0","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Extra: Explore the Data Set The popularity of some baby names may be influenced by cultural phenomena, such as a political figure coming to power. Below, we plot the popularity of name Hillary for female babies in Calfiornia over time. What do you notice about this plot? What real-world events in the U.S. occurred when there was a steep drop in babies named Hillary? hillary_baby_name = baby_names[(baby_names['Name'] == 'Hillary') \u0026 (baby_names['State'] == 'CA') \u0026 (baby_names['Sex'] == 'F')] plt.plot(hillary_baby_name['Year'], hillary_baby_name['Count']) plt.title(\"Hillary Popularity Over Time\") plt.xlabel('Year') plt.ylabel('Count'); The code above is hard coded to generate a dataframe representing the popularity of the female name Hillary in the state of California. While this approach works, it’s inelegant. Here we’ll use a more elegant approach that builds a dataframe such that: It contains ALL names. The counts are summed across all 50 states, not just California. To do this, we use groupby, though here we’re grouping on two columns (“Name” and “Year”) instead of just one. After grouping, we use the sum aggregation function. # just run this cell counts_aggregated_by_name_and_year = baby_names.groupby([\"Name\", \"Year\"]).sum() counts_aggregated_by_name_and_year Note that the resulting DataFrame is multi-indexed, i.e. it has two indices. The outer index is the Name, and the inner index is the Year. In order to visualize this data, we’ll use reset_index in order to set the index back to an integer and transform the Name and Year back into columnar data. # just run this cell counts_aggregated_by_name_and_year = counts_aggregated_by_name_and_year.reset_index() counts_aggregated_by_name_and_year Similar to before, we can plot the popularity of a given name by selecting the name we want to visualize. The code below is very similar to the plotting code above, except that we use query to get the name of interest instead of using a boolean array. Note: Here we use a special syntax @name_of_interest to tell the query command to use the python variable name_of_interest. Try out some other names and see what trends you observe. Note that since this is the American social security database, international names are not well represented. # just run this cell name_of_interest = 'Hillary' chosen_baby_name = counts_aggregated_by_name_and_year.query(\"Name == @name_of_interest\") plt.plot(chosen_baby_name['Year'], chosen_baby_name['Count']) plt.title(f\"Popularity Of {name_of_interest} Over Time\") plt.xlabel('Year') plt.ylabel('Count'); To double-check your work, the cell below will rerun all of the autograder tests. grader.check_all() ","date":"2024-07-15","objectID":"/datalab02/:5:1","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"Submission Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. Please save before exporting! # Save your notebook first, then run this cell to export your submission. grader.export(pdf=False) ","date":"2024-07-15","objectID":"/datalab02/:6:0","tags":null,"title":"DATA100-lab02","uri":"/datalab02/"},{"categories":["DATA100"],"content":"distribution 定义 ","date":"2024-07-15","objectID":"/datal7/:1:0","tags":null,"title":"DATA100-L7: Visualization Ⅰ","uri":"/datal7/"},{"categories":["DATA100"],"content":"bar plots for distribution ","date":"2024-07-15","objectID":"/datal7/:2:0","tags":null,"title":"DATA100-L7: Visualization Ⅰ","uri":"/datal7/"},{"categories":["DATA100"],"content":"data8 example ","date":"2024-07-15","objectID":"/datal7/:2:1","tags":null,"title":"DATA100-L7: Visualization Ⅰ","uri":"/datal7/"},{"categories":["DATA100"],"content":"compound way ","date":"2024-07-15","objectID":"/datal7/:2:2","tags":null,"title":"DATA100-L7: Visualization Ⅰ","uri":"/datal7/"},{"categories":["DATA100"],"content":"seaborn example import seaborn as sns sns.countplot(x='variable', data=df) # rug plot sns.rugplot(x='variable', data=df, color='black') ","date":"2024-07-15","objectID":"/datal7/:2:3","tags":null,"title":"DATA100-L7: Visualization Ⅰ","uri":"/datal7/"},{"categories":["DATA100"],"content":"plotly example ","date":"2024-07-15","objectID":"/datal7/:2:4","tags":null,"title":"DATA100-L7: Visualization Ⅰ","uri":"/datal7/"},{"categories":["DATA100"],"content":"处理异常值（outliers）和峰值（mode） ","date":"2024-07-15","objectID":"/datal7/:3:0","tags":null,"title":"DATA100-L7: Visualization Ⅰ","uri":"/datal7/"},{"categories":["DATA100"],"content":"density curve 密度曲线看峰 箱型图 import seaborn as sns sns.boxplot(x='variable', data=df) violin plot 和箱型图对比来看，violin plot宽度有意义 import seaborn as sns sns.violinplot(x='variable', data=df) 处理overplotting random jitter ","date":"2024-07-15","objectID":"/datal7/:3:1","tags":null,"title":"DATA100-L7: Visualization Ⅰ","uri":"/datal7/"},{"categories":["DATA100"],"content":"text data ","date":"2024-07-15","objectID":"/datal6/:1:0","tags":null,"title":"DATA100-L6: Regex","uri":"/datal6/"},{"categories":["DATA100"],"content":"python string methods .replace(str1, str2) .split('/') ","date":"2024-07-15","objectID":"/datal6/:1:1","tags":null,"title":"DATA100-L6: Regex","uri":"/datal6/"},{"categories":["DATA100"],"content":"regex 参考Tools正则表达式笔记 | 优先级较低 感兴趣的练习↓ https://alf.nu/RegexGolf ","date":"2024-07-15","objectID":"/datal6/:2:0","tags":null,"title":"DATA100-L6: Regex","uri":"/datal6/"},{"categories":["DATA100"],"content":"python re .sub() pattern(r\"......\") is a raw string, which means that backslashes are not interpreted as escape characters. eg: “\\\\section” in regular str, “\\section” in raw str. .findall(pattern, string) import re pattern = r'\\b\\w{3}\\b' string = 'The quick brown fox jumps over the lazy dog' matches = re.findall(pattern, string) print(matches) Output: ['The', 'fox', 'dog'] extract() extractall() 有时会有ser.str.extract()形式！ ","date":"2024-07-15","objectID":"/datal6/:2:1","tags":null,"title":"DATA100-L6: Regex","uri":"/datal6/"},{"categories":["DATA100"],"content":"Discussion 2: Pandas Practice We will begin our discussion of Pandas. You will practice: Selecting columns Filtering with boolean conditions Counting with value_counts import pandas as pd import numpy as np ","date":"2024-07-15","objectID":"/datadisc02/:0:0","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Pandas Practise In the first Pandas question, we will be working with the elections dataset from lecture. elections = pd.read_csv(\"elections.csv\") # read in the elections data into a pandas dataframe! elections.head(5) Year Candidate Party Popular vote Result % 0 1824 Andrew Jackson Democratic-Republican 151271 loss 57.210122 1 1824 John Quincy Adams Democratic-Republican 113142 win 42.789878 2 1828 Andrew Jackson Democratic 642806 win 56.203927 3 1828 John Quincy Adams National Republican 500897 loss 43.796073 4 1832 Andrew Jackson Democratic 702735 win 54.574789 ","date":"2024-07-15","objectID":"/datadisc02/:1:0","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 5 We want to select the “Popular vote” column as a pd.Series. Which of the following lines of code will error? elections['Popular vote'] elections.iloc['Popular vote'] elections.loc['Popular vote'] elections.loc[:, 'Popular vote'] elections.iloc[:, 'Popular vote'] Run each line in the cell below and see for yourself! # elections.iloc['Popular vote'] # wrong # elections.iloc[:, 'popular votes'] # wrong # elections['Popular vote'] # right # elections.loc['Popular vote'] # ket error # elections.loc[:,'Popular vote'] # right 0 151271 1 113142 2 642806 3 500897 4 702735 ... 173 62984828 174 732273 175 4489235 176 65853514 177 1457226 Name: Popular vote, Length: 178, dtype: int64 ","date":"2024-07-15","objectID":"/datadisc02/:1:1","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 6 Write one line of Pandas code that returns a pd.DataFrame that only contains election results from the 1900s. elections[(elections['Year'] \u003e= 1900) \u0026 (elections['Year'] \u003c 2000)] # 注意是 \u0026 Year Candidate Party Popular vote Result % 54 1900 John G. Woolley Prohibition 210864 loss 1.526821 55 1900 William Jennings Bryan Democratic 6370932 loss 46.130540 56 1900 William McKinley Republican 7228864 win 52.342640 57 1904 Alton B. Parker Democratic 5083880 loss 37.685116 58 1904 Eugene V. Debs Socialist 402810 loss 2.985897 ... ... ... ... ... ... ... 146 1996 Harry Browne Libertarian 485759 loss 0.505198 147 1996 Howard Phillips Taxpayers 184656 loss 0.192045 148 1996 John Hagelin Natural Law 113670 loss 0.118219 149 1996 Ralph Nader Green 685297 loss 0.712721 150 1996 Ross Perot Reform 8085294 loss 8.408844 97 rows × 6 columns ","date":"2024-07-15","objectID":"/datadisc02/:1:2","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 7 Write one line of Pandas code that returns a pd.Series, where the index is the Party, and the values are how many times that party won an election. Hint: use value_counts. # Your answer here elections['Party'].value_counts() Party Democratic 46 Republican 40 Prohibition 11 Libertarian 11 Socialist 10 Independent 6 Whig 6 Green 6 Progressive 4 Populist 3 Constitution 3 American Independent 3 American 2 National Republican 2 Democratic-Republican 2 Reform 2 Free Soil 2 Anti-Masonic 1 National Union 1 Constitutional Union 1 National Democratic 1 Union Labor 1 Greenback 1 Anti-Monopoly 1 Liberal Republican 1 Southern Democratic 1 Northern Democratic 1 Farmer–Labor 1 Dixiecrat 1 States' Rights 1 Communist 1 Union 1 Taxpayers 1 New Alliance 1 Citizens 1 Natural Law 1 Name: count, dtype: int64 ","date":"2024-07-15","objectID":"/datadisc02/:1:3","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Grading Assistance (Bonus) Fernando is writing a grading script to compute grades for students in Data 101. Recall that many factors go into computing a student’s final grade, including homework, discussion, exams, and labs. In this question, we will help Fernando compute the homework grades for all students using a DataFrame, hw_grades, provided by Gradescope. The Pandas DataFrame hw_grades contains homework grades for all students for all homework assignments, with one row for each combination of student and homework assignment. Any assignments that are incomplete are denoted by NaN (missing) values, and any late assignments are denoted by a True boolean value in the Late column. You may assume that the names of students are unique. Below is a sample of hw_grades. hw_grades = pd.read_csv(\"hw_grades.csv\") hw_grades.sample(5, random_state = 0) Name Assignment Grade Late 28 Sid Homework 9 82.517998 True 11 Ash Homework 2 78.264844 True 10 Ash Homework 1 98.421049 False 41 Emily Homework 2 62.900313 False 2 Meg Homework 3 89.785619 False ","date":"2024-07-15","objectID":"/datadisc02/:2:0","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 8a Assuming there is a late penalty that causes a 10% grade reduction to the student’s current score (i.e. a 65% score would become a 65% - 6.5% = 58.5%), write a line of Pandas code to calculate all the homework grades, including the late penalty if applicable, and store it in a column named ’LPGrade’. # Your answer here hw_grades['LPGrade'] = hw_grades['Grade'] * (1 - hw_grades['Late'] * 0.1) # 用个隐式转换 hw_grades.head() Name Assignment Grade Late LPGrade 0 Meg Homework 1 NaN False NaN 1 Meg Homework 2 64.191844 False 64.191844 2 Meg Homework 3 89.785619 False 89.785619 3 Meg Homework 4 74.420033 False 74.420033 4 Meg Homework 5 74.372434 True 66.935190 ","date":"2024-07-15","objectID":"/datadisc02/:2:1","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 8b Which of the following expressions outputs the students’ names and number of late assignments, from least to greatest number of late assignments? hw_grades.groupby([’Name’]).sum().sort_values() hw_grades.groupby([’Name’, ’Late’]).sum().sort_values() hw_grades.groupby([’Name’]).sum()[’Late’].sort_values() hw_grades.groupby([’Name’]).sum().sort_values()[’Late’] # Your answer here # hw_grades.groupby(['Name']).sum().sort_values() # \u003c---- Try to sort on df, but have to give 'by=...' into sort_values() hw_grades.groupby(['Name']).sum()['Late'].sort_values() Name Sid 1 Emily 2 Meg 2 Ash 3 Smith 3 Name: Late, dtype: int64 ","date":"2024-07-15","objectID":"/datadisc02/:2:2","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 8c If each assignment is weighted equally, fill in the blanks below to calculate each student’s overall homework grade, including late penalties for any applicable assignments. Hint: Recall that incomplete assignments have NaN values. How can we use fillna to replace these null values? hw_grades._________(_______) \\ .groupby(___________)[____________] \\ .agg(____________) # Your answer here hw_grades.fillna(0)\\ .groupby(['Name'])['LPGrade']\\ .agg('mean') # Python中，反斜杠 \\ 用作行续字符，它允许你将一行代码分割成多行，以提高代码的可读性。这在编写较长的一行代码时特别有用，可以避免代码过于拥挤，使得代码更易于阅读和维护。 Name Ash 80.830657 Emily 84.297725 Meg 69.218137 Sid 63.020729 Smith 58.332233 Name: LPGrade, dtype: float64 ","date":"2024-07-15","objectID":"/datadisc02/:2:3","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 8d Of all the homework assignments, which are the most difficult in terms of the median grade? Order by the median grade, from lowest to greatest. Do not consider incomplete assignments or late penalties in this calculation. Fill in the blanks below to answer this question. Hint: Recall that incomplete assignments have NaN values. How can we use dropna to remove these null values? hw_grades._________() \\ .groupby(___________)[____________] \\ .agg(____________) \\ .sort_values() # Your answer here hw_grades.dropna()\\ .groupby('Assignment')['Grade']\\ .agg('median')\\ .sort_values() Assignment Homework 2 64.160918 Homework 10 66.366211 Homework 5 74.372434 Homework 8 76.362904 Homework 4 78.207572 Homework 3 78.348163 Homework 9 82.517998 Homework 6 84.369535 Homework 1 85.473281 Homework 7 92.200688 Name: Grade, dtype: float64 ","date":"2024-07-15","objectID":"/datadisc02/:2:4","tags":null,"title":"DATA100-disc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"EDA: Exploratory Data Analysis ","date":"2024-07-14","objectID":"/datal5/:0:0","tags":null,"title":"DATA100-L5: Data Wrangling and EDA","uri":"/datal5/"},{"categories":["DATA100"],"content":"Infinite loop DW \u0026 EDA…… DW: raw data -\u003e clean data -\u003e usable data ","date":"2024-07-14","objectID":"/datal5/:1:0","tags":null,"title":"DATA100-L5: Data Wrangling and EDA","uri":"/datal5/"},{"categories":["DATA100"],"content":"key data properties to consider in EDA ","date":"2024-07-14","objectID":"/datal5/:2:0","tags":null,"title":"DATA100-L5: Data Wrangling and EDA","uri":"/datal5/"},{"categories":["DATA100"],"content":"structure file format rectangular data: tables and matrices CSV, TabSV/TSV, json(is a dict) txt, XML pd.read_csv('filename.tsv',delimiter='\\t') turn to lec jupyter notebook to see more details 变量种类 注意：不唯一，不全面 multiple files 主键？ ","date":"2024-07-14","objectID":"/datal5/:2:1","tags":null,"title":"DATA100-L5: Data Wrangling and EDA","uri":"/datal5/"},{"categories":["DATA100"],"content":"granularity(颗粒度？) scope and temporality 颗粒度 scope: sampling frame temporality: time-series data unix time posix time ","date":"2024-07-14","objectID":"/datal5/:2:2","tags":null,"title":"DATA100-L5: Data Wrangling and EDA","uri":"/datal5/"},{"categories":["DATA100"],"content":"faithfulness missing data? ","date":"2024-07-14","objectID":"/datal5/:2:3","tags":null,"title":"DATA100-L5: Data Wrangling and EDA","uri":"/datal5/"},{"categories":["UCB-CS61B"],"content":"Exceptions throw statement: throws an exception public V get(K key) { int location = findKey(key); if (location \u003c 0) { throw new IllegalArgumentException(\"Key \" + key + \" does not exist in map.\"); } return values[findKey(key)]; } 显式抛出异常 public static void main(String[] args) { System.out.println(\"ayyy lmao\"); throw new RuntimeException(\"For no reason.\"); } ","date":"2024-07-14","objectID":"/61b-14/:0:0","tags":null,"title":"61B-14: Exceptions, Iterators, Iterables","uri":"/61b-14/"},{"categories":["UCB-CS61B"],"content":"What has been Thrown, can be Caught Dog d = new Dog(\"Lucy\", \"Retriever\", 80); d.becomeAngry(); try { d.receivePat(); } catch (Exception e) { System.out.println( \"Tried to pat: \" + e); } System.out.println(d); 由callstack顺序 exception是一种对象，有时可能见到的错误↓ 最好明确怎么处理exception public static void gulgate() throws IOException { ... throw new IOException(\"hi\"); ... } 有时需要考虑main情况 上面没有明确处理 checked与否见种类 Iteration 创建能支持for (Item i : someIterable)的情况 ","date":"2024-07-14","objectID":"/61b-14/:1:0","tags":null,"title":"61B-14: Exceptions, Iterators, Iterables","uri":"/61b-14/"},{"categories":["UCB-CS61B"],"content":"The Iterable Interface public interface Iterable\u003cT\u003e { Iterator\u003cT\u003e iterator(); } package java.util; public interface Iterator\u003cT\u003e { boolean hasNext(); T next(); } ","date":"2024-07-14","objectID":"/61b-14/:2:0","tags":null,"title":"61B-14: Exceptions, Iterators, Iterables","uri":"/61b-14/"},{"categories":["UCB-CS61B"],"content":"假如要遍历ArrayMap，需要对key进行操作 到此完成，可以执行遍历 ","date":"2024-07-14","objectID":"/61b-14/:2:1","tags":null,"title":"61B-14: Exceptions, Iterators, Iterables","uri":"/61b-14/"},{"categories":["UCB-CS61B"],"content":"Packages and JAR Files ","date":"2024-07-14","objectID":"/61b-15/:0:0","tags":null,"title":"61B-15: Packages, Access Control, Objects","uri":"/61b-15/"},{"categories":["UCB-CS61B"],"content":"创建包 At the top of every file in the package, put the package name. Make sure that the file is stored in a folder with the appropriate folder name. For a package with name ug.joshh.animal, use folder ug/joshh/animal. 要用的时候import即可 ","date":"2024-07-14","objectID":"/61b-15/:1:0","tags":null,"title":"61B-15: Packages, Access Control, Objects","uri":"/61b-15/"},{"categories":["UCB-CS61B"],"content":"default package ","date":"2024-07-14","objectID":"/61b-15/:2:0","tags":null,"title":"61B-15: Packages, Access Control, Objects","uri":"/61b-15/"},{"categories":["UCB-CS61B"],"content":"JAR Files Access Control Object Methods: Equals and toString( ) ","date":"2024-07-14","objectID":"/61b-15/:3:0","tags":null,"title":"61B-15: Packages, Access Control, Objects","uri":"/61b-15/"},{"categories":["UCB-CS61B"],"content":"toString( ) ","date":"2024-07-14","objectID":"/61b-15/:4:0","tags":null,"title":"61B-15: Packages, Access Control, Objects","uri":"/61b-15/"},{"categories":["UCB-CS61B"],"content":"== vs equals( ) == compares references equals( ) compares values, but pay attention to the type! public class Date { private final int month; private final int day; private final int year; public Date(int m, int d, int y) { month = m; day = d; year = y; } public boolean equals(Object x) { if (this == x) return true; if (x == null) return false; if (this.getClass() != x.getClass()) { return false; } Date that = (Date) x; if (this.day != that.day) { return false; } if (this.month != that.month) { return false; } if (this.year != that.year) { return false; } return true; } } ","date":"2024-07-14","objectID":"/61b-15/:5:0","tags":null,"title":"61B-15: Packages, Access Control, Objects","uri":"/61b-15/"},{"categories":["UCB-CS61B"],"content":"Rules for Equals in Java 反身性：x.equals(x) == true 对称性 传递性 注意实现equals方法时，不要违背这些性质！ ","date":"2024-07-14","objectID":"/61b-15/:6:0","tags":null,"title":"61B-15: Packages, Access Control, Objects","uri":"/61b-15/"},{"categories":["UCB-CS61B"],"content":"61B: Writing Efficient Programs Programming cost. How long does it take to develop your programs? How easy is it to read, modify, and maintain your code? More important than you might think! Majority of cost is in maintenance, not development! 自顶向下，逐层抽象，分而治之，化整为零 ADT Implementations Designing ADTs 虽然extension简单，但是委托delegation更加灵活 Views 视图 在Java中，“view\"通常指的是一种数据结构的视图，它提供了一种访问和操作底层数据的方式，而不需要复制整个数据集。视图的主要优点是它们提供了一种高效的方式来操作数据子集，而不需要复制数据，从而节省内存和提高性能。然而，视图也有一些限制，例如固定大小的视图不能添加或删除元素。 Occasionally, implementation details may allow for views that are too difficult to implement for an abstract type. ","date":"2024-07-14","objectID":"/61b-16/:1:0","tags":null,"title":"61B-16: Encapsulation, Lists, Delegation vs. Extension","uri":"/61b-16/"},{"categories":["UCB-CS61B"],"content":"Programming in the Real World 对技术要敬畏 midterm review Comparing strings for equality using == vs .equals —\u003e see in autoboxing lecture 在Java中，this 是一个指向当前对象实例的引用。它通常用于引用当前类的实例成员，或者在方法中区分成员变量和局部变量。然而，你不能将 this 重新赋值为另一个对象的引用，因为 this 是一个固定的概念，它代表当前对象本身。 你提供的代码示例中，尝试将 this 赋值为一个新的 Dog 对象，这是不允许的。Java 编译器会报错，因为它违反了 this 的使用规则。 public class Dog { public void f() { this = new Dog(); // 这行代码会导致编译错误，因为不能重新赋值this } } Dog d = new Dog(); d.f(); // 调用f()方法，但由于上面的错误，这行代码实际上无法执行 如果你想要创建一个新的 Dog 对象并将其引用赋给 this，你需要使用另一个变量，比如 anotherDog。下面是修改后的代码示例： public class Dog { public void f() { Dog anotherDog = new Dog(); // 创建一个新的Dog对象 // 这里你可以使用anotherDog来引用新创建的Dog对象 } } Dog d = new Dog(); d.f(); // 现在f()方法可以正常执行，没有编译错误 在这段修改后的代码中，anotherDog 变量用于存储新创建的 Dog 对象的引用，而 this 仍然保持其原始含义，即指向当前的 Dog 对象实例。 ","date":"2024-07-14","objectID":"/61b-12/:0:0","tags":null,"title":"61B-12:  Coding in the Real World, Review","uri":"/61b-12/"},{"categories":["UCB-CS61B"],"content":"13-16几乎是java语法讲解😄 ","date":"2024-07-14","objectID":"/61b-13/:0:0","tags":null,"title":"61B-13: Generics, Autoboxing","uri":"/61b-13/"},{"categories":["UCB-CS61B"],"content":"Primitives Cannot Be Used as Actual Type Arguments ","date":"2024-07-14","objectID":"/61b-13/:1:0","tags":null,"title":"61B-13: Generics, Autoboxing","uri":"/61b-13/"},{"categories":["UCB-CS61B"],"content":"Autoboxing Wrapper Types Are (Mostly) Just Like Any Class 8种基本类型之间转换也存在widening Immutability 类似于const在cpp public class Date { public final int month; public final int day; public final int year; private boolean contrived = true; public Date(int m, int d, int y) { month = m; day = d; year = y; } } Warning: Declaring a reference as Final does not make object immutable. Example: public final ArrayDeque d = new ArrayDeque(); The d variable can never change, but the referenced deque can! 见指针常量与常量指针的区别in C++ Defining Generic Classes Goal 1: Create a class ArrayMap with the following methods: put(key, value): Associate key with value. If -1, adds k and v to the last position of the arrays. containsKey(key): Checks to see if arraymap contains the key. get(key): Returns value, assuming key exists.. keys(): Returns a list of all keys. size(): Returns number of keys. public class ArrayMap\u003cK, V\u003e { private K[] keys; private V[] values; private int size; public ArrayMap() { keys = (K[]) new Object[100]; values = (V[]) new Object[100]; size = 0; } private int findKey(K key) { for (int i = 0; i \u003c size; i++) { if (keys[i].equals(key)) { return i; } } return -1; } private int getKeyIndex(K key) { for (int i = 0; i \u003c size; i++) { if (keys[i].equals(key)) { return i; } return -1; } } public void put(K key, V value) { int i = getKeyIndex(key); if (i \u003e -1) { values[i] = value; return; } keys[size] = key; values[size] = value; size += 1; } public V get(K key) { return values[findKey(key)]; } public boolean containsKey(K key) { int i = findKey(key); return (i \u003e -1); } public List\u003cK\u003e keys() { List\u003cK\u003e list = new ArrayList\u003cK\u003e(); for (int i = 0; i \u003c size; i++) { list.add(keys[i]); } return list; } public int size() { return size; } } Generic Methods Goal: Create a class MapHelper with two methods: get(Map61B, key): Returns the value corresponding to the given key in the map if it exists, otherwise null. Unlike the ArrayMap’s get method, which crashes if the key doesn’t exist. maxKey(Map61B): Returns the maximum of all keys in the given ArrayMap. Works only if keys can be compared. public class MapHelper { public static \u003cX,Z\u003e Z get(ArrayMap\u003cX,Z\u003e map, X key) { if (map.containsKey(key)) { return map.get(key); } else { return null; } } public static \u003cX extends Comparable\u003cX\u003e,Z\u003e X maxKey(ArrayMap\u003cX,Z\u003e map) { X max = null; for (X key : map.keys()) { if (max == null || key.compareTo(max) \u003e 0) { max = key; } } return max; } } ","date":"2024-07-14","objectID":"/61b-13/:2:0","tags":null,"title":"61B-13: Generics, Autoboxing","uri":"/61b-13/"},{"categories":["UCB-CS61B"],"content":"Subtype Polymorphism 指的是可以使用父类类型的对象来引用子类类型的实例。 DIY Comparison 比较Object类对象时产生问题，如何比较？？？ 考虑写一个比较器，比较两个Object对象 加深编译理解 Comparable Interface public interface Comparable\u003cT\u003e { public int compareTo(T obj); } Comparator Interface public interface Comparator\u003cT\u003e { public int compare(T obj1, T obj2); } ","date":"2024-07-14","objectID":"/61b-10/:0:0","tags":null,"title":"61B-10: Subtype Polymorphism vs. HoFs","uri":"/61b-10/"},{"categories":["UCB-CS61B"],"content":"两者的关系↓ 总结 ","date":"2024-07-14","objectID":"/61b-10/:0:1","tags":null,"title":"61B-10: Subtype Polymorphism vs. HoFs","uri":"/61b-10/"},{"categories":["UCB-CS61B"],"content":"Java Libraries ","date":"2024-07-14","objectID":"/61b-11/:0:0","tags":null,"title":"61B-11: Libraries, Abstract Classes, Packages","uri":"/61b-11/"},{"categories":["UCB-CS61B"],"content":"Collections Collections is a package in Java that provides various utility classes for working with collections. ","date":"2024-07-14","objectID":"/61b-11/:1:0","tags":null,"title":"61B-11: Libraries, Abstract Classes, Packages","uri":"/61b-11/"},{"categories":["UCB-CS61B"],"content":"Tasks引入 3 tasks, given the text of a book: Create a list of all words in the book. Count the number of unique words. Keep track of the number of times that specific words are mentioned. #1 way set public static int countUniqueWords(List\u003cString\u003e words) { Set\u003cString\u003e ss = new HashSet\u003c\u003e(); for (String s : words) { ss.add(s); } return ss.size(); } public static int countUniqueWords(List\u003cString\u003e words) { Set\u003cString\u003e ss = new HashSet\u003c\u003e(); ss.addAll(words); return ss; } #2 way map public static Map\u003cString, Integer\u003e collectWordCount(List\u003cString\u003e words, List\u003cString\u003e targets) { Map\u003cString, Integer\u003e wordCounts = new HashMap\u003c\u003e(); for (String s : targets) { wordCounts.put(s, 0); } for (String s : words) { if (wordCounts.containsKey(s)) { int oldCount = wordCounts.get(s); wordCounts.put(s, oldCount + 1); } } return wordCounts; } Python里面则是dict实现，咋一看似乎更好？但是？ Java9新特点： Interfaces and Abstract Classes More interface details: Can provide variables, but they are public static final. final means the value can never change. A class can implement multiple interfaces. ","date":"2024-07-14","objectID":"/61b-11/:2:0","tags":null,"title":"61B-11: Libraries, Abstract Classes, Packages","uri":"/61b-11/"},{"categories":["UCB-CS61B"],"content":"interface summary ","date":"2024-07-14","objectID":"/61b-11/:3:0","tags":null,"title":"61B-11: Libraries, Abstract Classes, Packages","uri":"/61b-11/"},{"categories":["UCB-CS61B"],"content":"abstract class intro ","date":"2024-07-14","objectID":"/61b-11/:4:0","tags":null,"title":"61B-11: Libraries, Abstract Classes, Packages","uri":"/61b-11/"},{"categories":["UCB-CS61B"],"content":"两者对比 Packages A package is a namespace that organizes classes and interfaces. ","date":"2024-07-14","objectID":"/61b-11/:5:0","tags":null,"title":"61B-11: Libraries, Abstract Classes, Packages","uri":"/61b-11/"},{"categories":["UCB-CS61B"],"content":"Implementation Inheritance: Extends extends Because of extends, RotatingSLList inherits all members of SLList: All instance and static variables. （注意public, private, protected的区别） All methods. All nested classes. Constructors are not inherited. super public class VengefulSLList\u003cItem\u003e extends SLList\u003cItem\u003e { private SLList\u003cItem\u003e deletedItems; public VengefulSLList() { deletedItems = new SLList\u003cItem\u003e(); } @Override public Item removeLast() { Item oldBack = super.removeLast(); deletedItems.addLast(oldBack); return oldBack; } public void printLostItems() { deletedItems.print(); } } 注意没有super.super的情况 ","date":"2024-07-14","objectID":"/61b-9/:0:0","tags":null,"title":"61B-9: Extends, Casting, Higher Order Functions","uri":"/61b-9/"},{"categories":["UCB-CS61B"],"content":"constructor ","date":"2024-07-14","objectID":"/61b-9/:1:0","tags":null,"title":"61B-9: Extends, Casting, Higher Order Functions","uri":"/61b-9/"},{"categories":["UCB-CS61B"],"content":"Object class Encapsulation ","date":"2024-07-14","objectID":"/61b-9/:2:0","tags":null,"title":"61B-9: Extends, Casting, Higher Order Functions","uri":"/61b-9/"},{"categories":["UCB-CS61B"],"content":"Module Module: A set of methods that work together as a whole to perform some task or set of related tasks. Implementation Inheritance Breaks Encapsulation 注意private 还有 反复自我调用↓ Type Checking and Casting 子类赋值给基类可以，反之不行 Dynamic Method Selection and Casting Puzzle Higher Order Functions (A First Look) 执行类似f(f(x))的操作 Java7及之前不能使用函数指针，考虑实体化一个函数对象 Java8及其以后： 一张图总结继承 ","date":"2024-07-14","objectID":"/61b-9/:3:0","tags":null,"title":"61B-9: Extends, Casting, Higher Order Functions","uri":"/61b-9/"},{"categories":["UCB-CS61B"],"content":"Ad Hoc Testing vs. JUnit public class TestSort { /** Tests the sort method of the Sort class. */ public static testSort() { String[] input = {\"cows\", \"dwell\", \"above\", \"clouds\"}; String[] expected = {\"above\", \"cows\", \"clouds\", \"dwell\"}; Sort.sort(input); org.junit.Assert.assertArrayEquals(expected, input); } public static void main(String[] args) { testSort(); } } Selection Sort 简单介绍一下了，关注点在junit Simpler JUnit Tests ADD, TDD, Integration Testing More On JUnit (Extra) ","date":"2024-07-14","objectID":"/61b-7/:0:0","tags":null,"title":"61B-7: Testing","uri":"/61b-7/"},{"categories":["UCB-CS61B"],"content":" but hard to maintain! Hypernyms, Hyponyms, and Interface Inheritance ","date":"2024-07-14","objectID":"/61b-8/:0:0","tags":null,"title":"61B-8: Inheritance, Implements","uri":"/61b-8/"},{"categories":["UCB-CS61B"],"content":"interface public interface List61B\u003cItem\u003e { public void addFirst(Item x); public void addLast(Item y); public Item getFirst(); public Item getLast(); public Item removeLast(); public Item get(int i); public void insert(Item x, int position); public int size(); } Overriding vs. Overloading override注意加上@Override!!! Interface Inheritance 基类存放指针问题 Answer: If X is a superclass of Y, then memory boxes for X may contain Y. An AList is-a List. Therefore List variables can hold ALList addresses. Implementation Inheritance: Default Methods public interface List61B\u003cItem\u003e { public void addFirst(Item x); public void addLast(Item y); public Item getFirst(); public Item getLast(); public Item removeLast(); public Item get(int i); public void insert(Item x, int position); public int size(); default public void print() { for (int i = 0; i \u003c size(); i += 1) { System.out.print(get(i) + \" \"); } System.out.println(); } } Static and Dynamic Type, Dynamic Method Selection ⚠️ ⚠️ ⚠️ More Dynamic Method Selection, Overloading vs. Overriding ⚠️ ⚠️ ⚠️ 紧紧盯住细节！ Interface vs. Implementation Inheritance ","date":"2024-07-14","objectID":"/61b-8/:1:0","tags":null,"title":"61B-8: Inheritance, Implements","uri":"/61b-8/"},{"categories":["UCB-CS61B"],"content":"From IntList to SLList 事实是在SLList里面添加一个Intlist数据成员 Public vs. Private or Nested Classes 介绍了private ","date":"2024-07-14","objectID":"/61b-4/:0:0","tags":null,"title":"61B-4: SLLists, Nested Classes, Sentinel Nodes","uri":"/61b-4/"},{"categories":["UCB-CS61B"],"content":"Nested Classes public class SLList { public class IntNode { public int item; public IntNode next; public IntNode(int i, IntNode n) { item = i; next = n; } } private IntNode first; public SLList(int x) { first = new IntNode(x, null); } ... } addLast() and size() 讨论recursion和iteration两种思路，略过 空间换时间初见 Sentinel Nodes 对边界现象（空指针）的讨论和保护 简化代码.addLast(x) ","date":"2024-07-14","objectID":"/61b-4/:1:0","tags":null,"title":"61B-4: SLLists, Nested Classes, Sentinel Nodes","uri":"/61b-4/"},{"categories":["UCB-CS61B"],"content":"Doubly Linked Lists 注意只有sentinel时要讨论一些特殊情况，特别是环状链表。 Generic Lists 泛型列表 public class SLList\u003cBleepBlorp\u003e { private IntNode sentinel; private int size; public class IntNode { public BleepBlorp item; public IntNode next; ... } ... } SLList\u003cInteger\u003e s1 = new SLList\u003c\u003e(5); s1.insertFront(10); SLList\u003cString\u003e s2 = new SLList\u003c\u003e(\"hi\"); s2.insertFront(\"apple\"); Arrays, AList 介绍了System.arraycopy()用来resize 2D Arrays Arrays vs. Classes array的runtime动态索引（和cpp不一样） class runtime ","date":"2024-07-14","objectID":"/61b-5/:0:0","tags":null,"title":"61B-5: DLLists, Arrays","uri":"/61b-5/"},{"categories":["UCB-CS61B"],"content":"A Last Look at Linked Lists Naive Array Lists public class AList { private int[] items; private int size; public AList() { items = new int[100]; size = 0; } public void addLast(int x) { items[size] = x; size += 1; } public int getLast() { return items[size - 1]; } public int get(int i) { return items[i]; } public int size() { return size; } } Resizing Arrays public void addLast(int x) { if (size == items.length) { int[] a = new int[size + 1]; System.arraycopy(items, 0, a, 0, size); items = a; } items[size] = x; size += 1; } private void resize(int capacity) { int[] a = new int[capacity]; System.arraycopy(items, 0, a, 0, size); items = a; } public void addLast(int x) { if (size == items.length) { resize(size + 1); } items[size] = x; size += 1; } 几何resize ","date":"2024-07-14","objectID":"/61b-6/:0:0","tags":null,"title":"61B-6: ALists, Resizing, vs. SLists","uri":"/61b-6/"},{"categories":["UCB-CS61B"],"content":"memory usage 仔细考量 Generic ALists public class AList\u003cGlorp\u003e { private Glorp[] items; private int size; public AList() { items = (Glorp []) new Object[8]; size = 0; } private void resize(int cap) { Glorp[] a = (Glorp []) new Object[cap]; // reinterprets as Glorp[] System.arraycopy(items, 0, a, 0, size); items = a; } public Glorp get(int i) { return items[i]; } public Glorp deleteBack() { Glorp returnItem = getBack(); items[size - 1] = null; // to help garbage collection size -= 1; return returnItem; } ... ","date":"2024-07-14","objectID":"/61b-6/:1:0","tags":null,"title":"61B-6: ALists, Resizing, vs. SLists","uri":"/61b-6/"},{"categories":["UCB-CS61B"],"content":"java oop Java is an object oriented language with strict requirements: Every Java file must contain a class declaration*. All code lives inside a class*, even helper functions, global constants, etc. To run a Java program, you typically define a main method using public static void main(String[] args) *: This is not completely true, e.g. we can also declare “interfaces” in .Java files that may contain code. We’ll cover these later. ","date":"2024-07-14","objectID":"/61b-1/:1:0","tags":null,"title":"61B-1: Intro, Hello World Java","uri":"/61b-1/"},{"categories":["UCB-CS61B"],"content":"Java and Static Typing The compiler checks that all the types in your program are compatible before the program ever runs! This is unlike a language like Python, where type checks are performed DURING execution. ","date":"2024-07-14","objectID":"/61b-1/:2:0","tags":null,"title":"61B-1: Intro, Hello World Java","uri":"/61b-1/"},{"categories":["UCB-CS61B"],"content":"编译初看 ","date":"2024-07-14","objectID":"/61b-2/:1:0","tags":null,"title":"61B-2: Defining and Using Classes","uri":"/61b-2/"},{"categories":["UCB-CS61B"],"content":"Defining and Instantiating Classes Static vs. Instance Members ","date":"2024-07-14","objectID":"/61b-2/:2:0","tags":null,"title":"61B-2: Defining and Using Classes","uri":"/61b-2/"},{"categories":["UCB-CS61B"],"content":"Static vs. Non-static public static void main(String[] args) Using Libraries ","date":"2024-07-14","objectID":"/61b-2/:3:0","tags":null,"title":"61B-2: Defining and Using Classes","uri":"/61b-2/"},{"categories":["UCB-CS61B"],"content":"Primitive Types 8 primitive types in Java: byte, short, int, long, float, double, boolean, char Everything else, including arrays, is a reference type. ","date":"2024-07-14","objectID":"/61b-3/:0:0","tags":null,"title":"61B-3: References, Recursion, and Lists","uri":"/61b-3/"},{"categories":["UCB-CS61B"],"content":"The Golden Rule of Equals (GRoE) Given variables y and x: y = x copies all the bits from x into y. Reference Types Everything else, including arrays, is a reference type. 和cpp的区别之一不显式使用指针 Parameter Passing pass by value 😋 pass by reference（某种意义上java纯纯pass by value 😏） Instantiation of Arrays IntList and Linked Data Structures 单链表，不赘述 ","date":"2024-07-14","objectID":"/61b-3/:1:0","tags":null,"title":"61B-3: References, Recursion, and Lists","uri":"/61b-3/"},{"categories":null,"content":"CS61ABC DATA100(DS100) 触动的瞬间😋 ","date":"2024-07-14","objectID":"/beyondcode/thinking1/:0:0","tags":null,"title":"Thinking1","uri":"/beyondcode/thinking1/"},{"categories":null,"content":"记录2024寒假时候的思考 ","date":"2024-07-14","objectID":"/beyondcode/thinking0/:0:0","tags":null,"title":"Thinking0","uri":"/beyondcode/thinking0/"},{"categories":["DATA100"],"content":"lambda function lambda x: x**2 非显式定义函数，可以直接使用lambda表达式来定义一个函数。 This is a lambda function that takes in one argument x and returns the square of x. 再看sort_values() 注意传递key df.sort_values(by='column_name', keys=lambda x: x.str.lower(), ascending=True) ","date":"2024-07-14","objectID":"/datal4/:1:0","tags":["pandas"],"title":"DATA100-L4: Pandas Ⅱ","uri":"/datal4/"},{"categories":["DATA100"],"content":"add move modify and so on sort by length of string approach1: create a new column and add to original df newdf = df[\"Name\"].str.len() # create a new column with length of each string df['length'] = newdf df.sort_values(by='length', ascending=True) drop column ","date":"2024-07-14","objectID":"/datal4/:2:0","tags":["pandas"],"title":"DATA100-L4: Pandas Ⅱ","uri":"/datal4/"},{"categories":["DATA100"],"content":"groupby.agg ","date":"2024-07-14","objectID":"/datal4/:3:0","tags":["pandas"],"title":"DATA100-L4: Pandas Ⅱ","uri":"/datal4/"},{"categories":["DATA100"],"content":"never use loops in this class! df.groupby('column_name').agg(f) f is a dictionary of functions to apply to each column. The function can be a lambda function or a named function. ","date":"2024-07-14","objectID":"/datal4/:3:1","tags":["pandas"],"title":"DATA100-L4: Pandas Ⅱ","uri":"/datal4/"},{"categories":["DATA100"],"content":"groupby type: pandas.core.groupby.generic.DataFrameGroupBy ","date":"2024-07-14","objectID":"/datal4/:4:0","tags":["pandas"],"title":"DATA100-L4: Pandas Ⅱ","uri":"/datal4/"},{"categories":["DATA100"],"content":"filter df.groupby('column_name').filter(lambda x: x['column_name'].mean() \u003e 10) This will return a new DataFrame with only the groups that have a mean value greater than 10. ","date":"2024-07-14","objectID":"/datal4/:4:1","tags":["pandas"],"title":"DATA100-L4: Pandas Ⅱ","uri":"/datal4/"},{"categories":["DATA100"],"content":"multi index 多维索引 using pivot_table() df.pivot_table(index=['column1', 'column2'], columns='column3', values='column4', aggfunc='mean') This will create a multi-index pivot table with the specified index and columns, and the mean of column4 for each group. using groupby() df.groupby(['column1', 'column2']).agg({'column3': 'mean', 'column4':'sum'}) This will group the DataFrame by column1 and column2, and calculate the mean and sum of column3 and column4 for each group. ","date":"2024-07-14","objectID":"/datal4/:4:2","tags":["pandas"],"title":"DATA100-L4: Pandas Ⅱ","uri":"/datal4/"},{"categories":["DATA100"],"content":"joining tables left.merge(right, on='column_name', how='inner', lefton='column_name_left', righton='column_name_right') ","date":"2024-07-14","objectID":"/datal4/:5:0","tags":["pandas"],"title":"DATA100-L4: Pandas Ⅱ","uri":"/datal4/"},{"categories":["DATA100"],"content":" # Initialize Otter import otter grader = otter.Notebook(\"hw01.ipynb\") HW 1: Math Review and Plotting 重点在coding，理论供参考 ","date":"2024-07-14","objectID":"/datahw01/:0:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Due Date: Thursday Jan 27, 11:59 PM ","date":"2024-07-14","objectID":"/datahw01/:1:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Collaboration Policy Data science is a collaborative activity. While you may talk with others about the homework, we ask that you write your solutions individually. If you do discuss the assignments with others please include their names at the top of your notebook. Collaborators: list collaborators here ","date":"2024-07-14","objectID":"/datahw01/:2:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"This Assignment The purpose of this assignment is for you to combine Python, math, and the ideas in Data 8 to draw some interesting conclusions. The methods and results will help build the foundation of Data 100. ","date":"2024-07-14","objectID":"/datahw01/:3:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Score Breakdown Question Points 1a 1 1b 2 2a 1 2b 1 2c 2 2d 2 2e 1 3a 2 3b 2 3c 1 3d 2 3e 2 4a 1 4b 1 4c 1 4d 1 5a 1 5b 1 5d 3 6a 2 6b(i) 2 6b(ii) 2 6c 2 Total 36 ","date":"2024-07-14","objectID":"/datahw01/:4:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Before You Start For each question in the assignment, please write down your answer in the answer cell(s) right below the question. We understand that it is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run code, NEVER add cells between a question cell and the answer cell below it. It will cause errors when we run the autograder, and it will sometimes cause a failure to generate the PDF file. Important note: The local autograder tests will not be comprehensive. You can pass the automated tests in your notebook but still fail tests in the autograder. Please be sure to check your results carefully. ","date":"2024-07-14","objectID":"/datahw01/:5:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Initialize your environment This cell should run without error if you’re using the course Jupyter Hub or you have set up your personal computer correctly. import numpy as np import matplotlib import matplotlib.pyplot as plt plt.style.use('fivethirtyeight') ","date":"2024-07-14","objectID":"/datahw01/:5:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Preliminary: Jupyter Shortcuts Here are some useful Jupyter notebook keyboard shortcuts. To learn more keyboard shortcuts, go to Help -\u003e Keyboard Shortcuts in the menu above. Here are a few we like: ctrl+return : Evaluate the current cell shift+return: Evaluate the current cell and move to the next esc : command mode (may need to press before using any of the commands below) a : create a cell above b : create a cell below dd : delete a cell m : convert a cell to markdown y : convert a cell to code ","date":"2024-07-14","objectID":"/datahw01/:5:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Preliminary: NumPy You should be able to understand the code in the following cells. If not, review the following: The Data 8 Textbook Chapter on NumPy DS100 NumPy Review Condensed NumPy Review The Official NumPy Tutorial Jupyter pro-tip: Pull up the docs for any function in Jupyter by running a cell with the function name and a ? at the end: np.arange? \u001b[1;31mDocstring:\u001b[0m arange([start,] stop[, step,], dtype=None, *, device=None, like=None) Return evenly spaced values within a given interval. ``arange`` can be called with a varying number of positional arguments: * ``arange(stop)``: Values are generated within the half-open interval ``[0, stop)`` (in other words, the interval including `start` but excluding `stop`). * ``arange(start, stop)``: Values are generated within the half-open interval ``[start, stop)``. * ``arange(start, stop, step)`` Values are generated within the half-open interval ``[start, stop)``, with spacing between values given by ``step``. For integer arguments the function is roughly equivalent to the Python built-in :py:class:`range`, but returns an ndarray rather than a ``range`` instance. When using a non-integer step, such as 0.1, it is often better to use `numpy.linspace`. See the Warning sections below for more information. Parameters ---------- start : integer or real, optional Start of interval. The interval includes this value. The default start value is 0. stop : integer or real End of interval. The interval does not include this value, except in some cases where `step` is not an integer and floating point round-off affects the length of `out`. step : integer or real, optional Spacing between values. For any output `out`, this is the distance between two adjacent values, ``out[i+1] - out[i]``. The default step size is 1. If `step` is specified as a position argument, `start` must also be given. dtype : dtype, optional The type of the output array. If `dtype` is not given, infer the data type from the other input arguments. device : str, optional The device on which to place the created array. Default: None. For Array-API interoperability only, so must be ``\"cpu\"`` if passed. .. versionadded:: 2.0.0 like : array_like, optional Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as ``like`` supports the ``__array_function__`` protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument. .. versionadded:: 1.20.0 Returns ------- arange : ndarray Array of evenly spaced values. For floating point arguments, the length of the result is ``ceil((stop - start)/step)``. Because of floating point overflow, this rule may result in the last element of `out` being greater than `stop`. Warnings -------- The length of the output might not be numerically stable. Another stability issue is due to the internal implementation of `numpy.arange`. The actual step value used to populate the array is ``dtype(start + step) - dtype(start)`` and not `step`. Precision loss can occur here, due to casting or due to using floating points when `start` is much larger than `step`. This can lead to unexpected behaviour. For example:: \u003e\u003e\u003e np.arange(0, 5, 0.5, dtype=int) array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \u003e\u003e\u003e np.arange(-3, 3, 0.5, dtype=int) array([-3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8]) In such cases, the use of `numpy.linspace` should be preferred. The built-in :py:class:`range` generates :std:doc:`Python built-in integers that have arbitrary size \u003cpython:c-api/long\u003e`, while `numpy.arange` produces `numpy.int32` or `numpy.int64` numbers. This may result in incorrect results for large integer values:: \u003e\u003e\u003e power = 40 \u003e\u003e\u003e modulo = 10000 \u003e\u003e\u003e x1 = [(n ** power) % modulo for n in range(8)] \u003e\u003e\u003e x2 = [(n ** power) % modulo for n in np.arange(8)] \u003e\u003e\u003e print(x1) [0, 1, 7776, 8801, 6176, 625, 6576, 4001] # correct \u003e\u003e\u003e print(x2) [0, 1, 7776, 7185, 0, 5969, 4816, 3361] # incorrect See Also -------- numpy","date":"2024-07-14","objectID":"/datahw01/:5:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Preliminary: LaTeX You should use LaTeX to format math in your answers. If you aren’t familiar with LaTeX, not to worry. It’s not hard to use in a Jupyter notebook. Just place your math in between dollar signs within Markdown cells: $ f(x) = 2x $ becomes $ f(x) = 2x $. If you have a longer equation, use double dollar signs to place it on a line by itself: $$ \\sum_{i=0}^n i^2 $$ becomes: $$ \\sum_{i=0}^n i^2$$ You can align multiple lines using the \u0026 anchor, \\\\ newline, in an align block as follows: \\begin{align} f(x) \u0026= (x - 1)^2 \\\\ \u0026= x^2 - 2x + 1 \\end{align} becomes \\begin{align} f(x) \u0026= (x - 1)^2 \\ \u0026= x^2 - 2x + 1 \\end{align} This PDF has some handy LaTeX. For more about basic LaTeX formatting, you can read this article. ","date":"2024-07-14","objectID":"/datahw01/:5:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Preliminary: Sums Here’s a recap of some basic algebra written in sigma notation. The facts are all just applications of the ordinary associative and distributive properties of addition and multiplication, written compactly and without the possibly ambiguous “…”. But if you are ever unsure of whether you’re working correctly with a sum, you can always try writing $\\sum_{i=1}^n a_i$ as $a_1 + a_2 + \\cdots + a_n$ and see if that helps. You can use any reasonable notation for the index over which you are summing, just as in Python you can use any reasonable name in for name in list. Thus $\\sum_{i=1}^n a_i = \\sum_{k=1}^n a_k$. $\\sum_{i=1}^n (a_i + b_i) = \\sum_{i=1}^n a_i + \\sum_{i=1}^n b_i$ $\\sum_{i=1}^n d = nd$ $\\sum_{i=1}^n (ca_i + d) = c\\sum_{i=1}^n a_i + nd$ These properties may be useful in the Least Squares Predictor question. To see the LaTeX we used, double-click this cell. Evaluate the cell to exit. ","date":"2024-07-14","objectID":"/datahw01/:5:5","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 1: Calculus In this question we will review some fundamental properties of the sigmoid function, which will be discussed when we talk more about logistic regression in the latter half of the class. The sigmoid function is defined to be $$\\sigma(x) = \\frac{1}{1+e^{-x}}$$ ","date":"2024-07-14","objectID":"/datahw01/:6:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 1a Show that $\\sigma(-x) = 1 - \\sigma(x)$. Note, again: In this class, you must always put your answer in the cell that immediately follows the question. DO NOT create any cells between this one and the one that says Type your answer here, replacing this text. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:6:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 1b Show that the derivative of the sigmoid function can be written as: $$\\frac{d}{dx}\\sigma(x) = \\sigma(x)(1 - \\sigma(x))$$ This PDF has some handy LaTeX. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:6:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2: Probabilities and Proportions Much of data analysis involves interpreting proportions – lots and lots of related proportions. So let’s recall the basics. It might help to start by reviewing the main rules from Data 8, with particular attention to what’s being multiplied in the multiplication rule. ","date":"2024-07-14","objectID":"/datahw01/:7:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2a The Pew Research Foundation publishes the results of numerous surveys, one of which is about the trust that Americans have in groups such as the military, scientists, and elected officials to act in the public interest. A table in the article summarizes the results. Pick one of the options (i) and (ii) to answer the question below; if you pick (i), fill in the blank with the percent. Then, explain your choice. The percent of surveyed U.S. adults who had a great deal of confidence in both scientists and religious leaders (i) is equal to ______________________. (ii) cannot be found with the information in the article. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:7:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2b In a famous (or infamous) survey, members of the Harvard medical school were asked to consider a scenario in which “a test to detect a disease whose prevalence is 1/1,000 has a false positive rate of 5 percent”. The terminology, the specific question asked in the survey, and the answer, are discussed in detail in a Stat 88 textbook section that you are strongly encouraged to read. As Stat 88 is a Data 8 connector course, the section is another look at the same ideas as in the corresponding Data 8 textbook section. The corresponding tree diagram is copied below for your reference. The survey did not provide the true positive rate. The respondents and Stat 88 were allowed to assume that the true positive rate is 1, but we will not do so here. Let the true positive rate be some unknown proportion $p$. Suppose a person is picked at random from the population. Let $N$ be the event that the person doesn’t have the disease and let $T_N$ be the event that the person’s test result is negative. Fill in Blanks 1 and 2 with options chosen from (1)-(9). The proportion $P(N \\mid T_N)$ is the number of people who $\\underline{1}$ relative to the total number of people who $\\underline{2}$. (1) are in the population (2) have the disease (3) don’t have the disease (4) test positive (5) test negative (6) have the disease and test positive (7) have the disease and test negative (8) don’t have the disease and test positive (9) don’t have the disease and test negative Assign the variable q4bi to your answer to the first blank and q4bii to your answer to the second blank. q4bi = ... q4bii = ... q4bi, q4bii grader.check(\"q2b\") ","date":"2024-07-14","objectID":"/datahw01/:7:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2c (This is a continuation of the previous part.) Define a function no_disease_given_negative that takes $p$ as its argument and returns $P(N \\mid T_N)$. def no_disease_given_negative(p): ... grader.check(\"q4c\") ","date":"2024-07-14","objectID":"/datahw01/:7:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2d (This part is a continuation of the previous two.) Pick all of the options (i)-(iv) that are true for all values of $p$. Explain by algebraic or probailistic reasoning; you are welcome to use your function no_disease_given_negative to try a few cases numerically. Your explanation should include the reasons why you didn’t choose some options. $P(N \\mid T_N)$ is (i) equal to $0.95$. (ii) equal to $0.999 \\times 0.95$. (iii) greater than $0.999 \\times 0.95$. (iv) greater than $0.95$. Type your answer here, replacing this text. # Use this cell for experimenting if you wish, but your answer should be written in the cell above. ","date":"2024-07-14","objectID":"/datahw01/:7:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2e Suzuki is one of most commonly owned makes of cars in our county (Alameda). A car heading from Berkeley to San Francisco is pulled over on the freeway for speeding. Suppose I tell you that the car is either a Suzuki or a Lamborghini, and you have to guess which of the two is more likely. What would you guess, and why? Make some reasonable assumptions and explain them (data scientists often have to do this), justify your answer, and say how it’s connected to the previous parts. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:7:5","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3: Distributions Visualizing distributions, both categorical and numerical, helps us understand variability. In Data 8 you visualized numerical distributions by drawing histograms, which look like bar charts but represent proportions by the areas of the bars instead of the heights or lengths. In this exercise you will use the hist function in matplotlib instead of the corresponding Table method to draw histograms. To start off, suppose we want to plot the probability distribution of the number of spots on a single roll of a die. That should be a flat histogram since the chance of each of the values 1 through 6 is 1/6. Here is a first attempt at drawing the histogram. faces = range(1, 7) plt.hist(faces) (array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1.]), array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]), \u003cBarContainer object of 10 artists\u003e) This default plot is not helpful. We have to choose some arguments to get a visualization that we can interpret. Note that the second printed line shows the left ends of the default bins, as well as the right end of the last bin. The first line shows the counts in the bins. If you don’t want the printed lines you can add a semi-colon at the end of the call to plt.hist, but we’ll keep the lines for now. Let’s redraw the histogram with bins of unit length centered at the possible values. By the end of the exercise you’ll see a reason for centering. Notice that the argument for specifying bins is the same as the one for the Table method hist. unit_bins = np.arange(0.5, 6.6) plt.hist(faces, bins = unit_bins) (array([1., 1., 1., 1., 1., 1.]), array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5]), \u003cBarContainer object of 6 artists\u003e) We need to see the edges of the bars! Let’s specify the edge color ec to be white. Here are all the colors you could use, but do try to drag yourself away from the poetic names. plt.hist(faces, bins = unit_bins, ec='white') (array([1., 1., 1., 1., 1., 1.]), array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5]), \u003cBarContainer object of 6 artists\u003e) That’s much better, but look at the vertical axis. It is not drawn to the density scale defined in Data 8. We want a histogram of a probability distribution, so the total area should be 1. We just have to ask for that. plt.hist(faces, bins = unit_bins, ec='white', density=True) (array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667]), array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5]), \u003cBarContainer object of 6 artists\u003e) That’s the probability histogram of the number of spots on one roll of a die. The proportion is $1/6$ in each of the bins. Note: You may notice that running the above cells also displayed the return value of the last function call of each cell. This was intentional on our part to show you how plt.hist() (documentation) returned different values per plot. Note 2: Going forward, you can use a semicolon ; on the last line to suppress additional display, as below. plt.hist(faces, bins = unit_bins, ec='white', density=True); ","date":"2024-07-14","objectID":"/datahw01/:8:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3a Define a function integer_distribution that takes an array of integers and draws the histogram of the distribution using unit bins centered at the integers and white edges for the bars. The histogram should be drawn to the density scale. The left-most bar should be centered at the smallest integer in the array, and the right-most bar at the largest. Your function does not have to check that the input is an array consisting only of integers. The display does not need to include the printed proportions and bins. If you have trouble defining the function, go back and carefully read all the lines of code that resulted in the probability histogram of the number of spots on one roll of a die. Pay special attention to the bins. def integer_distribution(x): bins = np.arange(min(x) - 0.5, max(x) + 1.5) plt.hist(x, bins=bins, ec='white',density=True) integer_distribution(faces) ","date":"2024-07-14","objectID":"/datahw01/:8:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3b (Note: You can complete this part with just prerequisite knowledge for Data 100. That being said, Lecture 2 provides additional historical context and definitions for probability sample, sampling bias, and chance error). One way to use probability samples is to quantify sampling bias and chance error. Put briefly, if we assume that a sample distribution was selected at random from a known population, then we can quantify how likely that sample is to have arisen due to random chance (chance error). If the difference in sample and population distributions is too great, then we suspect that the given sample has bias in how it was selected from the population. Let’s see this process in a post-analysis of pre-election polling of the 1936 U.S. Presidential Election. Through the U.S. electoral college process (we’ll ignore it in this question, but read more here), Franklin D. Roosevelt won the election by an overwhelming margin. The popular vote results were approximately 61% Roosevelt (Democrat, incumbent), 37% Alf Landon (Republican), and 2% other candidates. For this problem, this is our population distribution. You can use np.random.multinomial to simulate drawing at random with replacement from a categorical distribution. The arguments are the sample size n and an array pvals of the proportions in all the categories. The function simulates n independent random draws from the distribution and returns the observed counts in all the categories. Read the documentation to see how this is described formally; we will use the formal terminology and notation in future assignments after we have discussed them in class. You will see that the function also takes a third argument size, which for our purposes will be an integer that specifies the number of times to run the entire simulation. All the runs are independent of each other. Write one line of code that uses np.random.multinomial to run 10 independent simulations of drawing 100 times at random with replacement from a population in which 61% of the people vote for Roosevelt, 37% for Landon, and 2% for other candidatdes. The output should be an array containing the counts in the Roosevelt category in the 10 simulations. It will help to recall how to slice NumPy arrays. Assign your answer to the variable sample. sample = np.random.multinomial(100, [0.61, 0.37, 0.02], size=10)[:, 0] sample array([54, 65, 58, 53, 66, 58, 61, 56, 60, 57], dtype=int32) grader.check(\"q3b\") q3b passed! 🙌 ","date":"2024-07-14","objectID":"/datahw01/:8:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3c Replace the “…” in the code cell below with a Python expression so that the output of the cell is an empirical histogram of 500,000 simulated counts of voters for Roosevelt in 100 draws made at random with replacement from the voting population. After you have drawn the histogram, you might want to take a moment to recall the conclusion reached by the Literary Digest, a magazine that—while having successfully predicted the outcome of many previous presidential elections—failed to correctly predict the winner of the 1936 presidential election. In their survey of 10 million individuals, they predicted the popular vote as just 43% for Roosevelt and 57% for Landon. Based on our simulation, there was most definitely sampling bias in the Digest’s sampling process. simulated_counts = np.random.multinomial(100, [0.61, 0.37, 0.02], size=500000)[:, 0] integer_distribution(simulated_counts) ","date":"2024-07-14","objectID":"/datahw01/:8:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3d As you know, the count of Roosevelt voters in a sample of 100 people drawn at random from the eligible population is expected to be 61. Just by looking at the histogram in Part c, and no other calculation, pick the correct option and explain your choice. You might want to refer to the Data 8 textbook again. The SD of the distribution of the number of Roosevelt voters in a random sample of 100 people drawn from the eligible population is closest to (i) 1.9 (ii) 4.9 (iii) 10.9 (iv) 15.9 Type your answer here. 假设上面图片是对的，用3σ原则粗略估计5左右。 ","date":"2024-07-14","objectID":"/datahw01/:8:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3e The normal curve with mean $\\mu$ and SD $\\sigma$ is defined by $$ f(x) ~ = ~ \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}}, ~~~ -\\infty \u003c x \u003c \\infty $$ Redraw your histogram from Part c and overlay the normal curve with $\\mu = 61$ and $\\sigma$ equal to the choice you made in Part d. You just have to call plt.plot after integer_distribution. Use np.e for $e$. For the curve, use 2 as the line width, and any color that is easy to see over the blue histogram. It’s fine to just let Python use its default color. Now you can see why centering the histogram bars over the integers was a good idea. The normal curve peaks at 26, which is the center of the corresponding bar. mu = 61 sigma = 4.9 x = np.linspace(40, 80, 200) f_x = 1/(sigma * np.sqrt(2 * np.pi)) * np.exp(-(x - mu)**2 / (2 * sigma**2)) plt.plot(x, f_x) integer_distribution(simulated_counts) ","date":"2024-07-14","objectID":"/datahw01/:8:5","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4: Linear Algebra A common representation of data uses matrices and vectors, so it is helpful to familiarize ourselves with linear algebra notation, as well as some simple operations. Define a vector $\\vec{v}$ to be a column vector. Then, the following properties hold: $c\\vec{v}$ with $c$ some constant $c \\in \\mathbb{R}$, is equal to a new vector where every element in $c\\vec{v}$ is equal to the corresponding element in $\\vec{v}$ multiplied by $c$. For example, $2 \\begin{bmatrix} 1 \\ 2 \\ \\end{bmatrix} = \\begin{bmatrix} 2 \\ 4 \\ \\end{bmatrix}$ $\\vec{v}_1 + \\vec{v}_2$ is equal to a new vector with elements equal to the elementwise addition of $\\vec{v}_1$ and $\\vec{v}_2$. For example, $\\begin{bmatrix} 1 \\ 2 \\ \\end{bmatrix} + \\begin{bmatrix} -3 \\ 4 \\ \\end{bmatrix} = \\begin{bmatrix} -2 \\ 6 \\ \\end{bmatrix}$. The above properties form our definition for a linear combination of vectors. $\\vec{v}_3$ is a linear combination of $\\vec{v}_1$ and $\\vec{v}_2$ if $\\vec{v}_3 = a\\vec{v}_1 + b\\vec{v}_2$, where $a$ and $b$ are some constants. Oftentimes, we stack column vectors to form a matrix. Define the rank of a matrix $A$ to be equal to the maximal number of linearly independent columns in $A$. A set of columns is linearly independent if no column can be written as a linear combination of any other column(s) within the set. For example, let $A$ be a matrix with 4 columns. If three of these columns are linearly independent, but the fourth can be written as a linear combination of the other three, then $\\text{rank}(A) = 3$. For each part below, you will be presented with a set of vectors, and a matrix consisting of those vectors stacked in columns. State the rank of the matrix, and whether or not the matrix is full rank. If the matrix is not full rank, state a linear relationship among the vectors—for example: $\\vec{v}_1 = 2\\vec{v}_2$. ","date":"2024-07-14","objectID":"/datahw01/:9:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4a $$ \\vec{v}_1 = \\begin{bmatrix} 1 \\ 0 \\ \\end{bmatrix} , \\vec{v}_2 = \\begin{bmatrix} 1 \\ 1 \\ \\end{bmatrix} , A = \\begin{bmatrix} \\vert \u0026 \\vert \\ \\vec{v}_1 \u0026 \\vec{v}_2 \\ \\vert \u0026 \\vert \\end{bmatrix}$$ Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:9:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4b $$ \\vec{v}_1 = \\begin{bmatrix} 3 \\ -4 \\ \\end{bmatrix} , \\vec{v}_2 = \\begin{bmatrix} 0 \\ 0 \\ \\end{bmatrix} , B = \\begin{bmatrix} \\vert \u0026 \\vert \\ \\vec{v}_1 \u0026 \\vec{v}_2 \\ \\vert \u0026 \\vert \\end{bmatrix} $$ Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:9:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4c $$ \\vec{v}_1 = \\begin{bmatrix} 0 \\ 1 \\ \\end{bmatrix} , \\vec{v}_2 = \\begin{bmatrix} 5 \\ 0 \\ \\end{bmatrix} , \\vec{v}_3 = \\begin{bmatrix} 10 \\ 10 \\ \\end{bmatrix} , C = \\begin{bmatrix} \\vert \u0026 \\vert \u0026 \\vert \\ \\vec{v}_1 \u0026 \\vec{v}_2 \u0026 \\vec{v}_3 \\ \\vert \u0026 \\vert \u0026 \\vert \\end{bmatrix} $$ Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:9:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4d $$ \\vec{v}_1 = \\begin{bmatrix} 0 \\ 2 \\ 3 \\ \\end{bmatrix} , \\vec{v}_2 = \\begin{bmatrix} -2 \\ -2 \\ 5 \\ \\end{bmatrix} , \\vec{v}_3 = \\begin{bmatrix} 2 \\ 4 \\ -2 \\ \\end{bmatrix} , D = \\begin{bmatrix} \\vert \u0026 \\vert \u0026 \\vert \\ \\vec{v}_1 \u0026 \\vec{v}_2 \u0026 \\vec{v}_3 \\ \\vert \u0026 \\vert \u0026 \\vert \\end{bmatrix} $$ Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:9:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 5: A Least Squares Predictor Let the list of numbers $(x_1, x_2, \\ldots, x_n)$ be data. You can think of each index $i$ as the label of a household, and the entry $x_i$ as the annual income of Household $i$. Define the mean or average $\\mu$ of the list to be $$\\mu ~ = ~ \\frac{1}{n}\\sum_{i=1}^n x_i.$$ ","date":"2024-07-14","objectID":"/datahw01/:10:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 5a The $i$ th deviation from average is the difference $x_i - \\mu$. In Data 8 you saw in numerical examples that the sum of all these deviations is 0. Now prove that fact. That is, show that $\\sum_{i=1}^n (x_i - \\mu) = 0$. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:10:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 5b Recall that the variance of a list is defined as the mean squared deviation from average, and that the standard deviation (SD) of the list is the square root of the variance. The SD is in the same units as the data and measures the rough size of the deviations from average. Denote the variance of the list by $\\sigma^2$. Write a math expression for $\\sigma^2$ in terms of the data ($x_{1} \\dots x_{n}$) and $\\mu$. We recommend building your expression by reading the definition of variance from right to left. That is, start by writing the notation for “average”, then “deviation from average”, and so on. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:10:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Mean Squared Error Suppose you have to predict the value of $x_i$ for some $i$, but you don’t get to see $i$ and you certainly don’t get to see $x_i$. You decide that whatever $x_i$ is, you’re just going to use some number $c$ as your predictor. The error in your prediction is $x_i - c$. Thus the mean squared error (MSE) of your predictor $c$ over the entire list of $n$ data points can be written as: $$MSE(c) = \\frac{1}{n}\\sum_{i=1}^n (x_i - c)^2.$$ You may already see some similarities to your definition of variance from above! You then start to wonder—if you picked your favorite number $c = \\mu$ as the predictor, would it be “better” than other choices $c \\neq \\mu$? ","date":"2024-07-14","objectID":"/datahw01/:10:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 5c One common approach to defining a “best” predictor is as predictor that minimizes the MSE on the data $(x_1, \\dots, x_n)$. In this course, we commonly use calculus to find the predictor $c$ as follows: Define $MSE$ to be a function of $c$, i.e., $MSE(c)$ as above. Assume that the data points $x_1, x_2, …, x_n$ are fixed, and that $c$ is the only variable. Determine the value of $c$ that minimizes $MSE(c)$. Justify that this is indeed a minimum, not a maximum. Step 1 is done for you in the problem statement; follow steps 2 and 3 to show that $\\mu$ is the value of $c$ that minimizes $MSE(c)$. You must do both steps. Type your answer here, replacing this text. Your proof above shows that $\\mu$ is the least squares constant predictor. ","date":"2024-07-14","objectID":"/datahw01/:10:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6: A More Familiar Least Squares Predictor In Data 8 you found (numerically) the least squares linear predictor of a variable $y$ based on a related variable $x$. In this course, we will prove your findings using a generalization of your calculation in the previous question. When we get to this proof later in this course, you will need to be comfortable with vector operations. For now, you will get familiar with this notation by rewriting your least squares findings from Data 8 (and the previous question) using vector notation. This question won’t require you to write LaTeX, so just focus on the mathematical notation we’re presenting. ","date":"2024-07-14","objectID":"/datahw01/:11:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"The Dot Product (1) We start by defining the dot product of two real vectors $x = \\begin{bmatrix} x_1 \\ x_2 \\ \\dots \\ x_n \\end{bmatrix}$ and $y = \\begin{bmatrix} y_1 \\ y_2 \\ \\dots \\ y_n \\end{bmatrix}$ as follows: $$x^T y = \\sum_{i=1}^n x_i y_i $$ Given the above definition, the dot product is (1) a scalar, not another vector; and (2) only defined for two vectors of the same length. Note: In this course we often opt for $x$ instead of $\\vec{x}$ to simplify notation; $x$ as a vector is inferred from its use in the dot product. Then $x_i$ is the $i$-th element of the vector $x$. Detail: In this course, we prefer the notation $x^Ty$ to illustrate a dot product, defined as matrix multiplication of $x^T$ and $y$. In the literature you may also see $x \\cdot y$, but we avoid this notation since the dot ($\\cdot$) notation is occasionally used for scalar values. Detail: The dot product is a special case of an inner product, where $x, y \\in \\mathbb{R}^n$. (2) We introduce a special vector, $\\mathbb{1}$, to write the mean $\\bar{x}$ of data $(x_1, x_2, \\dots, x_n)$ as a dot product: \\begin{align} \\bar{x} \u0026= \\frac{1}{n}\\sum_{i=1}^n x_i = \\frac{1}{n}\\sum_{i=1}^n 1x_i \\ \u0026= \\frac{1}{n}(x^T\\mathbb{1}). \\end{align} The data $(x_1, \\dots, x_n)$ have been defined as an $n$-dimensional column vector $x$, where $x = \\begin{bmatrix} x_1 \\ x_2 \\ \\dots \\ x_n \\end{bmatrix}$. The special vector $\\mathbb{1}$ is a vector of ones, whose length is defined by the vector operation in which it is used. So with $n$-dimensional column vector $x$, the dot product $x^T\\mathbb{1}$ implies that $\\mathbb{1}$ is an $n$-dimensional column vector where every element is $1$. Because dot products produce scalars, the multiplication of two scalars $\\frac{1}{n}$ and $x^T\\mathbb{1}$ produces another scalar, $\\bar{x}$. Note: We use bar notation for the mean ($\\bar{x}$ instead of $\\mu$) in this problem to differentiate $\\bar{x}$ from $\\bar{y}$, the latter of which is the mean of data $(y_1, \\dots, y_n)$. (3) We can further use this definition of $\\bar{x}$ to additionally write the variance $\\sigma_x^2$ of the data $(x_1, \\dots, x_n)$ as a dot product. Verify for yourself that the below operation defines $\\sigma_x^2$ as a scalar: \\begin{align} \\sigma_x^2 \u0026= \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2 \\ \u0026= \\frac{1}{n}(x - \\bar{x})^T(x - \\bar{x}). \\end{align} ","date":"2024-07-14","objectID":"/datahw01/:11:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6a To verify your understanding of the dot product as defined above, suppose you are working with $n$ datapoints ${(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)}$. Define the $x$ data as $(x_1, \\dots, x_n)$ and the $y$ data as $(y_1, \\dots, y_n)$, and define $x$ and $y$ as two $n$-dimensional column vectors, where the $i$-th elements of $x$ and $y$ are $x_i$ and $y_i$, respectively. Define $\\bar{x}$ and $\\bar{y}$ as the means of the $x$ data and $y$ data, respectively. Define $\\sigma_x^2$ and $\\sigma_y^2$ as the variances of the $x$ data and $y$ data, respectively. Therefore $\\sigma_x = \\sqrt{\\sigma_x^2}$ and $\\sigma_y = \\sqrt{\\sigma_y^2}$ are the standard deviations of the $x$ data and $y$ data, respectively. Suppose $n = 32$. What is the dimension of each of the following expressions? Expression (i). Note there are two ways it is written in the literature. $$\\dfrac{1}{\\sigma_x} (x - \\bar{x}) = \\dfrac{x - \\bar{x}}{\\sigma_x} $$ Expression (ii). $$\\dfrac{1}{n} \\left( \\dfrac{x - \\bar{x}}{\\sigma^x}\\right)^T \\left( \\dfrac{x - \\bar{x}}{\\sigma^x}\\right)$$ Assign the variables q6a_i and q6a_ii to an integer representing the dimension of the above expressions (i) and (ii), respectively. q6a_i = ... q6a_ii = ... # do not modify these lines print(f\"Q6a(i) is {q6a_i}-dimensional\") print(f\"Q6a(ii) is {q6a_ii}-dimensional\") grader.check(\"q6a\") ","date":"2024-07-14","objectID":"/datahw01/:11:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Dot Products in NumPy Next, we’ll use NumPy’s matrix multiplication operators to compute expressions for the regression line, which you learned in Data 8 was the unique line that minimizes the mean squared error of estimation among all straight lines. At this time, it may be helpful to review the Data 8 section. Before we continue, let’s contextualize our computation by loading in a dataset you saw in Data 8: the relation between weight lifted and shot put distance among surveyed female collegiate athletes. We’ve plotted the point using matplotlib’s scatter function, which you will see in more detail in two weeks. # Run this cell to plot the data. weight_lifted = np.array([ 37.5, 51.5, 61.3, 61.3, 63.6, 66.1, 70. , 92.7, 90.5, 90.5, 94.8, 97. , 97. , 97. , 102. , 102. , 103.6, 100.4, 108.4, 114. , 115.3, 114.9, 114.7, 123.6, 125.8, 119.1, 118.9, 141.1]) shot_put_distance = np.array([ 6.4, 10.2, 12.4, 13. , 13.2, 13. , 12.7, 13.9, 15.5, 15.8, 15.8, 16.8, 17.1, 17.8, 14.8, 15.5, 16.1, 16.2, 17.9, 15.9, 15.8, 16.7, 17.6, 16.8, 17. , 18.2, 19.2, 18.6]) plt.scatter(weight_lifted, shot_put_distance) plt.xlabel(\"Weight Lifted\") plt.ylabel(\"Shot Put Distance\") Looks pretty linear! Let’s try to fit a regression line to this data. Define the vectors $x$ as the weight lifted data vector and $y$ as the shot put distance data vector, respectively, of the college athletes. Then the regression line uses the weight lifted $x$ to predict $\\hat{y}$, which is the linear estimate of the actual value shot put distance $y$ as follows: \\begin{align} \\hat{y} \u0026= \\hat{a} + \\hat{b}{x}\\text{, where} \\ \\hat{a} \u0026= \\bar{y} - \\hat{b}\\bar{x} \\ \\hat{b} \u0026= r \\dfrac{\\sigma_y}{\\sigma_x} \\end{align} $\\bar{x}, \\bar{y}$ and $\\sigma_x, \\sigma_y$ are the means and standard deviations, respectively of the data $x$ and $y$, respectively. Here, $r$ is the correlation coefficient as defined in Data 8! Note: We use the hat $\\hat{}$ notation to indicate values we are estimating: $\\hat{y}$, the predicted shot put distance, as well as $\\hat{a}$ and $\\hat{b}$, the respective estimated intercept and slope parameters we are using to model the “best” linear predictor of $y$ from $x$. We’ll dive into this later in the course. Note: Remember how we dropped the $\\vec{}$ vector notation? These linear regression equations therefore represent both the scalar case (predict a single value $\\hat{y}$ from a single $x$) and the vector case (predict a vector $\\hat{y}$ element-wise from a vector $x$). How convenient!! In this part, instead of using NumPy’s built-in statistical functions like np.mean() and np.std(), you are going to use NumPy’s matrix operations to create the components of the regression line from first principles. The @ operator multiplies NumPy matrices or arrays together (documentation). We can use this operator to write functions to compute statistics on data, using the expressions that we defined in part (a). Check it out: # Just run this cell. def dot_mean(arr): n = len(arr) all_ones = np.ones(n) # creates n-dimensional vector of ones return (arr.T @ all_ones)/n def dot_var(arr): n = len(arr) mean = dot_mean(arr) zero_mean_arr = arr - mean return (zero_mean_arr.T @ zero_mean_arr)/n def dot_std(arr): return np.sqrt(dot_var(arr)) print(\"np.mean(weight_lifted) =\", np.mean(weight_lifted), \"\\tdot_mean(weight_lifted) =\", dot_mean(weight_lifted)) print(\"np.var(weight_lifted) =\", np.std(weight_lifted), \"\\tdot_var(weight_lifted =\", dot_var(weight_lifted)) print(\"np.std(weight_lifted) =\", np.std(weight_lifted), \"\\tdot_std(weight_lifted =\", dot_std(weight_lifted)) Now, you will write code to define the expressions you explored in part (a) of this question. ","date":"2024-07-14","objectID":"/datahw01/:11:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6b (i) Use the NumPy @ operator to compute expression (i) from part (a). For convenience, we’ve rewritten the expression below. Note that this expression is also referred to as $x$ in standard units (Data 8 textbook section). $$\\dfrac{x - \\bar{x}}{\\sigma_x} $$ Write the body of the function dot_su which takes in a 1-D NumPy array arr and returns arr in standard units. Do not use np.mean(), np.std(), np.var(), np.sum() nor any Python loops. You should only use a subset of @, /, +, -, len(), the dot_mean(), dot_var(), and dot_std() functions defined above. def dot_su(arr): ... # do not edit below this line q6bi_su = dot_su(weight_lifted) q6bi_su grader.check(\"q6bi\") ","date":"2024-07-14","objectID":"/datahw01/:11:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6b (ii) Next use the NumPy @ operator to compute the correlation coefficient $r$, which is expression (ii) from part (a). For convenience, we’ve rewritten the expression below. $$r = \\dfrac{1}{n} \\left( \\dfrac{x - \\bar{x}}{\\sigma^x}\\right)^T \\left( \\dfrac{x - \\bar{x}}{\\sigma^x}\\right)$$ Write the body of the function dot_corr_coeff which takes in two 1-D NumPy arrays x and y and returns the correlation coefficient of x and y. As before, Do not use np.mean(), np.std(), np.var(), np.sum() nor any Python loops. As before, you should only use a subset of @, /, +, -, len(), the dot_mean(), dot_var(), and dot_std() functions defined above. You may also use the dot_su() function that you defined in the previous part. def dot_corr_coeff(x, y): ... # do not edit below this line q6bii_r = dot_corr_coeff(weight_lifted, shot_put_distance) q6bii_r grader.check(\"q6bii\") ","date":"2024-07-14","objectID":"/datahw01/:11:5","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6c We’re ready to put everything together! Finally, use the dot_-prefixed functions in this question to compute the regression line. For convenience, we’ve rewritten the expressions below. $\\hat{y}$ is the linear estimate of the value $y$ based on $x$. \\begin{align} \\hat{y} \u0026= \\hat{a} + \\hat{b}{x}\\text{, where} \\ \\hat{a} \u0026= \\bar{y} - \\hat{b}\\bar{x} \\ \\hat{b} \u0026= r \\dfrac{\\sigma_y}{\\sigma_x} \\end{align} Define the functions compute_a_hat and compute_b_hat which return the intercept and slope, respectively, of the regression line defind above for a linear estimator of y using x. Verify how the functions are used to plot the linear regression line (implemented for you). As before, Do not use np.mean(), np.std(), np.var(), np.sum(), or any for loops. You may use a subset of @, /, +, -, len(), dot_mean(), dot_var(), dot_std(), dot_su(), dot_corr_coeff(). Hint: You may want to define a_hat in terms of b_hat. def compute_a_hat(x, y): ... def compute_b_hat(x, y): ... # do not edit below this line a_hat = compute_a_hat(weight_lifted, shot_put_distance) b_hat = compute_b_hat(weight_lifted, shot_put_distance) shot_put_hats = a_hat + b_hat * weight_lifted plt.scatter(weight_lifted, shot_put_distance) # the actual data plt.plot(weight_lifted, shot_put_hats, color='g', alpha=0.5) # the prediction line, transparent green plt.xlabel(\"Weight Lifted\") plt.ylabel(\"Shot Put Distance\") display(compute_a_hat(weight_lifted, shot_put_distance)) display(compute_b_hat(weight_lifted, shot_put_distance)) grader.check(\"q6c\") To double-check your work, the cell below will rerun all of the autograder tests. grader.check_all() ","date":"2024-07-14","objectID":"/datahw01/:11:6","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Submission Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. Please save before exporting! # Save your notebook first, then run this cell to export your submission. grader.export() ","date":"2024-07-14","objectID":"/datahw01/:12:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"DataFrames: a data structure for tabular data ","date":"2024-07-13","objectID":"/datal3/:1:0","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"API always remember to turn to GPT/google/doc ","date":"2024-07-13","objectID":"/datal3/:1:1","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"indexing and loc/iloc generate subsets: loc: an operator select items by labels df.loc[row_indexer, column_indexer] row_indexer: can be a single label, a list of labels, slice（闭区间）, single value column_indexer: same as row_indexer returns a DataFrame or Series iloc: an operator select items by positions df.iloc[row_indexer, column_indexer] row_indexer: numeric index or a list of numeric indices，此时回到python经典索引 左闭右开 column_indexer: same as row_indexer returns a DataFrame or Series 通常情况下，我们使用 loc 进行索引 .head(6) and .tail() to get the first or last few rows of a DataFrame(syntactic sugar) ","date":"2024-07-13","objectID":"/datal3/:2:0","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"[ ]: context sensitive operator ","date":"2024-07-13","objectID":"/datal3/:3:0","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"series: a data structure for 1D labeled data ","date":"2024-07-13","objectID":"/datal3/:4:0","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"index: a array-like object that labels the rows and columns of a DataFrame columns: usually do not have same name. 转换： ","date":"2024-07-13","objectID":"/datal3/:5:0","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"conditional selection ","date":"2024-07-13","objectID":"/datal3/:6:0","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"类型意识! 三种数据类型中的哪一个？？？ ","date":"2024-07-13","objectID":"/datal3/:7:0","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"describe() ","date":"2024-07-13","objectID":"/datal3/:7:1","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"sample() df.sample(n=5, replace=True) # randomly select 5 rows ","date":"2024-07-13","objectID":"/datal3/:7:2","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"value_counts() df['column_name'].value_counts() # count the frequency of each value in a column return a Series with the count of each value in the column. ","date":"2024-07-13","objectID":"/datal3/:7:3","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"unique() df['column_name'].unique() # get all unique values in a column return a numpy array with the unique values in the column. ","date":"2024-07-13","objectID":"/datal3/:7:4","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"sort_values() df.sort_values(by='column_name', ascending=False) # sort the DataFrame by values in a column return a new DataFrame with the rows sorted by values in a column. ","date":"2024-07-13","objectID":"/datal3/:7:5","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["DATA100"],"content":"reference https://www.textbook.ds100.org/ch/a04/ref_pandas.html https://pandas.pydata.org/pandas-docs/stable/reference/index.html ","date":"2024-07-13","objectID":"/datal3/:8:0","tags":["pandas"],"title":"DATA100-L3: Pandas Ⅰ","uri":"/datal3/"},{"categories":["UCB-CS61B"],"content":"ordered linked list—\u003e binary search tree or skip list (out of course) BST Definitions A tree consists of: A set of nodes. A set of edges that connect those nodes. Constraint: There is exactly one path between any two nodes. In a rooted tree, we call one node the root. Every node N except the root has exactly one parent, defined as the first node on the path from N to the root. Unlike (most) real trees, the root is usually depicted at the top of the tree. A node with no child is called a leaf. In a rooted binary tree, every node has either 0, 1, or 2 children (subtrees). ","date":"2024-07-13","objectID":"/61b-21/:0:0","tags":null,"title":"61B-21: Trees, BSTs","uri":"/61b-21/"},{"categories":["UCB-CS61B"],"content":"Properties of BSTs A binary search tree is a rooted binary tree with the BST property. BST Property. For every node X in the tree: Every key in the left subtree is less than X’s key. Every key in the right subtree is greater than X’s key. One consequence of these rules: No duplicate keys allowed! BST Operations ","date":"2024-07-13","objectID":"/61b-21/:1:0","tags":null,"title":"61B-21: Trees, BSTs","uri":"/61b-21/"},{"categories":["UCB-CS61B"],"content":"Finding a searchKey in a BST static BST find(BST T, Key sk) { if (T == null) return null; if (sk.keyequals(T.label())) return T; else if (sk ≺ T.label()) return find(T.left, sk); else return find(T.right, sk); } runtime: $O(h)$, where $h$ is the height of the tree, i.e., $O(log (N))$, where $N$ is the number of nodes in the tree. ","date":"2024-07-13","objectID":"/61b-21/:2:0","tags":null,"title":"61B-21: Trees, BSTs","uri":"/61b-21/"},{"categories":["UCB-CS61B"],"content":"Inserting a new key into a BST static BST insert(BST T, Key ik) { if (T == null) return new BST(ik); if (ik ≺ T.label()) T.left = insert(T.left, ik); else if (ik ≻ T.label()) T.right = insert(T.right, ik); return T; } ","date":"2024-07-13","objectID":"/61b-21/:3:0","tags":null,"title":"61B-21: Trees, BSTs","uri":"/61b-21/"},{"categories":["UCB-CS61B"],"content":"Deleting a key from a BST no child: simply remove the node. one child: replace the node with its child. two children: find the inorder successor (smallest in the right subtree) and replace the node with it. Then recursively delete the inorder successor from the right subtree. BST Performance ","date":"2024-07-13","objectID":"/61b-21/:4:0","tags":null,"title":"61B-21: Trees, BSTs","uri":"/61b-21/"},{"categories":["UCB-CS61B"],"content":"Tree Height Performance of spindly trees can be just as bad as a linked list! usually, the height of a BST is $O(log(N))$, where $N$ is the number of nodes in the tree. ","date":"2024-07-13","objectID":"/61b-21/:5:0","tags":null,"title":"61B-21: Trees, BSTs","uri":"/61b-21/"},{"categories":["UCB-CS61B"],"content":"Insertion demo Random inserts take on average only Θ(log N) each. ","date":"2024-07-13","objectID":"/61b-21/:6:0","tags":null,"title":"61B-21: Trees, BSTs","uri":"/61b-21/"},{"categories":["UCB-CS61B"],"content":"Deletion demo https://docs.google.com/presentation/d/1rEHpAx8Xu2LnJBWsRPWy8blL20qb96Q5UhdZtQYFkBI/edit#slide=id.g75707c75c_0224 ","date":"2024-07-13","objectID":"/61b-21/:7:0","tags":null,"title":"61B-21: Trees, BSTs","uri":"/61b-21/"},{"categories":["UCB-CS61B"],"content":"To avoid the worst-case time complexity of O(n), we need to use a balanced binary search tree. Tree Rotation Non-obvious fact: Rotation allows balancing of any BST. One way to achieve balance: Rotate after each insertion and deletion to maintain balance. … the mystery is to know which rotations. We’ll come back to this. B-trees / 2-3 trees / 2-3-4 trees ","date":"2024-07-13","objectID":"/61b-22/:0:0","tags":null,"title":"61B-22: Balanced BSTs","uri":"/61b-22/"},{"categories":["UCB-CS61B"],"content":"search tree ","date":"2024-07-13","objectID":"/61b-22/:1:0","tags":null,"title":"61B-22: Balanced BSTs","uri":"/61b-22/"},{"categories":["UCB-CS61B"],"content":"weird solution to achieve balance add leaf overstuff leaf, but can not be too juicy! ","date":"2024-07-13","objectID":"/61b-22/:2:0","tags":null,"title":"61B-22: Balanced BSTs","uri":"/61b-22/"},{"categories":["UCB-CS61B"],"content":"Performance of B-trees Splitting tree is a better name, but I didn’t invent them, so we’re stuck with their real name: B-trees. A B-tree of order M=4 (like we used today) is also called a 2-3-4 tree or a 2-4 tree. The name refers to the number of children that a node can have, e.g. a 2-3-4 tree node may have 2, 3, or 4 children. A B-tree of order M=3 (like in the textbook) is also called a 2-3 tree. Red-Black Trees There are many types of search trees: Binary search trees: Require rotations to maintain balance. There are many strategies for rotation. Coming up with a strategy is hard. 2-3 trees: No rotations required. Clever (and strange idea): Build a BST that is isometric (structurally identical) to a 2-3 tree. Use rotations to ensure the isometry. Since 2-3 trees are balanced, rotations on BST will ensure balance. Maintaining Isometry Through Rotations (Optional) Violations for LLRBs: Two red children. Two consecutive red links. Right red child. Operations for Fixing LLRB Tree Violations: Tree rotations and Color Flips! when insert , use red link if right-insert happens, rotateLeft two red children? two reds in a row? Left-Red-Right-Red? ","date":"2024-07-13","objectID":"/61b-22/:3:0","tags":null,"title":"61B-22: Balanced BSTs","uri":"/61b-22/"},{"categories":["UCB-CS61B"],"content":"summary ","date":"2024-07-13","objectID":"/61b-22/:4:0","tags":null,"title":"61B-22: Balanced BSTs","uri":"/61b-22/"},{"categories":["UCB-CS61B"],"content":"Big-O Notation ","date":"2024-07-13","objectID":"/61b-19/:1:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"细节分析 ","date":"2024-07-13","objectID":"/61b-19/:2:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"局限性 ","date":"2024-07-13","objectID":"/61b-19/:3:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"对比 Important: Big O does not mean “worst case”! Often abused to mean this. ","date":"2024-07-13","objectID":"/61b-19/:4:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"大O记号的用处 ","date":"2024-07-13","objectID":"/61b-19/:5:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"Big-Omega Notation $\\Omega(f(n))$ ","date":"2024-07-13","objectID":"/61b-19/:6:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"大Ω记号的用处 ","date":"2024-07-13","objectID":"/61b-19/:7:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"非严格证明和严格证明 ","date":"2024-07-13","objectID":"/61b-19/:8:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"不相交集问题 public interface DisjointSets { /** Connects two items P and Q. */ void connect(int p, int q); /** Checks to see if two items are connected. */ boolean isConnected(int p, int q); } ","date":"2024-07-13","objectID":"/61b-20/:0:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"naive implementation 真的链接两个元素，然后考虑遍历整个集合，判断是否有两个元素是连通的。 ","date":"2024-07-13","objectID":"/61b-20/:0:1","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"better implementation Better approach: Model connectedness in terms of sets. How things are connected isn’t something we need to know.😉 ","date":"2024-07-13","objectID":"/61b-20/:0:2","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"quick-find public class QuickFindDS implements DisjointSets { private int[] id; // really fast public boolean isConnected(int p, int q) { return id[p] == id[q]; } public void connect(int p, int q) { int pid = id[p]; int qid = id[q]; for (int i = 0; i \u003c id.length; i++) { if (id[i] == pid) { id[i] = qid; } }... } // constructor public QuickFindDS(int N) { id = new int[N]; for (int i = 0; i \u003c N; i++) id[i] = i; } } ","date":"2024-07-13","objectID":"/61b-20/:1:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"quick-union 考虑不用数组，用 🌳😋 tree can not be too tall: 树不能太高，否则会退化成链表⚠️ public class QuickUnionDS implements DisjointSets { private int[] parent; public QuickUnionDS(int N) { parent = new int[N]; for (int i = 0; i \u003c N; i++) parent[i] = i; } // linear time to create N trees private int find(int p) { while (p != parent[p]) p = parent[p]; // p[i] and i 很重要！ return p; } public boolean isConnected(int p, int q) { return find(p) == find(q); } public void connect(int p, int q) { int i = find(p); int j = find(q); parent[i] = j; // 合并两个树 } } ","date":"2024-07-13","objectID":"/61b-20/:2:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"weighted quick-union 希望平衡权重 权重可以是树的大小，也可以是树的深度。 以下考虑元素个数（树的大小） New rule（目前是不加证明的经验公式）: Always link root of smaller tree to larger tree. public class WeightedQuickUnionDS implements DisjointSets { private int[] parent; private int[] size; // size of each tree public WeightedQuickUnionDS(int N) { parent = new int[N]; size = new int[N]; // 增加了size array记录 for (int i = 0; i \u003c N; i++) { parent[i] = i; size[i] = 1; // each tree is of size 1 } } // find and isConnected are the same as before! private int find(int p) { while (p != parent[p]) p = parent[p]; // p[i] and i 很重要！ return p; } public boolean isConnected(int p, int q) { return find(p) == find(q); } public void connect(int p, int q) { int i = find(p); int j = find(q); if (size[i] \u003c size[j]) { parent[i] = j; size[j] += size[i]; // add size of i to j } else { parent[j] = i; size[i] += size[j]; // add size of j to i } } } ","date":"2024-07-13","objectID":"/61b-20/:3:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"path compression（UCB-CS170😋） 路径压缩：将树的根节点指向树的根节点，减少树的高度。 路径压缩的好处： 减少树的高度，使得find和isConnected的效率更高。 减少内存消耗。 log*(n) is the iterated log - it’s the number of times you need to apply log to n to go below 1. Note that 2^65536 is higher than the number of atoms in the universe. ","date":"2024-07-13","objectID":"/61b-20/:4:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"不加证明给出目前最极限的情况 $\\alpha(N)$ public class WeightedQuickUnionDSWithPathCompression implements DisjointSets { private int[] parent; private int[] size; public WeightedQuickUnionDSWithPathCompression(int N) { parent = new int[N]; size = new int[N]; for (int i = 0; i \u003c N; i++) { parent[i] = i; size[i] = 1; } } // find 并不会太难 乐 private int find(int p) { if (p == parent[p]) { return p; } else { parent[p] = find(parent[p]); return parent[p]; } } public boolean isConnected(int p, int q) { return find(p) == find(q); } public void connect(int p, int q) { int i = find(p); int j = find(q); if (i == j) return; if (size[i] \u003c size[j]) { parent[i] = j; size[j] += size[i]; } else { parent[j] = i; size[i] += size[j]; } } } ","date":"2024-07-13","objectID":"/61b-20/:4:1","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"references Nazca Lines: http://redicecreations.com/ul_img/24592nazca_bird.jpg Implementation code adapted from Algorithms, 4th edition and Professor Jonathan Shewchuk’s lecture notes on disjoint sets, where he presents a faster one-array solution. I would recommend taking a look. (http://www.cs.berkeley.edu/~jrs/61b/lec/33) The proof of the inverse ackermann runtime for disjoint sets is given here: http://www.uni-trier.de/fileadmin/fb4/prof/INF/DEA/Uebungen_LVA-Ankuendigungen/ws07/KAuD/effi.pdf as originally proved by Tarjan here at UC Berkeley in 1975. ","date":"2024-07-13","objectID":"/61b-20/:5:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"没有捷径，全靠仔细 for loops ","date":"2024-07-13","objectID":"/61b-18/:1:0","tags":null,"title":"61B-18: Asymptotics II","uri":"/61b-18/"},{"categories":["UCB-CS61B"],"content":"recursion 形如$\\Theta(n^k)$, $k$ 是递归的深度 ","date":"2024-07-13","objectID":"/61b-18/:2:0","tags":null,"title":"61B-18: Asymptotics II","uri":"/61b-18/"},{"categories":["UCB-CS61B"],"content":"binary search 形如$\\Theta(\\log n)$ C(N) = ⌊log2(N)⌋+1 ","date":"2024-07-13","objectID":"/61b-18/:3:0","tags":null,"title":"61B-18: Asymptotics II","uri":"/61b-18/"},{"categories":["UCB-CS61B"],"content":"merge sort 形如$\\Theta(n\\log n)$ ","date":"2024-07-13","objectID":"/61b-18/:4:0","tags":null,"title":"61B-18: Asymptotics II","uri":"/61b-18/"},{"categories":["UCB-CS61B"],"content":"Runtime Characterizations In most cases, we care only about asymptotic behavior, i.e. what happens for very large N. ","date":"2024-07-13","objectID":"/61b-17/:1:0","tags":null,"title":"61B-17: Asymptotics I","uri":"/61b-17/"},{"categories":["UCB-CS61B"],"content":"Intuitive Simplification Consider only the worst case. Restrict Attention to One Operation. 找得好并且巧的话可很快看出，退而求其次的话可以考虑画图分析 Eliminate low order terms. Eliminate multiplicative constants. ","date":"2024-07-13","objectID":"/61b-17/:2:0","tags":null,"title":"61B-17: Asymptotics I","uri":"/61b-17/"},{"categories":["UCB-CS61B"],"content":"Big-Theta Notation $\\Theta(f(n))$ The only difference is that we use the Θ symbol anywhere we would have said “order of growth”. ","date":"2024-07-13","objectID":"/61b-17/:3:0","tags":null,"title":"61B-17: Asymptotics I","uri":"/61b-17/"},{"categories":["DATA100"],"content":" # Initialize Otter import otter grader = otter.Notebook(\"lab01.ipynb\") Lab 01 Welcome to the first lab of Data 100! This lab is meant to help you familiarize yourself with JupyterHub, review Python and numpy, and introduce you to matplotlib, a Python visualization library. To receive credit for a lab, answer all questions correctly and submit before the deadline. This lab is due Tuesday, January 25 at 11:59 PM. ","date":"2024-07-13","objectID":"/datalab01/:0:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Lab Walk-Through In addition to the lab notebook, we have also released a prerecorded walk-through video of the lab. We encourage you to reference this video as you work through the lab. Run the cell below to display the video. # from IPython.display import YouTubeVideo # YouTubeVideo(\"PS7lPZUnNBo\", list = 'PLQCcNQgUcDfrhStFqvgpvLNhOS43bnSQq', listType = 'playlist') ","date":"2024-07-13","objectID":"/datalab01/:0:1","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Collaboration Policy Data science is a collaborative activity. While you may talk with others about the labs, we ask that you write your solutions individually. If you do discuss the assignments with others please include their names below. (That’s a good way to learn your classmates’ names.) Collaborators: list collaborators here ","date":"2024-07-13","objectID":"/datalab01/:0:2","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Part 1: Jupyter Tips ","date":"2024-07-13","objectID":"/datalab01/:1:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Viewing Documentation To output the documentation for a function, use the help function. # help(print) ?print \u001b[1;31mSignature:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m \u001b[1;31mDocstring:\u001b[0m Prints the values to a stream, or to sys.stdout by default. sep string inserted between values, default a space. end string appended after the last value, default a newline. file a file-like object (stream); defaults to the current sys.stdout. flush whether to forcibly flush the stream. \u001b[1;31mType:\u001b[0m builtin_function_or_method You can also use Jupyter to view function documentation inside your notebook. The function must already be defined in the kernel for this to work. Below, click your mouse anywhere on the print block below and use Shift + Tab to view the function’s documentation. print('Welcome to Data 100.') Welcome to Data 100. ","date":"2024-07-13","objectID":"/datalab01/:1:1","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Importing Libraries and Magic Commands In Data 100, we will be using common Python libraries to help us process data. By convention, we import all libraries at the very top of the notebook. There are also a set of standard aliases that are used to shorten the library names. Below are some of the libraries that you may encounter throughout the course, along with their respective aliases. import pandas as pd import numpy as np import matplotlib.pyplot as plt plt.style.use('fivethirtyeight') %matplotlib inline %matplotlib inline is a Jupyter magic command that configures the notebook so that Matplotlib displays any plots that you draw directly in the notebook rather than to a file, allowing you to view the plots upon executing your code. (Note: In practice, this is no longer necessary, but we’re showing it to you now anyway.) Another useful magic command is %%time, which times the execution of that cell. You can use this by writing it as the first line of a cell. (Note that %% is used for cell magic commands that apply to the entire cell, whereas % is used for line magic commands that only apply to a single line.) %%time lst = [] for i in range(100): lst.append(i) CPU times: total: 0 ns Wall time: 0 ns ","date":"2024-07-13","objectID":"/datalab01/:1:2","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Keyboard Shortcuts Even if you are familiar with Jupyter, we strongly encourage you to become proficient with keyboard shortcuts (this will save you time in the future). To learn about keyboard shortcuts, go to Help –\u003e Keyboard Shortcuts in the menu above. Here are a few that we like: Ctrl + Return (or Cmd + Return on Mac): Evaluate the current cell Shift + Return: Evaluate the current cell and move to the next ESC : command mode (may need to press before using any of the commands below) a : create a cell above b : create a cell below dd : delete a cell z : undo the last cell operation m : convert a cell to markdown y : convert a cell to code ","date":"2024-07-13","objectID":"/datalab01/:1:3","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Part 2: Prerequisites It’s time to answer some review questions. Each question has a response cell directly below it. Most response cells are followed by a test cell that runs automated tests to check your work. Please don’t delete questions, response cells, or test cells. You won’t get credit for your work if you do. If you have extra content in a response cell, such as an example call to a function you’re implementing, that’s fine. Also, feel free to add cells between the question cells and test cells (or the next cell, for questions without test cases). Any extra cells you add will be considered part of your submission. Finally, when you finish an assignment, make sure to “restart and run all cells” to ensure everything works properly. Note that for labs, ontime submissions that pass all the test cases will receive full credit. However for homeworks, test cells don’t always confirm that your response is correct. They are meant to give you some useful feedback, but it’s your responsibility to ensure your response answers the question correctly. There may be other tests that we run when scoring your notebooks. We strongly recommend that you check your solutions yourself rather than just relying on the test cells. ","date":"2024-07-13","objectID":"/datalab01/:2:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Python Python is the main programming language we’ll use in the course. We expect that you’ve taken CS 61A, Data 8, or an equivalent class, so we will not be covering general Python syntax. If any of the following exercises are challenging (or if you would like to refresh your Python knowledge), please review one or more of the following materials. Python Tutorial: Introduction to Python from the creators of Python. Composing Programs Chapter 1: This is more of a introduction to programming with Python. Advanced Crash Course: A fast crash course which assumes some programming background. ","date":"2024-07-13","objectID":"/datalab01/:2:1","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"NumPy NumPy is the numerical computing module introduced in Data 8, which is a prerequisite for this course. Here’s a quick recap of NumPy. For more review, read the following materials. NumPy Quick Start Tutorial DS100 NumPy Review Stanford CS231n NumPy Tutorial The Data 8 Textbook Chapter on NumPy ","date":"2024-07-13","objectID":"/datalab01/:2:2","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 1 The core of NumPy is the array. Like Python lists, arrays store data; however, they store data in a more efficient manner. In many cases, this allows for faster computation and data manipulation. In Data 8, we used make_array from the datascience module, but that’s not the most typical way. Instead, use np.array to create an array. It takes a sequence, such as a list or range. Below, create an array arr containing the values 1, 2, 3, 4, and 5 (in that order). arr = np.array([1,2,3,4,5]) grader.check(\"q1\") q1 passed! 🌟 In addition to values in the array, we can access attributes such as shape and data type. A full list of attributes can be found here. arr[3] np.int64(4) arr[2:4] # 左闭右开 array([3, 4]) arr.shape # 一维长度为5 (5,) arr.dtype dtype('int64') Arrays, unlike Python lists, cannot store items of different data types. # A regular Python list can store items of different data types [1, '3'] [1, '3'] # Arrays will convert everything to the same data type np.array([1, '3']) array(['1', '3'], dtype='\u003cU21') # Another example of array type conversion np.array([5, 8.3]) array([5. , 8.3]) Arrays are also useful in performing vectorized operations. Given two or more arrays of equal length, arithmetic will perform element-wise computations across the arrays. For example, observe the following: # Python list addition will concatenate the two lists [1, 2, 3] + [4, 5, 6] [1, 2, 3, 4, 5, 6] # NumPy array addition will add them element-wise np.array([1, 2, 3]) + np.array([4, 5, 6]) array([5, 7, 9]) ","date":"2024-07-13","objectID":"/datalab01/:2:3","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 2 Question 2a Write a function summation that evaluates the following summation for $n \\geq 1$: $$\\sum_{i=1}^{n} i^3 + 3 i^2$$ Note: You should not use for loops in your solution. Check the NumPy documentation. If you’re stuck, try a search engine! Searching the web for examples of how to use modules is very common in data science. # 用好np向量化 def summation(n): \"\"\"Compute the summation i^3 + 3 * i^2 for 1 \u003c= i \u003c= n.\"\"\" arr = np.arange(1, n+1) newArr = arr**3 + 3 * arr**2 return int(np.sum(newArr)) grader.check(\"q2a\") q2a passed! 💯 Question 2b Write a function elementwise_array_sum that computes the square of each value in list_1, the cube of each value in list_2, then returns a list containing the element-wise sum of these results. Assume that list_1 and list_2 have the same number of elements, do not use for loops. The input parameters will both be python lists, so you may need to convert the lists into arrays before performing your operations. The output should be a numpy array. def elementwise_array_sum(list_1, list_2): \"\"\"Compute x^2 + y^3 for each x, y in list_1, list_2. Assume list_1 and list_2 have the same length. Return a NumPy array. \"\"\" assert len(list_1) == len(list_2), \"both args must have the same number of elements\" # create a NumPy array from the two lists arr1 = np.array(list_1) arr2 = np.array(list_2) arr_sum = arr1 ** 2 + arr2 ** 3 return arr_sum grader.check(\"q2b\") q2b passed! 🌟 You might have been told that Python is slow, but array arithmetic is carried out very fast, even for large arrays. Below is an implementation of the above code that does not use NumPy arrays. def elementwise_list_sum(list_1, list_2): \"\"\"Compute x^2 + y^3 for each x, y in list_1, list_2. Assume list_1 and list_2 have the same length. \"\"\" return [x ** 2 + y ** 3 for x, y in zip(list_1, list_2)] For ten numbers, elementwise_list_sum and elementwise_array_sum both take a similar amount of time. sample_list_1 = list(range(10)) sample_array_1 = np.arange(10) %%time elementwise_list_sum(sample_list_1, sample_list_1) CPU times: total: 0 ns Wall time: 0 ns [0, 2, 12, 36, 80, 150, 252, 392, 576, 810] %%time elementwise_array_sum(sample_array_1, sample_array_1) CPU times: total: 0 ns Wall time: 0 ns array([ 0, 2, 12, 36, 80, 150, 252, 392, 576, 810]) The time difference seems negligible for a list/array of size 10; depending on your setup, you may even observe that elementwise_list_sum executes faster than elementwise_array_sum! However, we will commonly be working with much larger datasets: sample_list_2 = list(range(100000)) sample_array_2 = np.arange(100000) %%time elementwise_list_sum(sample_list_2, sample_list_2) ; # The semicolon hides the output CPU times: total: 15.6 ms Wall time: 33.2 ms %%time elementwise_array_sum(sample_array_2, sample_array_2) CPU times: total: 0 ns Wall time: 557 μs array([ 0, 2, 12, ..., 999920002099982, 999950000799996, 999980000100000]) With the larger dataset, we see that using NumPy results in code that executes over 50 times faster! Throughout this course (and in the real world), you will find that writing efficient code will be important; arrays and vectorized operations are the most common way of making Python programs run quickly. Question 2c Recall the formula for population variance below: $$\\sigma^2 = \\frac{\\sum_{i=1}^N (x_i - \\mu)^2}{N}$$ Complete the functions below to compute the population variance of population, an array of numbers. For this question, do not use built in NumPy functions, such as np.var. Again, avoid using for loops! def mean(population): \"\"\" Returns the mean of population (mu) Keyword arguments: population -- a numpy array of numbers \"\"\" # Calculate the mean of a population return sum(population)/float(len(population)) def variance(population): \"\"\" Returns the variance of population (sigma squared) Keyword arguments: population -- a numpy array of numbers \"\"\" # Calculate the variance of a population mu = mean(population) return sum((population-mu) ** 2)/float(len(populati","date":"2024-07-13","objectID":"/datalab01/:2:4","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Part 3: Plotting Here we explore plotting using matplotlib and numpy. ","date":"2024-07-13","objectID":"/datalab01/:3:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 3 Consider the function $f(x) = x^2$ for $-\\infty \u003c x \u003c \\infty$. Question 3a Find the equation of the tangent line to $f$ at $x = 0$. Use LaTeX to type your solution, such that it looks like the serif font used to display the math expressions in the sentences above. HINT: You can click any text cell to see the raw Markdown syntax. $tangent line: 切线$ $y = 0$ Question 3b Find the equation of the tangent line to $f$ at $x = 8$. Please use LaTeX to type your solution. $y = 16x$ Question 3c Write code to plot the function $f$, the tangent line at $x=8$, and the tangent line at $x=0$. Set the range of the x-axis to (-15, 15) and the range of the y-axis to (-100, 300) and the figure size to (4,4). Your resulting plot should look like this (it’s okay if the colors in your plot don’t match with ours, as long as they’re all different colors): You should use the plt.plot function to plot lines. You may find the following functions useful: plt.plot(..) plt.figure(figsize=..) plt.ylim(..) plt.axhline(..) def f(x): return x ** 2 def df(x): return 2*x def plot(f, df): plt.figure(figsize=(4, 4)) x = np.array([-15, 15]) plt.plot(x,f(x),color='blue') plt.plot(x,df(x),color='green') plt.axhline(0,color='red') plt.ylim(-100, 300) plot(f, df) ","date":"2024-07-13","objectID":"/datalab01/:3:1","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 4 (Ungraded) Data science is a rapidly expanding field and no degree program can hope to teach you everything that will be helpful to you as a data scientist. So it’s important that you become familiar with looking up documentation and learning how to read it. Below is a section of code that plots a three-dimensional “wireframe” plot. You’ll see what that means when you draw it. Replace each # Your answer here with a description of what the line above does, what the arguments being passed in are, and how the arguments are used in the function. For example, np.arange(2, 5, 0.2) # This returns an array of numbers from 2 to 5 with an interval size of 0.2 Hint: The Shift + Tab tip from earlier in the notebook may help here. Remember that objects must be defined in order for the documentation shortcut to work; for example, all of the documentation will show for method calls from np since we’ve already executed import numpy as np. However, since z is not yet defined in the kernel, z.reshape(x.shape) will not show documentation until you run the line z = np.cos(squared). from mpl_toolkits.mplot3d import axes3d u = np.linspace(1.5 * np.pi, -1.5 * np.pi, 100) # Your answer here [x, y] = np.meshgrid(u, u) # Your answer here squared = np.sqrt(x.flatten() ** 2 + y.flatten() ** 2) z = np.cos(squared) # Your answer here z = z.reshape(x.shape) # Your answer here fig = plt.figure(figsize = (6, 6)) ax = fig.add_subplot(111, projection = '3d') # Your answer here ax.plot_wireframe(x, y, z, rstride = 5, cstride = 5, lw = 2) # Your answer here ax.view_init(elev = 60, azim = 25) # Your answer here plt.savefig(\"figure1.png\") # Your answer here ","date":"2024-07-13","objectID":"/datalab01/:3:2","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 5 (Ungraded) Do you think that eating french fries with mayonnaise is a crime? Tell us what you think in the following Markdown cell. :) 6 注意numpy版本并不是一一对应，返回种类发生变化 To double-check your work, the cell below will rerun all of the autograder tests. grader.check_all() q1 results: All test cases passed! q2a results: All test cases passed! q2b results: All test cases passed! q2c results: q2c - 1 result: ❌ Test case failed Trying: population_0 = np.random.randn(100) Expecting nothing ok Trying: np.isclose(mean(population_0), np.mean(population_0), atol=1e-6) Expecting: True ********************************************************************** Line 2, in q2c 0 Failed example: np.isclose(mean(population_0), np.mean(population_0), atol=1e-6) Expected: True Got: np.True_ q2c - 2 result: ❌ Test case failed Trying: population_0 = np.random.randn(100) Expecting nothing ok Trying: np.isclose(variance(population_0), np.var(population_0), atol=1e-6) Expecting: True ********************************************************************** Line 2, in q2c 1 Failed example: np.isclose(variance(population_0), np.var(population_0), atol=1e-6) Expected: True Got: np.True_ q2d results: All test cases passed! ","date":"2024-07-13","objectID":"/datalab01/:3:3","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Submission Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. Please save before exporting! # Save your notebook first, then run this cell to export your submission. grader.export(pdf=False) ","date":"2024-07-13","objectID":"/datalab01/:4:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"two common errors chance error: randomness can vary bias error: systematic error in one direction ","date":"2024-07-13","objectID":"/datal2/:1:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["DATA100"],"content":"bias ","date":"2024-07-13","objectID":"/datal2/:2:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["DATA100"],"content":"common non-random samples convenience samples: samples that are easy to obtain but may not be representative of the population quota samples: samples that are drawn from a limited number of individuals or groups ","date":"2024-07-13","objectID":"/datal2/:3:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["DATA100"],"content":"random samples random can produce biases but we can estimate the bias and chance error properties of random samples: 明确概率 no need to be same chance 😋 scheme of random sampling: “Random sample with replacement” 是统计学中的一个术语，指的是在进行抽样时，每次抽取的样本在放回原总体之后，再进行下一次抽取。这意味着同一个个体或元素有可能被多次抽取。 这种抽样方法的特点包括： 每次抽取都是独立的，即前一次的抽取结果不会影响后一次的抽取。 总体中的每个元素在每次抽取中被选中的概率是相同的。 由于样本被放回，样本的大小可以等于或小于总体的大小。 与之相对的是 “Random sample without replacement”，即不放回抽样，这种情况下，一旦一个元素被抽取，它就不会再次被抽取，因此抽取的样本量总是小于总体的大小。😉 SRS：🤔注意是每个\"pair\"！ ","date":"2024-07-13","objectID":"/datal2/:4:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["DATA100"],"content":"多项式和二项式分布采样 ","date":"2024-07-13","objectID":"/datal2/:5:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["NNDL"],"content":"neuronal networks and deep learning… coming soon ","date":"2024-07-12","objectID":"/nndl/:0:0","tags":null,"title":"NNDL0","uri":"/nndl/"},{"categories":["CSIEC"],"content":"COLLEGE STUDENTS INNOVATION AND ENTREPRENEURSHIP COMPETITION (CSIEC) ","date":"2024-07-12","objectID":"/experiences/csiec/csiec0/:0:0","tags":null,"title":"CSIEC0","uri":"/experiences/csiec/csiec0/"},{"categories":["DATA100"],"content":"cycle of data science ","date":"2024-07-12","objectID":"/datal1/:1:0","tags":null,"title":"DATA100-L1: course overview","uri":"/datal1/"},{"categories":["UCB-CS61B"],"content":"math problems $$ N! ∈ \\Omega (N^{N}) ? $$ √ $$ log(N!) ∈ \\Omega (NlogN) ? $$ √ $$ NlogN∈ \\Omega (log(N!)) ? $$ √ 所以可以推出： $$ NlogN ∈ \\Theta (logN!) $$ $$ log(N!) ∈ \\Theta (NlogN) $$ ","date":"2024-07-11","objectID":"/61b-35/:1:0","tags":null,"title":"61B-35","uri":"/61b-35/"},{"categories":["UCB-CS61B"],"content":"TUCS用时 上下界？ the ultimate comparison sort run time $$ \\Omega(NlogN) $$ $$ O(NlogN) $$ 下面开始证明： 考虑下界，对n个物体进行排序，有N！种可能，用两两比大小，考虑决策树的高度$$ H = \\log_2 N! $$ 因此下界为 $$ \\Omega (log(N!)) $$ 或者 $$ \\Omega (NlogN) $$ 上界通过TUCS的性质可以通过具体示例反证得到，比如用merge sort ","date":"2024-07-11","objectID":"/61b-35/:2:0","tags":null,"title":"61B-35","uri":"/61b-35/"},{"categories":["UCB-CS61B"],"content":"More quick sort, Stability, Shuffling ","date":"2024-07-11","objectID":"/61b-34/:0:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"quick sort VS merge sort QuicksortL3S = left + 3-scan + shuffle Quicksort_LTHS: Tony Hoare partition scheme: L ptr 仅仅指向小的 G ptr 仅仅指向大的 ptr walk towards to each other, stopping on a hated item 两个都停下来的话， 交换一下， 然后移动其中一个 when ptrs cross, done. 和G交换pivot ","date":"2024-07-11","objectID":"/61b-34/:1:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"Not random smarter pivot selection: median Quicksort_PickTH 考虑了如何计算数组地址的复杂度， 以及如何选择pivot的复杂度。 worst case: $$ \\Theta(NlogN) $$ 但实际上并没有那么好，因为计算中位数的复杂度是$$\\Theta(N)$$。耗费了更多时间。 ","date":"2024-07-11","objectID":"/61b-34/:2:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"quick select–using partitioning worst case: a sorted array $$ \\Theta(N^2) $$ on average: $$ N + N/2 + N/4 +… + 1 = \\Theta(N) $$ ","date":"2024-07-11","objectID":"/61b-34/:3:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"stability for stable sort, we need to keep the relative order of equal elements Is insertion sort stable? yes, it is stable. Is quick sort stable? depends on the partitioning scheme. ","date":"2024-07-11","objectID":"/61b-34/:4:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"adaptive array.sort() is adaptive 查看java官方文档 ","date":"2024-07-11","objectID":"/61b-34/:5:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"shuffling random number and then sort ","date":"2024-07-11","objectID":"/61b-34/:6:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"信息无损性 模糊性 ","date":"2024-07-11","objectID":"/61b-38/:0:0","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"prefix-free codes ","date":"2024-07-11","objectID":"/61b-38/:1:0","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"Huffman codes ","date":"2024-07-11","objectID":"/61b-38/:1:1","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"shannon-fano codes using tries to convert compressed data into a original data longest prefix matching ","date":"2024-07-11","objectID":"/61b-38/:1:2","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"self-extracting bits ","date":"2024-07-11","objectID":"/61b-38/:2:0","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"Overview ","date":"2024-07-11","objectID":"/61b-37/:1:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"Tries——前缀树/字典树 usages: prefix matching approximate matching keysWithPrefix(String prefix) // returns all keys in the trie that start with the given prefix longestPrefixOf(String query) // returns the longest key in the trie that is a prefix of the query ","date":"2024-07-11","objectID":"/61b-37/:2:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"implementation private class Node{ boolean exists; Map\u003cCharacter, Node\u003e links; public Node(){ links = new TreeMap\u003c\u003e(); exists = false; } } ","date":"2024-07-11","objectID":"/61b-37/:3:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"T9 keyboard ","date":"2024-07-11","objectID":"/61b-37/:4:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"Ternary search Tries public class TSTSet\u003cValue\u003e{ private Node\u003cValue\u003e root; private static class Node\u003cValue\u003e{ private char c; private Node\u003cValue\u003e lo, mid, hi; } } 但是这种实现方式表现不佳 ","date":"2024-07-11","objectID":"/61b-37/:5:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"radix sort 不用comparisons的排序算法，时间复杂度O(dn)，d为最大数的位数，n为待排序数的个数。 空间换时间 bucket sort counting sort: 找出待排序数的最大值max，确定计数数组的长度为max+1。 遍历待排序数，将每个数的个位数值作为索引，将该索引对应的计数数组元素加1。 遍历计数数组，将每个元素的值作为索引，将该索引对应的元素值输出到结果数组中。 runtime: O(n+k) LSD radix sort: least significant digit radix sort 找出待排序数的最大值max，确定计数数组的长度为10。 遍历待排序数，将每个数的个位数值作为索引，将该索引对应的计数数组元素加1。 LSD sort vs merge sort: similar strings:LSD sort is better dissimilar strings:merge sort is better MSD radix sort: most significant digit radix sort 找出待排序数的最大值max，确定计数数组的长度为10。 遍历待排序数，将每个数的个位数值作为索引，将该索引对应的计数数组元素加1。 遍历计数数组，将每个元素的值作为索引，将该索引对应的元素值输出到结果数组中。 runtime: O(n+k) ","date":"2024-07-10","objectID":"/61b-36/:0:0","tags":null,"title":"61B-36","uri":"/61b-36/"},{"categories":["TOOLS"],"content":"文件状态 未跟踪-未修改-已修改-暂存 git add \u003cname\u003e - *-\u003e暂存 git commit -m \"message\" - 暂存-\u003e未修改 git rm \u003cname\u003e - 未修改-\u003e未跟踪 ","date":"2024-06-29","objectID":"/tools/git/git/:1:0","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"查看状态 git status 更加细致几行几列 git diff 查看历史日志 git log --pretty=oneline git log --graph --oneline --decorate ","date":"2024-06-29","objectID":"/tools/git/git/:1:1","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"基本操作 ","date":"2024-06-29","objectID":"/tools/git/git/:2:0","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"基础配置 git config --global user.name \"your name\" git config --global user.email \"your email\" ","date":"2024-06-29","objectID":"/tools/git/git/:2:1","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"创建版本库 mkdir myproject cd myproject git init ","date":"2024-06-29","objectID":"/tools/git/git/:2:2","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"克隆版本库 git clone https://github.com/username/repository.git ","date":"2024-06-29","objectID":"/tools/git/git/:2:3","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"跟踪文件or文件夹 git add \u003cfilename\u003e git rm \u003cfilename\u003e git rm --cache \u003cfilename\u003e ","date":"2024-06-29","objectID":"/tools/git/git/:2:4","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"设置缓存状态 git add git reset HEAD \u003cfilename\u003e ","date":"2024-06-29","objectID":"/tools/git/git/:2:5","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"提交修改 git commit -m \"commit message str\" 撤销非首次修改 git reset head~ --soft ","date":"2024-06-29","objectID":"/tools/git/git/:2:6","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"和github联系 git remote add origin https://github.com/username/repository.git git remote git remote rename origin old_name 推到远程仓库 git push origin master ssh连接？ ","date":"2024-06-29","objectID":"/tools/git/git/:2:7","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"分支管理 创建分支 git branch --list git branch hhzz git checkout hhzz git checkout -b hhzz 合并分支 git merge hhzz 删除分支 git branch -d hhzz ","date":"2024-06-29","objectID":"/tools/git/git/:2:8","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"贮藏功能 stash 待施工 ","date":"2024-06-29","objectID":"/tools/git/git/:2:9","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"重置、换基功能 待施工 ","date":"2024-06-29","objectID":"/tools/git/git/:2:10","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"Regular Expressions ","date":"2024-06-29","objectID":"/tools/reg/:0:0","tags":null,"title":"正则表达式笔记","uri":"/tools/reg/"},{"categories":["TOOLS"],"content":"注意版本和文档！ ","date":"2024-06-29","objectID":"/tools/reg/:1:0","tags":null,"title":"正则表达式笔记","uri":"/tools/reg/"},{"categories":["TOOLS"],"content":"常用工具 https://regex101.com/ https://regexr.com/ python re模块 字符 . 匹配任意一个字符 [] 匹配括号中的任意一个字符,如 [a-zA-Z1-3] 匹配大写字母或小写字母或数字1-3, [^] 匹配除了括号中的字符 预定字符类 \\d 匹配数字 \\D 匹配非数字 \\w 匹配字母、数字或下划线 \\W 匹配非字母、数字或下划线 \\s 匹配空白字符或者tab \\S 匹配非空白字符 边界匹配 ^ 匹配字符串的开头 $ 匹配字符串的结尾 \\b 匹配单词的边界, 如 \\bthe\\b 匹配the \\B 匹配非单词边界 数量词 * 匹配前面的字符0次或多次 + 匹配前面的字符1次或多次 ? 匹配前面的字符0次或1次 {n} 匹配前面的字符n次 {n,} 匹配前面的字符至少n次 {n,m} 匹配前面的字符至少n次, 至多m次 非贪婪匹配 量词默认是贪婪匹配, 即尽可能多的匹配字符, 如 a.*b 会匹配到最长的以a开头的b 后面的量词加上? 则为非贪婪匹配, 即尽可能少的匹配字符, 如 a.*?b 会匹配到最短的以a开头的b 分组与捕获 () 用来创建分组, 捕获括号中的字符, 并在匹配时返回匹配到的内容 [] 用来创建字符类, 如 [Pp] 匹配P或p | 用来创建或关系, 如 a(bc|de) 匹配a后面是bc或de \\n 引用分组, 如 \\1 引用第一个分组 $n 引用第n个分组 ?: 非捕获分组, 如 (?:abc) 匹配abc, 不捕获匹配到的内容 前瞻和后顾 正向前瞻 (?=abc) 匹配abc前面的字符 反向前瞻 (?!abc) 匹配abc前面的字符 正向后顾 (?\u003c=abc) 匹配abc后面的字符 反向后顾 (?\u003c!abc) 匹配abc后面的字符 ","date":"2024-06-29","objectID":"/tools/reg/:2:0","tags":null,"title":"正则表达式笔记","uri":"/tools/reg/"},{"categories":["PRP"],"content":"PRP系列将用于记录研究项目，包括但不限于课题、研究方法、研究成果、研究心得、研究经验、研究心路历程等。 ","date":"2024-05-21","objectID":"/experiences/prp/prp0/:0:0","tags":null,"title":"PRP0","uri":"/experiences/prp/prp0/"},{"categories":["C++"],"content":"learning pointer(advanced version) 为了防止搞混而写 ","date":"2024-05-05","objectID":"/crash/cpp1/:0:0","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"下标为0?首地址? void test0(){ int arr[] = {1, 2, 3}; cout \u003c\u003c \u0026arr[0] \u003c\u003c endl; cout \u003c\u003c \u0026arr \u003c\u003c endl; cout \u003c\u003c arr \u003c\u003c endl; } arr \u0026arr \u0026arr[0] 存储的都是相同的地址 arr 常量指针不能被改变 ","date":"2024-05-05","objectID":"/crash/cpp1/:0:1","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"指向数组元素的指针(不一定是首元素)以用[]来访问数组元素 void test2() { int a[3] = {1,2,3}; int *p = a; p++; cout \u003c\u003c p[0] \u003c\u003c endl; // 2 } ","date":"2024-05-05","objectID":"/crash/cpp1/:0:2","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"数组类型的指针 void test2(){ int arr[] = {1, 2, 3}; int (*p)[] = \u0026arr; // 定义一个指向数组的指针 cout \u003c\u003c (*p)[0] \u003c\u003c endl; // 输出数组首地址 cout \u003c\u003c p[0] \u003c\u003c endl; // 输出数组首地址 cout \u003c\u003c p[0][0] \u003c\u003c endl; // 输出数组首元素 } int *p[] = \u0026arr vs int (*p)[] = \u0026arr???? [ ]优先级高于* int (*p)[] = \u0026arr; *p --\u003e 一个指针 （*p）[] --\u003e 指向数组的指针 int (*p)[] --\u003e 指向的数组的元素是int类型 p = \u0026arr 定义了一个指向数组的指针，(*p) = arr 解引用指针得到数组首地址，(*p)[0] = arr[0] 访问数组首元素 p[0] = arr 访问数组首地址，p[0][0] = arr[0] 访问数组首元素 ","date":"2024-05-05","objectID":"/crash/cpp1/:0:3","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"那么int *(*p)[] = { };水到渠成了 ","date":"2024-05-05","objectID":"/crash/cpp1/:0:4","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"内存映像图 内存映像图 1 2 … 内存地址从上往下递增 和CSAPP里面的栈画法有点不一样 ","date":"2024-05-05","objectID":"/crash/cpp1/:0:5","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"delete 申请一个连续的内存块，然后将其视为二维数组： int** arr = new int*[rows]; for (int i = 0; i \u003c rows; ++i) { arr[i] = new int[cols]; } 释放时，你需要先释放每一行的内存，然后释放行指针数组： for (int i = 0; i \u003c rows; ++i) { delete[] arr[i]; } delete[] arr; 申请一个足够大的连续内存块，然后将其视为二维数组： int* arr = new int[rows * cols]; 在这种情况下，你只需要释放一次： delete[] arr; 注意，这种方式下，arr实际上是一个一维数组，但是你可以像访问二维数组一样使用它（例如，arr[i][j]实际上是arr[i * cols + j]）。 确保在释放内存后将指针设置为nullptr，以避免悬垂指针问题： delete[] arr; arr = nullptr; // 或者使用智能指针自动管理内存 ","date":"2024-05-05","objectID":"/crash/cpp1/:0:6","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"char? int main() { char **p, *city[] = {\"aaa\",\"bbb\"}; for (p = city; p \u003c city + 2; ++p) { cout \u003c\u003c *p \u003c\u003c endl; } return 0; } 结果为： aaa bbb ","date":"2024-05-05","objectID":"/crash/cpp1/:0:7","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["csapp"],"content":"实验一：栈溢出攻击实验 ","date":"2024-04-22","objectID":"/csapp_attacklab/:1:0","tags":null,"title":"CSAPP_attacklab","uri":"/csapp_attacklab/"},{"categories":["csapp"],"content":"栈的基本结构 ","date":"2024-04-22","objectID":"/csapp_attacklab/:1:1","tags":null,"title":"CSAPP_attacklab","uri":"/csapp_attacklab/"},{"categories":["csapp"],"content":"实验二：ROP攻击实验 ","date":"2024-04-22","objectID":"/csapp_attacklab/:2:0","tags":null,"title":"CSAPP_attacklab","uri":"/csapp_attacklab/"},{"categories":["csapp"],"content":"csapp_bomblab 都是汇编语言，没有什么好说的 注意GDB调试 ","date":"2024-04-22","objectID":"/csapp_bomblab/:0:0","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["csapp"],"content":"核心概念之一：寻址 如何寻址？ $Imm(r_1,r_2,factor)$ 注意值还是地址？ (%rdx)取memory时，$M[R_i]$ 中M一直在最外层 ","date":"2024-04-22","objectID":"/csapp_bomblab/:1:0","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["csapp"],"content":"核心概念之二：GDB调试 ","date":"2024-04-22","objectID":"/csapp_bomblab/:2:0","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["csapp"],"content":"常用命令 run 运行程序（注意结合数据流pipeline） b +$Addr$ 设置断点 delete 删除断点 next 单步执行 step stepi``finish进入函数 p $eax 打印变量 x /$nxb $Addr$ 打印内存 layout asm 切换到汇编模式有好看的窗口 info registers 打印寄存器 info frame 打印栈帧 info args 打印函数参数 info locals 打印局部变量 info breakpoints 打印断点信息 continue 继续运行 quit stop退出调试 ","date":"2024-04-22","objectID":"/csapp_bomblab/:2:1","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["csapp"],"content":"一些些技巧 mov一些奇奇怪怪的地址时，很可能是线索，可以用x /$nxb $Addr$查看内存 jne之类的能不能直接取等擦边通过 常见的基础语句（条件/循环）有一些固定的范式，可以用x /6i $PC等查看指令 ","date":"2024-04-22","objectID":"/csapp_bomblab/:3:0","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["CSAPP"],"content":"int bit-level operations ","date":"2024-04-21","objectID":"/csapp_datalab/:1:0","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"德摩根律（位运算和集合论） 与：\u0026 非：~ 两者组合已经可以表示四个基本运算：与、非、或、异或。 ","date":"2024-04-21","objectID":"/csapp_datalab/:1:1","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"移动位运算 注意是否为无符号数，有符号数的移位运算规则与无符号数不同。 有符号数的移位运算规则： 左移：符号位不变，右边补0。 右移：符号位不变，左边补符号位。 无符号数的移位运算规则： 左移：左边补0。 右移：右边补0。 ","date":"2024-04-21","objectID":"/csapp_datalab/:1:2","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"与运算（\u0026）取特定的位数，用于位层面条件判断 ","date":"2024-04-21","objectID":"/csapp_datalab/:1:3","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"减法的实现 A + ~A = -1 –\u003e A + (~A+1) = 0 ","date":"2024-04-21","objectID":"/csapp_datalab/:1:4","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"减法的描述范围问题 做差取符号位 ","date":"2024-04-21","objectID":"/csapp_datalab/:1:5","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"掩码操作 int conditional(int x, int y, int z) { int exp1 = ~(!!x) + 1; int exp2 = ~(!x) + 1; return (exp1\u0026y) + (exp2\u0026z); } ","date":"2024-04-21","objectID":"/csapp_datalab/:1:6","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"位层面分类讨论 /* howManyBits - return the minimum number of bits required to represent x in * two's complement(补码系统) * Examples: howManyBits(12) = 5 * howManyBits(298) = 10 * howManyBits(-5) = 4 负数的话 取反 同理 * howManyBits(0) = 1 * howManyBits(-1) = 1 特殊点? * howManyBits(0x80000000) = 32 * Legal ops: ! ~ \u0026 ^ | + \u003c\u003c \u003e\u003e * Max ops: 90 * Rating: 4 */ int howManyBits(int x) { // 取为正数操作 int flag = x \u003e\u003e 31; x = (~flag \u0026 x) + (flag \u0026 (~x)); // 掩码分类思想 // 0000 0100 0000 0000 0000 0000 0000 0000 // Flag_i = !!(x \u003e\u003e i) int bit16 = !!(x \u003e\u003e 16) \u003c\u003c 4; // log2 N x \u003e\u003e= bit16; // \u003e\u003e= 右移赋值运算符 int bit8 = !!(x \u003e\u003e 8) \u003c\u003c 3; x \u003e\u003e= bit8; int bit4 = !!(x \u003e\u003e 4) \u003c\u003c 2; x \u003e\u003e= bit4; int bit2 = !!(x \u003e\u003e 2) \u003c\u003c 1; x \u003e\u003e= bit2; int bit1 = !!(x \u003e\u003e 1) \u003c\u003c 0; x \u003e\u003e= bit1; int bit0 = x; // x = 1 return (bit0+bit1+bit2+bit4+bit8+bit16) + 1; } ","date":"2024-04-21","objectID":"/csapp_datalab/:1:7","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"float bit-level operations $$ float = (-1)^s * M * 2^E $$ ","date":"2024-04-21","objectID":"/csapp_datalab/:2:0","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"float to binary sign bit: $s$ exponent bits: $E$ —\u003e $E = e - 127$ mantissa bits: $M$—\u003efrac add $1$ and $0$ to the left until $M$ has 23 bits ","date":"2024-04-21","objectID":"/csapp_datalab/:2:1","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"}]