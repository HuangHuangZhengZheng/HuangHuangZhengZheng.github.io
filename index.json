[{"categories":["DATA100"],"content":"Discussion 2: Pandas Practice We will begin our discussion of Pandas. You will practice: Selecting columns Filtering with boolean conditions Counting with value_counts import pandas as pd import numpy as np ","date":"2024-07-15","objectID":"/datadisc02/:0:0","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Pandas Practise In the first Pandas question, we will be working with the elections dataset from lecture. elections = pd.read_csv(\"elections.csv\") # read in the elections data into a pandas dataframe! elections.head(5) Year Candidate Party Popular vote Result % 0 1824 Andrew Jackson Democratic-Republican 151271 loss 57.210122 1 1824 John Quincy Adams Democratic-Republican 113142 win 42.789878 2 1828 Andrew Jackson Democratic 642806 win 56.203927 3 1828 John Quincy Adams National Republican 500897 loss 43.796073 4 1832 Andrew Jackson Democratic 702735 win 54.574789 ","date":"2024-07-15","objectID":"/datadisc02/:1:0","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 5 We want to select the ‚ÄúPopular vote‚Äù column as a pd.Series. Which of the following lines of code will error? elections['Popular vote'] elections.iloc['Popular vote'] elections.loc['Popular vote'] elections.loc[:, 'Popular vote'] elections.iloc[:, 'Popular vote'] Run each line in the cell below and see for yourself! # elections.iloc['Popular vote'] # wrong # elections.iloc[:, 'popular votes'] # wrong # elections['Popular vote'] # right # elections.loc['Popular vote'] # ket error # elections.loc[:,'Popular vote'] # right 0 151271 1 113142 2 642806 3 500897 4 702735 ... 173 62984828 174 732273 175 4489235 176 65853514 177 1457226 Name: Popular vote, Length: 178, dtype: int64 ","date":"2024-07-15","objectID":"/datadisc02/:1:1","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 6 Write one line of Pandas code that returns a pd.DataFrame that only contains election results from the 1900s. elections[(elections['Year'] \u003e= 1900) \u0026 (elections['Year'] \u003c 2000)] # Ê≥®ÊÑèÊòØ \u0026 Year Candidate Party Popular vote Result % 54 1900 John G. Woolley Prohibition 210864 loss 1.526821 55 1900 William Jennings Bryan Democratic 6370932 loss 46.130540 56 1900 William McKinley Republican 7228864 win 52.342640 57 1904 Alton B. Parker Democratic 5083880 loss 37.685116 58 1904 Eugene V. Debs Socialist 402810 loss 2.985897 ... ... ... ... ... ... ... 146 1996 Harry Browne Libertarian 485759 loss 0.505198 147 1996 Howard Phillips Taxpayers 184656 loss 0.192045 148 1996 John Hagelin Natural Law 113670 loss 0.118219 149 1996 Ralph Nader Green 685297 loss 0.712721 150 1996 Ross Perot Reform 8085294 loss 8.408844 97 rows √ó 6 columns ","date":"2024-07-15","objectID":"/datadisc02/:1:2","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 7 Write one line of Pandas code that returns a pd.Series, where the index is the Party, and the values are how many times that party won an election. Hint: use value_counts. # Your answer here elections['Party'].value_counts() Party Democratic 46 Republican 40 Prohibition 11 Libertarian 11 Socialist 10 Independent 6 Whig 6 Green 6 Progressive 4 Populist 3 Constitution 3 American Independent 3 American 2 National Republican 2 Democratic-Republican 2 Reform 2 Free Soil 2 Anti-Masonic 1 National Union 1 Constitutional Union 1 National Democratic 1 Union Labor 1 Greenback 1 Anti-Monopoly 1 Liberal Republican 1 Southern Democratic 1 Northern Democratic 1 Farmer‚ÄìLabor 1 Dixiecrat 1 States' Rights 1 Communist 1 Union 1 Taxpayers 1 New Alliance 1 Citizens 1 Natural Law 1 Name: count, dtype: int64 ","date":"2024-07-15","objectID":"/datadisc02/:1:3","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Grading Assistance (Bonus) Fernando is writing a grading script to compute grades for students in Data 101. Recall that many factors go into computing a student‚Äôs final grade, including homework, discussion, exams, and labs. In this question, we will help Fernando compute the homework grades for all students using a DataFrame, hw_grades, provided by Gradescope. The Pandas DataFrame hw_grades contains homework grades for all students for all homework assignments, with one row for each combination of student and homework assignment. Any assignments that are incomplete are denoted by NaN (missing) values, and any late assignments are denoted by a True boolean value in the Late column. You may assume that the names of students are unique. Below is a sample of hw_grades. hw_grades = pd.read_csv(\"hw_grades.csv\") hw_grades.sample(5, random_state = 0) Name Assignment Grade Late 28 Sid Homework 9 82.517998 True 11 Ash Homework 2 78.264844 True 10 Ash Homework 1 98.421049 False 41 Emily Homework 2 62.900313 False 2 Meg Homework 3 89.785619 False ","date":"2024-07-15","objectID":"/datadisc02/:2:0","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 8a Assuming there is a late penalty that causes a 10% grade reduction to the student‚Äôs current score (i.e. a 65% score would become a 65% - 6.5% = 58.5%), write a line of Pandas code to calculate all the homework grades, including the late penalty if applicable, and store it in a column named ‚ÄôLPGrade‚Äô. # Your answer here hw_grades['LPGrade'] = hw_grades['Grade'] * (1 - hw_grades['Late'] * 0.1) # Áî®‰∏™ÈöêÂºèËΩ¨Êç¢ hw_grades.head() Name Assignment Grade Late LPGrade 0 Meg Homework 1 NaN False NaN 1 Meg Homework 2 64.191844 False 64.191844 2 Meg Homework 3 89.785619 False 89.785619 3 Meg Homework 4 74.420033 False 74.420033 4 Meg Homework 5 74.372434 True 66.935190 ","date":"2024-07-15","objectID":"/datadisc02/:2:1","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 8b Which of the following expressions outputs the students‚Äô names and number of late assignments, from least to greatest number of late assignments? hw_grades.groupby([‚ÄôName‚Äô]).sum().sort_values() hw_grades.groupby([‚ÄôName‚Äô, ‚ÄôLate‚Äô]).sum().sort_values() hw_grades.groupby([‚ÄôName‚Äô]).sum()[‚ÄôLate‚Äô].sort_values() hw_grades.groupby([‚ÄôName‚Äô]).sum().sort_values()[‚ÄôLate‚Äô] # Your answer here # hw_grades.groupby(['Name']).sum().sort_values() # \u003c---- Try to sort on df, but have to give 'by=...' into sort_values() hw_grades.groupby(['Name']).sum()['Late'].sort_values() Name Sid 1 Emily 2 Meg 2 Ash 3 Smith 3 Name: Late, dtype: int64 ","date":"2024-07-15","objectID":"/datadisc02/:2:2","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 8c If each assignment is weighted equally, fill in the blanks below to calculate each student‚Äôs overall homework grade, including late penalties for any applicable assignments. Hint: Recall that incomplete assignments have NaN values. How can we use fillna to replace these null values? hw_grades._________(_______) \\ .groupby(___________)[____________] \\ .agg(____________) # Your answer here hw_grades.fillna(0)\\ .groupby(['Name'])['LPGrade']\\ .agg('mean') # Python‰∏≠ÔºåÂèçÊñúÊù† \\ Áî®‰ΩúË°åÁª≠Â≠óÁ¨¶ÔºåÂÆÉÂÖÅËÆ∏‰Ω†Â∞Ü‰∏ÄË°å‰ª£Á†ÅÂàÜÂâ≤ÊàêÂ§öË°åÔºå‰ª•ÊèêÈ´ò‰ª£Á†ÅÁöÑÂèØËØªÊÄß„ÄÇËøôÂú®ÁºñÂÜôËæÉÈïøÁöÑ‰∏ÄË°å‰ª£Á†ÅÊó∂ÁâπÂà´ÊúâÁî®ÔºåÂèØ‰ª•ÈÅøÂÖç‰ª£Á†ÅËøá‰∫éÊã•Êå§Ôºå‰ΩøÂæó‰ª£Á†ÅÊõ¥Êòì‰∫éÈòÖËØªÂíåÁª¥Êä§„ÄÇ Name Ash 80.830657 Emily 84.297725 Meg 69.218137 Sid 63.020729 Smith 58.332233 Name: LPGrade, dtype: float64 ","date":"2024-07-15","objectID":"/datadisc02/:2:3","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":["DATA100"],"content":"Question 8d Of all the homework assignments, which are the most difficult in terms of the median grade? Order by the median grade, from lowest to greatest. Do not consider incomplete assignments or late penalties in this calculation. Fill in the blanks below to answer this question. Hint: Recall that incomplete assignments have NaN values. How can we use dropna to remove these null values? hw_grades._________() \\ .groupby(___________)[____________] \\ .agg(____________) \\ .sort_values() # Your answer here hw_grades.dropna()\\ .groupby('Assignment')['Grade']\\ .agg('median')\\ .sort_values() Assignment Homework 2 64.160918 Homework 10 66.366211 Homework 5 74.372434 Homework 8 76.362904 Homework 4 78.207572 Homework 3 78.348163 Homework 9 82.517998 Homework 6 84.369535 Homework 1 85.473281 Homework 7 92.200688 Name: Grade, dtype: float64 ","date":"2024-07-15","objectID":"/datadisc02/:2:4","tags":null,"title":"Datadisc02","uri":"/datadisc02/"},{"categories":null,"content":"CS61ABC DATA100(DS100) Ëß¶Âä®ÁöÑÁû¨Èó¥üòã ","date":"2024-07-14","objectID":"/beyondcode/thinking1/:0:0","tags":null,"title":"Thinking1","uri":"/beyondcode/thinking1/"},{"categories":null,"content":"ËÆ∞ÂΩï2024ÂØíÂÅáÊó∂ÂÄôÁöÑÊÄùËÄÉ ","date":"2024-07-14","objectID":"/beyondcode/thinking0/:0:0","tags":null,"title":"Thinking0","uri":"/beyondcode/thinking0/"},{"categories":["DATA100"],"content":"lambda function lambda x: x**2 ÈùûÊòæÂºèÂÆö‰πâÂáΩÊï∞ÔºåÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®lambdaË°®ËææÂºèÊù•ÂÆö‰πâ‰∏Ä‰∏™ÂáΩÊï∞„ÄÇ This is a lambda function that takes in one argument x and returns the square of x. ÂÜçÁúãsort_values() Ê≥®ÊÑè‰º†ÈÄíkey df.sort_values(by='column_name', keys=lambda x: x.str.lower(), ascending=True) ","date":"2024-07-14","objectID":"/datal4/:1:0","tags":["pandas"],"title":"DATA100-L4: Pandas ‚Ö°","uri":"/datal4/"},{"categories":["DATA100"],"content":"add move modify and so on sort by length of string approach1: create a new column and add to original df newdf = df[\"Name\"].str.len() # create a new column with length of each string df['length'] = newdf df.sort_values(by='length', ascending=True) drop column ","date":"2024-07-14","objectID":"/datal4/:2:0","tags":["pandas"],"title":"DATA100-L4: Pandas ‚Ö°","uri":"/datal4/"},{"categories":["DATA100"],"content":"groupby.agg ","date":"2024-07-14","objectID":"/datal4/:3:0","tags":["pandas"],"title":"DATA100-L4: Pandas ‚Ö°","uri":"/datal4/"},{"categories":["DATA100"],"content":"never use loops in this class! df.groupby('column_name').agg(f) f is a dictionary of functions to apply to each column. The function can be a lambda function or a named function. ","date":"2024-07-14","objectID":"/datal4/:3:1","tags":["pandas"],"title":"DATA100-L4: Pandas ‚Ö°","uri":"/datal4/"},{"categories":["DATA100"],"content":"groupby type: pandas.core.groupby.generic.DataFrameGroupBy ","date":"2024-07-14","objectID":"/datal4/:4:0","tags":["pandas"],"title":"DATA100-L4: Pandas ‚Ö°","uri":"/datal4/"},{"categories":["DATA100"],"content":"filter df.groupby('column_name').filter(lambda x: x['column_name'].mean() \u003e 10) This will return a new DataFrame with only the groups that have a mean value greater than 10. ","date":"2024-07-14","objectID":"/datal4/:4:1","tags":["pandas"],"title":"DATA100-L4: Pandas ‚Ö°","uri":"/datal4/"},{"categories":["DATA100"],"content":"multi index Â§öÁª¥Á¥¢Âºï using pivot_table() df.pivot_table(index=['column1', 'column2'], columns='column3', values='column4', aggfunc='mean') This will create a multi-index pivot table with the specified index and columns, and the mean of column4 for each group. using groupby() df.groupby(['column1', 'column2']).agg({'column3': 'mean', 'column4':'sum'}) This will group the DataFrame by column1 and column2, and calculate the mean and sum of column3 and column4 for each group. ","date":"2024-07-14","objectID":"/datal4/:4:2","tags":["pandas"],"title":"DATA100-L4: Pandas ‚Ö°","uri":"/datal4/"},{"categories":["DATA100"],"content":"joining tables left.merge(right, on='column_name', how='inner', lefton='column_name_left', righton='column_name_right') ","date":"2024-07-14","objectID":"/datal4/:5:0","tags":["pandas"],"title":"DATA100-L4: Pandas ‚Ö°","uri":"/datal4/"},{"categories":["DATA100"],"content":" # Initialize Otter import otter grader = otter.Notebook(\"hw01.ipynb\") HW 1: Math Review and Plotting ÈáçÁÇπÂú®codingÔºåÁêÜËÆ∫‰æõÂèÇËÄÉ ","date":"2024-07-14","objectID":"/datahw01/:0:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Due Date: Thursday Jan 27, 11:59 PM ","date":"2024-07-14","objectID":"/datahw01/:1:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Collaboration Policy Data science is a collaborative activity. While you may talk with others about the homework, we ask that you write your solutions individually. If you do discuss the assignments with others please include their names at the top of your notebook. Collaborators: list collaborators here ","date":"2024-07-14","objectID":"/datahw01/:2:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"This Assignment The purpose of this assignment is for you to combine Python, math, and the ideas in Data 8 to draw some interesting conclusions. The methods and results will help build the foundation of Data 100. ","date":"2024-07-14","objectID":"/datahw01/:3:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Score Breakdown Question Points 1a 1 1b 2 2a 1 2b 1 2c 2 2d 2 2e 1 3a 2 3b 2 3c 1 3d 2 3e 2 4a 1 4b 1 4c 1 4d 1 5a 1 5b 1 5d 3 6a 2 6b(i) 2 6b(ii) 2 6c 2 Total 36 ","date":"2024-07-14","objectID":"/datahw01/:4:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Before You Start For each question in the assignment, please write down your answer in the answer cell(s) right below the question. We understand that it is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run code, NEVER add cells between a question cell and the answer cell below it. It will cause errors when we run the autograder, and it will sometimes cause a failure to generate the PDF file. Important note: The local autograder tests will not be comprehensive. You can pass the automated tests in your notebook but still fail tests in the autograder. Please be sure to check your results carefully. ","date":"2024-07-14","objectID":"/datahw01/:5:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Initialize your environment This cell should run without error if you‚Äôre using the course Jupyter Hub or you have set up your personal computer correctly. import numpy as np import matplotlib import matplotlib.pyplot as plt plt.style.use('fivethirtyeight') ","date":"2024-07-14","objectID":"/datahw01/:5:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Preliminary: Jupyter Shortcuts Here are some useful Jupyter notebook keyboard shortcuts. To learn more keyboard shortcuts, go to Help -\u003e Keyboard Shortcuts in the menu above. Here are a few we like: ctrl+return : Evaluate the current cell shift+return: Evaluate the current cell and move to the next esc : command mode (may need to press before using any of the commands below) a : create a cell above b : create a cell below dd : delete a cell m : convert a cell to markdown y : convert a cell to code ","date":"2024-07-14","objectID":"/datahw01/:5:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Preliminary: NumPy You should be able to understand the code in the following cells. If not, review the following: The Data 8 Textbook Chapter on NumPy DS100 NumPy Review Condensed NumPy Review The Official NumPy Tutorial Jupyter pro-tip: Pull up the docs for any function in Jupyter by running a cell with the function name and a ? at the end: np.arange? \u001b[1;31mDocstring:\u001b[0m arange([start,] stop[, step,], dtype=None, *, device=None, like=None) Return evenly spaced values within a given interval. ``arange`` can be called with a varying number of positional arguments: * ``arange(stop)``: Values are generated within the half-open interval ``[0, stop)`` (in other words, the interval including `start` but excluding `stop`). * ``arange(start, stop)``: Values are generated within the half-open interval ``[start, stop)``. * ``arange(start, stop, step)`` Values are generated within the half-open interval ``[start, stop)``, with spacing between values given by ``step``. For integer arguments the function is roughly equivalent to the Python built-in :py:class:`range`, but returns an ndarray rather than a ``range`` instance. When using a non-integer step, such as 0.1, it is often better to use `numpy.linspace`. See the Warning sections below for more information. Parameters ---------- start : integer or real, optional Start of interval. The interval includes this value. The default start value is 0. stop : integer or real End of interval. The interval does not include this value, except in some cases where `step` is not an integer and floating point round-off affects the length of `out`. step : integer or real, optional Spacing between values. For any output `out`, this is the distance between two adjacent values, ``out[i+1] - out[i]``. The default step size is 1. If `step` is specified as a position argument, `start` must also be given. dtype : dtype, optional The type of the output array. If `dtype` is not given, infer the data type from the other input arguments. device : str, optional The device on which to place the created array. Default: None. For Array-API interoperability only, so must be ``\"cpu\"`` if passed. .. versionadded:: 2.0.0 like : array_like, optional Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as ``like`` supports the ``__array_function__`` protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument. .. versionadded:: 1.20.0 Returns ------- arange : ndarray Array of evenly spaced values. For floating point arguments, the length of the result is ``ceil((stop - start)/step)``. Because of floating point overflow, this rule may result in the last element of `out` being greater than `stop`. Warnings -------- The length of the output might not be numerically stable. Another stability issue is due to the internal implementation of `numpy.arange`. The actual step value used to populate the array is ``dtype(start + step) - dtype(start)`` and not `step`. Precision loss can occur here, due to casting or due to using floating points when `start` is much larger than `step`. This can lead to unexpected behaviour. For example:: \u003e\u003e\u003e np.arange(0, 5, 0.5, dtype=int) array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \u003e\u003e\u003e np.arange(-3, 3, 0.5, dtype=int) array([-3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8]) In such cases, the use of `numpy.linspace` should be preferred. The built-in :py:class:`range` generates :std:doc:`Python built-in integers that have arbitrary size \u003cpython:c-api/long\u003e`, while `numpy.arange` produces `numpy.int32` or `numpy.int64` numbers. This may result in incorrect results for large integer values:: \u003e\u003e\u003e power = 40 \u003e\u003e\u003e modulo = 10000 \u003e\u003e\u003e x1 = [(n ** power) % modulo for n in range(8)] \u003e\u003e\u003e x2 = [(n ** power) % modulo for n in np.arange(8)] \u003e\u003e\u003e print(x1) [0, 1, 7776, 8801, 6176, 625, 6576, 4001] # correct \u003e\u003e\u003e print(x2) [0, 1, 7776, 7185, 0, 5969, 4816, 3361] # incorrect See Also -------- numpy","date":"2024-07-14","objectID":"/datahw01/:5:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Preliminary: LaTeX You should use LaTeX to format math in your answers. If you aren‚Äôt familiar with LaTeX, not to worry. It‚Äôs not hard to use in a Jupyter notebook. Just place your math in between dollar signs within Markdown cells: $ f(x) = 2x $ becomes $ f(x) = 2x $. If you have a longer equation, use double dollar signs to place it on a line by itself: $$ \\sum_{i=0}^n i^2 $$ becomes: $$ \\sum_{i=0}^n i^2$$ You can align multiple lines using the \u0026 anchor, \\\\ newline, in an align block as follows: \\begin{align} f(x) \u0026= (x - 1)^2 \\\\ \u0026= x^2 - 2x + 1 \\end{align} becomes \\begin{align} f(x) \u0026= (x - 1)^2 \\ \u0026= x^2 - 2x + 1 \\end{align} This PDF has some handy LaTeX. For more about basic LaTeX formatting, you can read this article. ","date":"2024-07-14","objectID":"/datahw01/:5:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Preliminary: Sums Here‚Äôs a recap of some basic algebra written in sigma notation. The facts are all just applications of the ordinary associative and distributive properties of addition and multiplication, written compactly and without the possibly ambiguous ‚Äú‚Ä¶‚Äù. But if you are ever unsure of whether you‚Äôre working correctly with a sum, you can always try writing $\\sum_{i=1}^n a_i$ as $a_1 + a_2 + \\cdots + a_n$ and see if that helps. You can use any reasonable notation for the index over which you are summing, just as in Python you can use any reasonable name in for name in list. Thus $\\sum_{i=1}^n a_i = \\sum_{k=1}^n a_k$. $\\sum_{i=1}^n (a_i + b_i) = \\sum_{i=1}^n a_i + \\sum_{i=1}^n b_i$ $\\sum_{i=1}^n d = nd$ $\\sum_{i=1}^n (ca_i + d) = c\\sum_{i=1}^n a_i + nd$ These properties may be useful in the Least Squares Predictor question. To see the LaTeX we used, double-click this cell. Evaluate the cell to exit. ","date":"2024-07-14","objectID":"/datahw01/:5:5","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 1: Calculus In this question we will review some fundamental properties of the sigmoid function, which will be discussed when we talk more about logistic regression in the latter half of the class. The sigmoid function is defined to be $$\\sigma(x) = \\frac{1}{1+e^{-x}}$$ ","date":"2024-07-14","objectID":"/datahw01/:6:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 1a Show that $\\sigma(-x) = 1 - \\sigma(x)$. Note, again: In this class, you must always put your answer in the cell that immediately follows the question. DO NOT create any cells between this one and the one that says Type your answer here, replacing this text. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:6:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 1b Show that the derivative of the sigmoid function can be written as: $$\\frac{d}{dx}\\sigma(x) = \\sigma(x)(1 - \\sigma(x))$$ This PDF has some handy LaTeX. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:6:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2: Probabilities and Proportions Much of data analysis involves interpreting proportions ‚Äì lots and lots of related proportions. So let‚Äôs recall the basics. It might help to start by reviewing the main rules from Data 8, with particular attention to what‚Äôs being multiplied in the multiplication rule. ","date":"2024-07-14","objectID":"/datahw01/:7:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2a The Pew Research Foundation publishes the results of numerous surveys, one of which is about the trust that Americans have in groups such as the military, scientists, and elected officials to act in the public interest. A table in the article summarizes the results. Pick one of the options (i) and (ii) to answer the question below; if you pick (i), fill in the blank with the percent. Then, explain your choice. The percent of surveyed U.S. adults who had a great deal of confidence in both scientists and religious leaders (i) is equal to ______________________. (ii) cannot be found with the information in the article. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:7:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2b In a famous (or infamous) survey, members of the Harvard medical school were asked to consider a scenario in which ‚Äúa test to detect a disease whose prevalence is 1/1,000 has a false positive rate of 5 percent‚Äù. The terminology, the specific question asked in the survey, and the answer, are discussed in detail in a Stat 88 textbook section that you are strongly encouraged to read. As Stat 88 is a Data 8 connector course, the section is another look at the same ideas as in the corresponding Data 8 textbook section. The corresponding tree diagram is copied below for your reference. The survey did not provide the true positive rate. The respondents and Stat 88 were allowed to assume that the true positive rate is 1, but we will not do so here. Let the true positive rate be some unknown proportion $p$. Suppose a person is picked at random from the population. Let $N$ be the event that the person doesn‚Äôt have the disease and let $T_N$ be the event that the person‚Äôs test result is negative. Fill in Blanks 1 and 2 with options chosen from (1)-(9). The proportion $P(N \\mid T_N)$ is the number of people who $\\underline{1}$ relative to the total number of people who $\\underline{2}$. (1) are in the population (2) have the disease (3) don‚Äôt have the disease (4) test positive (5) test negative (6) have the disease and test positive (7) have the disease and test negative (8) don‚Äôt have the disease and test positive (9) don‚Äôt have the disease and test negative Assign the variable q4bi to your answer to the first blank and q4bii to your answer to the second blank. q4bi = ... q4bii = ... q4bi, q4bii grader.check(\"q2b\") ","date":"2024-07-14","objectID":"/datahw01/:7:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2c (This is a continuation of the previous part.) Define a function no_disease_given_negative that takes $p$ as its argument and returns $P(N \\mid T_N)$. def no_disease_given_negative(p): ... grader.check(\"q4c\") ","date":"2024-07-14","objectID":"/datahw01/:7:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2d (This part is a continuation of the previous two.) Pick all of the options (i)-(iv) that are true for all values of $p$. Explain by algebraic or probailistic reasoning; you are welcome to use your function no_disease_given_negative to try a few cases numerically. Your explanation should include the reasons why you didn‚Äôt choose some options. $P(N \\mid T_N)$ is (i) equal to $0.95$. (ii) equal to $0.999 \\times 0.95$. (iii) greater than $0.999 \\times 0.95$. (iv) greater than $0.95$. Type your answer here, replacing this text. # Use this cell for experimenting if you wish, but your answer should be written in the cell above. ","date":"2024-07-14","objectID":"/datahw01/:7:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 2e Suzuki is one of most commonly owned makes of cars in our county (Alameda). A car heading from Berkeley to San Francisco is pulled over on the freeway for speeding. Suppose I tell you that the car is either a Suzuki or a Lamborghini, and you have to guess which of the two is more likely. What would you guess, and why? Make some reasonable assumptions and explain them (data scientists often have to do this), justify your answer, and say how it‚Äôs connected to the previous parts. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:7:5","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3: Distributions Visualizing distributions, both categorical and numerical, helps us understand variability. In Data 8 you visualized numerical distributions by drawing histograms, which look like bar charts but represent proportions by the areas of the bars instead of the heights or lengths. In this exercise you will use the hist function in matplotlib instead of the corresponding Table method to draw histograms. To start off, suppose we want to plot the probability distribution of the number of spots on a single roll of a die. That should be a flat histogram since the chance of each of the values 1 through 6 is 1/6. Here is a first attempt at drawing the histogram. faces = range(1, 7) plt.hist(faces) (array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1.]), array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]), \u003cBarContainer object of 10 artists\u003e) This default plot is not helpful. We have to choose some arguments to get a visualization that we can interpret. Note that the second printed line shows the left ends of the default bins, as well as the right end of the last bin. The first line shows the counts in the bins. If you don‚Äôt want the printed lines you can add a semi-colon at the end of the call to plt.hist, but we‚Äôll keep the lines for now. Let‚Äôs redraw the histogram with bins of unit length centered at the possible values. By the end of the exercise you‚Äôll see a reason for centering. Notice that the argument for specifying bins is the same as the one for the Table method hist. unit_bins = np.arange(0.5, 6.6) plt.hist(faces, bins = unit_bins) (array([1., 1., 1., 1., 1., 1.]), array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5]), \u003cBarContainer object of 6 artists\u003e) We need to see the edges of the bars! Let‚Äôs specify the edge color ec to be white. Here are all the colors you could use, but do try to drag yourself away from the poetic names. plt.hist(faces, bins = unit_bins, ec='white') (array([1., 1., 1., 1., 1., 1.]), array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5]), \u003cBarContainer object of 6 artists\u003e) That‚Äôs much better, but look at the vertical axis. It is not drawn to the density scale defined in Data 8. We want a histogram of a probability distribution, so the total area should be 1. We just have to ask for that. plt.hist(faces, bins = unit_bins, ec='white', density=True) (array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667]), array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5]), \u003cBarContainer object of 6 artists\u003e) That‚Äôs the probability histogram of the number of spots on one roll of a die. The proportion is $1/6$ in each of the bins. Note: You may notice that running the above cells also displayed the return value of the last function call of each cell. This was intentional on our part to show you how plt.hist() (documentation) returned different values per plot. Note 2: Going forward, you can use a semicolon ; on the last line to suppress additional display, as below. plt.hist(faces, bins = unit_bins, ec='white', density=True); ","date":"2024-07-14","objectID":"/datahw01/:8:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3a Define a function integer_distribution that takes an array of integers and draws the histogram of the distribution using unit bins centered at the integers and white edges for the bars. The histogram should be drawn to the density scale. The left-most bar should be centered at the smallest integer in the array, and the right-most bar at the largest. Your function does not have to check that the input is an array consisting only of integers. The display does not need to include the printed proportions and bins. If you have trouble defining the function, go back and carefully read all the lines of code that resulted in the probability histogram of the number of spots on one roll of a die. Pay special attention to the bins. def integer_distribution(x): bins = np.arange(min(x) - 0.5, max(x) + 1.5) plt.hist(x, bins=bins, ec='white',density=True) integer_distribution(faces) ","date":"2024-07-14","objectID":"/datahw01/:8:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3b (Note: You can complete this part with just prerequisite knowledge for Data 100. That being said, Lecture 2 provides additional historical context and definitions for probability sample, sampling bias, and chance error). One way to use probability samples is to quantify sampling bias and chance error. Put briefly, if we assume that a sample distribution was selected at random from a known population, then we can quantify how likely that sample is to have arisen due to random chance (chance error). If the difference in sample and population distributions is too great, then we suspect that the given sample has bias in how it was selected from the population. Let‚Äôs see this process in a post-analysis of pre-election polling of the 1936 U.S. Presidential Election. Through the U.S. electoral college process (we‚Äôll ignore it in this question, but read more here), Franklin D. Roosevelt won the election by an overwhelming margin. The popular vote results were approximately 61% Roosevelt (Democrat, incumbent), 37% Alf Landon (Republican), and 2% other candidates. For this problem, this is our population distribution. You can use np.random.multinomial to simulate drawing at random with replacement from a categorical distribution. The arguments are the sample size n and an array pvals of the proportions in all the categories. The function simulates n independent random draws from the distribution and returns the observed counts in all the categories. Read the documentation to see how this is described formally; we will use the formal terminology and notation in future assignments after we have discussed them in class. You will see that the function also takes a third argument size, which for our purposes will be an integer that specifies the number of times to run the entire simulation. All the runs are independent of each other. Write one line of code that uses np.random.multinomial to run 10 independent simulations of drawing 100 times at random with replacement from a population in which 61% of the people vote for Roosevelt, 37% for Landon, and 2% for other candidatdes. The output should be an array containing the counts in the Roosevelt category in the 10 simulations. It will help to recall how to slice NumPy arrays. Assign your answer to the variable sample. sample = np.random.multinomial(100, [0.61, 0.37, 0.02], size=10)[:, 0] sample array([54, 65, 58, 53, 66, 58, 61, 56, 60, 57], dtype=int32) grader.check(\"q3b\") q3b passed! üôå ","date":"2024-07-14","objectID":"/datahw01/:8:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3c Replace the ‚Äú‚Ä¶‚Äù in the code cell below with a Python expression so that the output of the cell is an empirical histogram of 500,000 simulated counts of voters for Roosevelt in 100 draws made at random with replacement from the voting population. After you have drawn the histogram, you might want to take a moment to recall the conclusion reached by the Literary Digest, a magazine that‚Äîwhile having successfully predicted the outcome of many previous presidential elections‚Äîfailed to correctly predict the winner of the 1936 presidential election. In their survey of 10 million individuals, they predicted the popular vote as just 43% for Roosevelt and 57% for Landon. Based on our simulation, there was most definitely sampling bias in the Digest‚Äôs sampling process. simulated_counts = np.random.multinomial(100, [0.61, 0.37, 0.02], size=500000)[:, 0] integer_distribution(simulated_counts) ","date":"2024-07-14","objectID":"/datahw01/:8:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3d As you know, the count of Roosevelt voters in a sample of 100 people drawn at random from the eligible population is expected to be 61. Just by looking at the histogram in Part c, and no other calculation, pick the correct option and explain your choice. You might want to refer to the Data 8 textbook again. The SD of the distribution of the number of Roosevelt voters in a random sample of 100 people drawn from the eligible population is closest to (i) 1.9 (ii) 4.9 (iii) 10.9 (iv) 15.9 Type your answer here. ÂÅáËÆæ‰∏äÈù¢ÂõæÁâáÊòØÂØπÁöÑÔºåÁî®3œÉÂéüÂàôÁ≤óÁï•‰º∞ËÆ°5Â∑¶Âè≥„ÄÇ ","date":"2024-07-14","objectID":"/datahw01/:8:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 3e The normal curve with mean $\\mu$ and SD $\\sigma$ is defined by $$ f(x) ~ = ~ \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}}, ~~~ -\\infty \u003c x \u003c \\infty $$ Redraw your histogram from Part c and overlay the normal curve with $\\mu = 61$ and $\\sigma$ equal to the choice you made in Part d. You just have to call plt.plot after integer_distribution. Use np.e for $e$. For the curve, use 2 as the line width, and any color that is easy to see over the blue histogram. It‚Äôs fine to just let Python use its default color. Now you can see why centering the histogram bars over the integers was a good idea. The normal curve peaks at 26, which is the center of the corresponding bar. mu = 61 sigma = 4.9 x = np.linspace(40, 80, 200) f_x = 1/(sigma * np.sqrt(2 * np.pi)) * np.exp(-(x - mu)**2 / (2 * sigma**2)) plt.plot(x, f_x) integer_distribution(simulated_counts) ","date":"2024-07-14","objectID":"/datahw01/:8:5","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4: Linear Algebra A common representation of data uses matrices and vectors, so it is helpful to familiarize ourselves with linear algebra notation, as well as some simple operations. Define a vector $\\vec{v}$ to be a column vector. Then, the following properties hold: $c\\vec{v}$ with $c$ some constant $c \\in \\mathbb{R}$, is equal to a new vector where every element in $c\\vec{v}$ is equal to the corresponding element in $\\vec{v}$ multiplied by $c$. For example, $2 \\begin{bmatrix} 1 \\ 2 \\ \\end{bmatrix} = \\begin{bmatrix} 2 \\ 4 \\ \\end{bmatrix}$ $\\vec{v}_1 + \\vec{v}_2$ is equal to a new vector with elements equal to the elementwise addition of $\\vec{v}_1$ and $\\vec{v}_2$. For example, $\\begin{bmatrix} 1 \\ 2 \\ \\end{bmatrix} + \\begin{bmatrix} -3 \\ 4 \\ \\end{bmatrix} = \\begin{bmatrix} -2 \\ 6 \\ \\end{bmatrix}$. The above properties form our definition for a linear combination of vectors. $\\vec{v}_3$ is a linear combination of $\\vec{v}_1$ and $\\vec{v}_2$ if $\\vec{v}_3 = a\\vec{v}_1 + b\\vec{v}_2$, where $a$ and $b$ are some constants. Oftentimes, we stack column vectors to form a matrix. Define the rank of a matrix $A$ to be equal to the maximal number of linearly independent columns in $A$. A set of columns is linearly independent if no column can be written as a linear combination of any other column(s) within the set. For example, let $A$ be a matrix with 4 columns. If three of these columns are linearly independent, but the fourth can be written as a linear combination of the other three, then $\\text{rank}(A) = 3$. For each part below, you will be presented with a set of vectors, and a matrix consisting of those vectors stacked in columns. State the rank of the matrix, and whether or not the matrix is full rank. If the matrix is not full rank, state a linear relationship among the vectors‚Äîfor example: $\\vec{v}_1 = 2\\vec{v}_2$. ","date":"2024-07-14","objectID":"/datahw01/:9:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4a $$ \\vec{v}_1 = \\begin{bmatrix} 1 \\ 0 \\ \\end{bmatrix} , \\vec{v}_2 = \\begin{bmatrix} 1 \\ 1 \\ \\end{bmatrix} , A = \\begin{bmatrix} \\vert \u0026 \\vert \\ \\vec{v}_1 \u0026 \\vec{v}_2 \\ \\vert \u0026 \\vert \\end{bmatrix}$$ Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:9:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4b $$ \\vec{v}_1 = \\begin{bmatrix} 3 \\ -4 \\ \\end{bmatrix} , \\vec{v}_2 = \\begin{bmatrix} 0 \\ 0 \\ \\end{bmatrix} , B = \\begin{bmatrix} \\vert \u0026 \\vert \\ \\vec{v}_1 \u0026 \\vec{v}_2 \\ \\vert \u0026 \\vert \\end{bmatrix} $$ Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:9:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4c $$ \\vec{v}_1 = \\begin{bmatrix} 0 \\ 1 \\ \\end{bmatrix} , \\vec{v}_2 = \\begin{bmatrix} 5 \\ 0 \\ \\end{bmatrix} , \\vec{v}_3 = \\begin{bmatrix} 10 \\ 10 \\ \\end{bmatrix} , C = \\begin{bmatrix} \\vert \u0026 \\vert \u0026 \\vert \\ \\vec{v}_1 \u0026 \\vec{v}_2 \u0026 \\vec{v}_3 \\ \\vert \u0026 \\vert \u0026 \\vert \\end{bmatrix} $$ Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:9:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 4d $$ \\vec{v}_1 = \\begin{bmatrix} 0 \\ 2 \\ 3 \\ \\end{bmatrix} , \\vec{v}_2 = \\begin{bmatrix} -2 \\ -2 \\ 5 \\ \\end{bmatrix} , \\vec{v}_3 = \\begin{bmatrix} 2 \\ 4 \\ -2 \\ \\end{bmatrix} , D = \\begin{bmatrix} \\vert \u0026 \\vert \u0026 \\vert \\ \\vec{v}_1 \u0026 \\vec{v}_2 \u0026 \\vec{v}_3 \\ \\vert \u0026 \\vert \u0026 \\vert \\end{bmatrix} $$ Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:9:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 5: A Least Squares Predictor Let the list of numbers $(x_1, x_2, \\ldots, x_n)$ be data. You can think of each index $i$ as the label of a household, and the entry $x_i$ as the annual income of Household $i$. Define the mean or average $\\mu$ of the list to be $$\\mu ~ = ~ \\frac{1}{n}\\sum_{i=1}^n x_i.$$ ","date":"2024-07-14","objectID":"/datahw01/:10:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 5a The $i$ th deviation from average is the difference $x_i - \\mu$. In Data 8 you saw in numerical examples that the sum of all these deviations is 0. Now prove that fact. That is, show that $\\sum_{i=1}^n (x_i - \\mu) = 0$. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:10:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 5b Recall that the variance of a list is defined as the mean squared deviation from average, and that the standard deviation (SD) of the list is the square root of the variance. The SD is in the same units as the data and measures the rough size of the deviations from average. Denote the variance of the list by $\\sigma^2$. Write a math expression for $\\sigma^2$ in terms of the data ($x_{1} \\dots x_{n}$) and $\\mu$. We recommend building your expression by reading the definition of variance from right to left. That is, start by writing the notation for ‚Äúaverage‚Äù, then ‚Äúdeviation from average‚Äù, and so on. Type your answer here, replacing this text. ","date":"2024-07-14","objectID":"/datahw01/:10:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Mean Squared Error Suppose you have to predict the value of $x_i$ for some $i$, but you don‚Äôt get to see $i$ and you certainly don‚Äôt get to see $x_i$. You decide that whatever $x_i$ is, you‚Äôre just going to use some number $c$ as your predictor. The error in your prediction is $x_i - c$. Thus the mean squared error (MSE) of your predictor $c$ over the entire list of $n$ data points can be written as: $$MSE(c) = \\frac{1}{n}\\sum_{i=1}^n (x_i - c)^2.$$ You may already see some similarities to your definition of variance from above! You then start to wonder‚Äîif you picked your favorite number $c = \\mu$ as the predictor, would it be ‚Äúbetter‚Äù than other choices $c \\neq \\mu$? ","date":"2024-07-14","objectID":"/datahw01/:10:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 5c One common approach to defining a ‚Äúbest‚Äù predictor is as predictor that minimizes the MSE on the data $(x_1, \\dots, x_n)$. In this course, we commonly use calculus to find the predictor $c$ as follows: Define $MSE$ to be a function of $c$, i.e., $MSE(c)$ as above. Assume that the data points $x_1, x_2, ‚Ä¶, x_n$ are fixed, and that $c$ is the only variable. Determine the value of $c$ that minimizes $MSE(c)$. Justify that this is indeed a minimum, not a maximum. Step 1 is done for you in the problem statement; follow steps 2 and 3 to show that $\\mu$ is the value of $c$ that minimizes $MSE(c)$. You must do both steps. Type your answer here, replacing this text. Your proof above shows that $\\mu$ is the least squares constant predictor. ","date":"2024-07-14","objectID":"/datahw01/:10:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6: A More Familiar Least Squares Predictor In Data 8 you found (numerically) the least squares linear predictor of a variable $y$ based on a related variable $x$. In this course, we will prove your findings using a generalization of your calculation in the previous question. When we get to this proof later in this course, you will need to be comfortable with vector operations. For now, you will get familiar with this notation by rewriting your least squares findings from Data 8 (and the previous question) using vector notation. This question won‚Äôt require you to write LaTeX, so just focus on the mathematical notation we‚Äôre presenting. ","date":"2024-07-14","objectID":"/datahw01/:11:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"The Dot Product (1) We start by defining the dot product of two real vectors $x = \\begin{bmatrix} x_1 \\ x_2 \\ \\dots \\ x_n \\end{bmatrix}$ and $y = \\begin{bmatrix} y_1 \\ y_2 \\ \\dots \\ y_n \\end{bmatrix}$ as follows: $$x^T y = \\sum_{i=1}^n x_i y_i $$ Given the above definition, the dot product is (1) a scalar, not another vector; and (2) only defined for two vectors of the same length. Note: In this course we often opt for $x$ instead of $\\vec{x}$ to simplify notation; $x$ as a vector is inferred from its use in the dot product. Then $x_i$ is the $i$-th element of the vector $x$. Detail: In this course, we prefer the notation $x^Ty$ to illustrate a dot product, defined as matrix multiplication of $x^T$ and $y$. In the literature you may also see $x \\cdot y$, but we avoid this notation since the dot ($\\cdot$) notation is occasionally used for scalar values. Detail: The dot product is a special case of an inner product, where $x, y \\in \\mathbb{R}^n$. (2) We introduce a special vector, $\\mathbb{1}$, to write the mean $\\bar{x}$ of data $(x_1, x_2, \\dots, x_n)$ as a dot product: \\begin{align} \\bar{x} \u0026= \\frac{1}{n}\\sum_{i=1}^n x_i = \\frac{1}{n}\\sum_{i=1}^n 1x_i \\ \u0026= \\frac{1}{n}(x^T\\mathbb{1}). \\end{align} The data $(x_1, \\dots, x_n)$ have been defined as an $n$-dimensional column vector $x$, where $x = \\begin{bmatrix} x_1 \\ x_2 \\ \\dots \\ x_n \\end{bmatrix}$. The special vector $\\mathbb{1}$ is a vector of ones, whose length is defined by the vector operation in which it is used. So with $n$-dimensional column vector $x$, the dot product $x^T\\mathbb{1}$ implies that $\\mathbb{1}$ is an $n$-dimensional column vector where every element is $1$. Because dot products produce scalars, the multiplication of two scalars $\\frac{1}{n}$ and $x^T\\mathbb{1}$ produces another scalar, $\\bar{x}$. Note: We use bar notation for the mean ($\\bar{x}$ instead of $\\mu$) in this problem to differentiate $\\bar{x}$ from $\\bar{y}$, the latter of which is the mean of data $(y_1, \\dots, y_n)$. (3) We can further use this definition of $\\bar{x}$ to additionally write the variance $\\sigma_x^2$ of the data $(x_1, \\dots, x_n)$ as a dot product. Verify for yourself that the below operation defines $\\sigma_x^2$ as a scalar: \\begin{align} \\sigma_x^2 \u0026= \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2 \\ \u0026= \\frac{1}{n}(x - \\bar{x})^T(x - \\bar{x}). \\end{align} ","date":"2024-07-14","objectID":"/datahw01/:11:1","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6a To verify your understanding of the dot product as defined above, suppose you are working with $n$ datapoints ${(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)}$. Define the $x$ data as $(x_1, \\dots, x_n)$ and the $y$ data as $(y_1, \\dots, y_n)$, and define $x$ and $y$ as two $n$-dimensional column vectors, where the $i$-th elements of $x$ and $y$ are $x_i$ and $y_i$, respectively. Define $\\bar{x}$ and $\\bar{y}$ as the means of the $x$ data and $y$ data, respectively. Define $\\sigma_x^2$ and $\\sigma_y^2$ as the variances of the $x$ data and $y$ data, respectively. Therefore $\\sigma_x = \\sqrt{\\sigma_x^2}$ and $\\sigma_y = \\sqrt{\\sigma_y^2}$ are the standard deviations of the $x$ data and $y$ data, respectively. Suppose $n = 32$. What is the dimension of each of the following expressions? Expression (i). Note there are two ways it is written in the literature. $$\\dfrac{1}{\\sigma_x} (x - \\bar{x}) = \\dfrac{x - \\bar{x}}{\\sigma_x} $$ Expression (ii). $$\\dfrac{1}{n} \\left( \\dfrac{x - \\bar{x}}{\\sigma^x}\\right)^T \\left( \\dfrac{x - \\bar{x}}{\\sigma^x}\\right)$$ Assign the variables q6a_i and q6a_ii to an integer representing the dimension of the above expressions (i) and (ii), respectively. q6a_i = ... q6a_ii = ... # do not modify these lines print(f\"Q6a(i) is {q6a_i}-dimensional\") print(f\"Q6a(ii) is {q6a_ii}-dimensional\") grader.check(\"q6a\") ","date":"2024-07-14","objectID":"/datahw01/:11:2","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Dot Products in NumPy Next, we‚Äôll use NumPy‚Äôs matrix multiplication operators to compute expressions for the regression line, which you learned in Data 8 was the unique line that minimizes the mean squared error of estimation among all straight lines. At this time, it may be helpful to review the Data 8 section. Before we continue, let‚Äôs contextualize our computation by loading in a dataset you saw in Data 8: the relation between weight lifted and shot put distance among surveyed female collegiate athletes. We‚Äôve plotted the point using matplotlib‚Äôs scatter function, which you will see in more detail in two weeks. # Run this cell to plot the data. weight_lifted = np.array([ 37.5, 51.5, 61.3, 61.3, 63.6, 66.1, 70. , 92.7, 90.5, 90.5, 94.8, 97. , 97. , 97. , 102. , 102. , 103.6, 100.4, 108.4, 114. , 115.3, 114.9, 114.7, 123.6, 125.8, 119.1, 118.9, 141.1]) shot_put_distance = np.array([ 6.4, 10.2, 12.4, 13. , 13.2, 13. , 12.7, 13.9, 15.5, 15.8, 15.8, 16.8, 17.1, 17.8, 14.8, 15.5, 16.1, 16.2, 17.9, 15.9, 15.8, 16.7, 17.6, 16.8, 17. , 18.2, 19.2, 18.6]) plt.scatter(weight_lifted, shot_put_distance) plt.xlabel(\"Weight Lifted\") plt.ylabel(\"Shot Put Distance\") Looks pretty linear! Let‚Äôs try to fit a regression line to this data. Define the vectors $x$ as the weight lifted data vector and $y$ as the shot put distance data vector, respectively, of the college athletes. Then the regression line uses the weight lifted $x$ to predict $\\hat{y}$, which is the linear estimate of the actual value shot put distance $y$ as follows: \\begin{align} \\hat{y} \u0026= \\hat{a} + \\hat{b}{x}\\text{, where} \\ \\hat{a} \u0026= \\bar{y} - \\hat{b}\\bar{x} \\ \\hat{b} \u0026= r \\dfrac{\\sigma_y}{\\sigma_x} \\end{align} $\\bar{x}, \\bar{y}$ and $\\sigma_x, \\sigma_y$ are the means and standard deviations, respectively of the data $x$ and $y$, respectively. Here, $r$ is the correlation coefficient as defined in Data 8! Note: We use the hat $\\hat{}$ notation to indicate values we are estimating: $\\hat{y}$, the predicted shot put distance, as well as $\\hat{a}$ and $\\hat{b}$, the respective estimated intercept and slope parameters we are using to model the ‚Äúbest‚Äù linear predictor of $y$ from $x$. We‚Äôll dive into this later in the course. Note: Remember how we dropped the $\\vec{}$ vector notation? These linear regression equations therefore represent both the scalar case (predict a single value $\\hat{y}$ from a single $x$) and the vector case (predict a vector $\\hat{y}$ element-wise from a vector $x$). How convenient!! In this part, instead of using NumPy‚Äôs built-in statistical functions like np.mean() and np.std(), you are going to use NumPy‚Äôs matrix operations to create the components of the regression line from first principles. The @ operator multiplies NumPy matrices or arrays together (documentation). We can use this operator to write functions to compute statistics on data, using the expressions that we defined in part (a). Check it out: # Just run this cell. def dot_mean(arr): n = len(arr) all_ones = np.ones(n) # creates n-dimensional vector of ones return (arr.T @ all_ones)/n def dot_var(arr): n = len(arr) mean = dot_mean(arr) zero_mean_arr = arr - mean return (zero_mean_arr.T @ zero_mean_arr)/n def dot_std(arr): return np.sqrt(dot_var(arr)) print(\"np.mean(weight_lifted) =\", np.mean(weight_lifted), \"\\tdot_mean(weight_lifted) =\", dot_mean(weight_lifted)) print(\"np.var(weight_lifted) =\", np.std(weight_lifted), \"\\tdot_var(weight_lifted =\", dot_var(weight_lifted)) print(\"np.std(weight_lifted) =\", np.std(weight_lifted), \"\\tdot_std(weight_lifted =\", dot_std(weight_lifted)) Now, you will write code to define the expressions you explored in part (a) of this question. ","date":"2024-07-14","objectID":"/datahw01/:11:3","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6b (i) Use the NumPy @ operator to compute expression (i) from part (a). For convenience, we‚Äôve rewritten the expression below. Note that this expression is also referred to as $x$ in standard units (Data 8 textbook section). $$\\dfrac{x - \\bar{x}}{\\sigma_x} $$ Write the body of the function dot_su which takes in a 1-D NumPy array arr and returns arr in standard units. Do not use np.mean(), np.std(), np.var(), np.sum() nor any Python loops. You should only use a subset of @, /, +, -, len(), the dot_mean(), dot_var(), and dot_std() functions defined above. def dot_su(arr): ... # do not edit below this line q6bi_su = dot_su(weight_lifted) q6bi_su grader.check(\"q6bi\") ","date":"2024-07-14","objectID":"/datahw01/:11:4","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6b (ii) Next use the NumPy @ operator to compute the correlation coefficient $r$, which is expression (ii) from part (a). For convenience, we‚Äôve rewritten the expression below. $$r = \\dfrac{1}{n} \\left( \\dfrac{x - \\bar{x}}{\\sigma^x}\\right)^T \\left( \\dfrac{x - \\bar{x}}{\\sigma^x}\\right)$$ Write the body of the function dot_corr_coeff which takes in two 1-D NumPy arrays x and y and returns the correlation coefficient of x and y. As before, Do not use np.mean(), np.std(), np.var(), np.sum() nor any Python loops. As before, you should only use a subset of @, /, +, -, len(), the dot_mean(), dot_var(), and dot_std() functions defined above. You may also use the dot_su() function that you defined in the previous part. def dot_corr_coeff(x, y): ... # do not edit below this line q6bii_r = dot_corr_coeff(weight_lifted, shot_put_distance) q6bii_r grader.check(\"q6bii\") ","date":"2024-07-14","objectID":"/datahw01/:11:5","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Question 6c We‚Äôre ready to put everything together! Finally, use the dot_-prefixed functions in this question to compute the regression line. For convenience, we‚Äôve rewritten the expressions below. $\\hat{y}$ is the linear estimate of the value $y$ based on $x$. \\begin{align} \\hat{y} \u0026= \\hat{a} + \\hat{b}{x}\\text{, where} \\ \\hat{a} \u0026= \\bar{y} - \\hat{b}\\bar{x} \\ \\hat{b} \u0026= r \\dfrac{\\sigma_y}{\\sigma_x} \\end{align} Define the functions compute_a_hat and compute_b_hat which return the intercept and slope, respectively, of the regression line defind above for a linear estimator of y using x. Verify how the functions are used to plot the linear regression line (implemented for you). As before, Do not use np.mean(), np.std(), np.var(), np.sum(), or any for loops. You may use a subset of @, /, +, -, len(), dot_mean(), dot_var(), dot_std(), dot_su(), dot_corr_coeff(). Hint: You may want to define a_hat in terms of b_hat. def compute_a_hat(x, y): ... def compute_b_hat(x, y): ... # do not edit below this line a_hat = compute_a_hat(weight_lifted, shot_put_distance) b_hat = compute_b_hat(weight_lifted, shot_put_distance) shot_put_hats = a_hat + b_hat * weight_lifted plt.scatter(weight_lifted, shot_put_distance) # the actual data plt.plot(weight_lifted, shot_put_hats, color='g', alpha=0.5) # the prediction line, transparent green plt.xlabel(\"Weight Lifted\") plt.ylabel(\"Shot Put Distance\") display(compute_a_hat(weight_lifted, shot_put_distance)) display(compute_b_hat(weight_lifted, shot_put_distance)) grader.check(\"q6c\") To double-check your work, the cell below will rerun all of the autograder tests. grader.check_all() ","date":"2024-07-14","objectID":"/datahw01/:11:6","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"Submission Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. Please save before exporting! # Save your notebook first, then run this cell to export your submission. grader.export() ","date":"2024-07-14","objectID":"/datahw01/:12:0","tags":["math","plotting"],"title":"DATA100-hw01","uri":"/datahw01/"},{"categories":["DATA100"],"content":"DataFrames: a data structure for tabular data ","date":"2024-07-13","objectID":"/datal3/:1:0","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"API always remember to turn to GPT/google/doc ","date":"2024-07-13","objectID":"/datal3/:1:1","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"indexing and loc/iloc generate subsets: loc: an operator select items by labels df.loc[row_indexer, column_indexer] row_indexer: can be a single label, a list of labels, sliceÔºàÈó≠Âå∫Èó¥Ôºâ, single value column_indexer: same as row_indexer returns a DataFrame or Series iloc: an operator select items by positions df.iloc[row_indexer, column_indexer] row_indexer: numeric index or a list of numeric indicesÔºåÊ≠§Êó∂ÂõûÂà∞pythonÁªèÂÖ∏Á¥¢Âºï Â∑¶Èó≠Âè≥ÂºÄ column_indexer: same as row_indexer returns a DataFrame or Series ÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨‰ΩøÁî® loc ËøõË°åÁ¥¢Âºï .head(6) and .tail() to get the first or last few rows of a DataFrame(syntactic sugar) ","date":"2024-07-13","objectID":"/datal3/:2:0","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"[ ]: context sensitive operator ","date":"2024-07-13","objectID":"/datal3/:3:0","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"series: a data structure for 1D labeled data ","date":"2024-07-13","objectID":"/datal3/:4:0","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"index: a array-like object that labels the rows and columns of a DataFrame columns: usually do not have same name. ËΩ¨Êç¢Ôºö ","date":"2024-07-13","objectID":"/datal3/:5:0","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"conditional selection ","date":"2024-07-13","objectID":"/datal3/:6:0","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"Á±ªÂûãÊÑèËØÜ! ‰∏âÁßçÊï∞ÊçÆÁ±ªÂûã‰∏≠ÁöÑÂì™‰∏Ä‰∏™ÔºüÔºüÔºü ","date":"2024-07-13","objectID":"/datal3/:7:0","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"describe() ","date":"2024-07-13","objectID":"/datal3/:7:1","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"sample() df.sample(n=5, replace=True) # randomly select 5 rows ","date":"2024-07-13","objectID":"/datal3/:7:2","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"value_counts() df['column_name'].value_counts() # count the frequency of each value in a column return a Series with the count of each value in the column. ","date":"2024-07-13","objectID":"/datal3/:7:3","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"unique() df['column_name'].unique() # get all unique values in a column return a numpy array with the unique values in the column. ","date":"2024-07-13","objectID":"/datal3/:7:4","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"sort_values() df.sort_values(by='column_name', ascending=False) # sort the DataFrame by values in a column return a new DataFrame with the rows sorted by values in a column. ","date":"2024-07-13","objectID":"/datal3/:7:5","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["DATA100"],"content":"reference https://www.textbook.ds100.org/ch/a04/ref_pandas.html https://pandas.pydata.org/pandas-docs/stable/reference/index.html ","date":"2024-07-13","objectID":"/datal3/:8:0","tags":["pandas"],"title":"DATA100-L3: Pandas ‚Ö†","uri":"/datal3/"},{"categories":["UCB-CS61B"],"content":"Big-O Notation ","date":"2024-07-13","objectID":"/61b-19/:1:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"ÁªÜËäÇÂàÜÊûê ","date":"2024-07-13","objectID":"/61b-19/:2:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"Â±ÄÈôêÊÄß ","date":"2024-07-13","objectID":"/61b-19/:3:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"ÂØπÊØî Important: Big O does not mean ‚Äúworst case‚Äù! Often abused to mean this. ","date":"2024-07-13","objectID":"/61b-19/:4:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"Â§ßOËÆ∞Âè∑ÁöÑÁî®Â§Ñ ","date":"2024-07-13","objectID":"/61b-19/:5:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"Big-Omega Notation $\\Omega(f(n))$ ","date":"2024-07-13","objectID":"/61b-19/:6:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"Â§ßŒ©ËÆ∞Âè∑ÁöÑÁî®Â§Ñ ","date":"2024-07-13","objectID":"/61b-19/:7:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"Èùû‰∏•Ê†ºËØÅÊòéÂíå‰∏•Ê†ºËØÅÊòé ","date":"2024-07-13","objectID":"/61b-19/:8:0","tags":null,"title":"61B-19: Asymptotics III","uri":"/61b-19/"},{"categories":["UCB-CS61B"],"content":"‰∏çÁõ∏‰∫§ÈõÜÈóÆÈ¢ò public interface DisjointSets { /** Connects two items P and Q. */ void connect(int p, int q); /** Checks to see if two items are connected. */ boolean isConnected(int p, int q); } ","date":"2024-07-13","objectID":"/61b-20/:0:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"naive implementation ÁúüÁöÑÈìæÊé•‰∏§‰∏™ÂÖÉÁ¥†ÔºåÁÑ∂ÂêéËÄÉËôëÈÅçÂéÜÊï¥‰∏™ÈõÜÂêàÔºåÂà§Êñ≠ÊòØÂê¶Êúâ‰∏§‰∏™ÂÖÉÁ¥†ÊòØËøûÈÄöÁöÑ„ÄÇ ","date":"2024-07-13","objectID":"/61b-20/:0:1","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"better implementation Better approach: Model connectedness in terms of sets. How things are connected isn‚Äôt something we need to know.üòâ ","date":"2024-07-13","objectID":"/61b-20/:0:2","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"quick-find public class QuickFindDS implements DisjointSets { private int[] id; // really fast public boolean isConnected(int p, int q) { return id[p] == id[q]; } public void connect(int p, int q) { int pid = id[p]; int qid = id[q]; for (int i = 0; i \u003c id.length; i++) { if (id[i] == pid) { id[i] = qid; } }... } // constructor public QuickFindDS(int N) { id = new int[N]; for (int i = 0; i \u003c N; i++) id[i] = i; } } ","date":"2024-07-13","objectID":"/61b-20/:1:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"quick-union ËÄÉËôë‰∏çÁî®Êï∞ÁªÑÔºåÁî® üå≥üòã tree can not be too tall: Ê†ë‰∏çËÉΩÂ§™È´òÔºåÂê¶Âàô‰ºöÈÄÄÂåñÊàêÈìæË°®‚ö†Ô∏è public class QuickUnionDS implements DisjointSets { private int[] parent; public QuickUnionDS(int N) { parent = new int[N]; for (int i = 0; i \u003c N; i++) parent[i] = i; } // linear time to create N trees private int find(int p) { while (p != parent[p]) p = parent[p]; // p[i] and i ÂæàÈáçË¶ÅÔºÅ return p; } public boolean isConnected(int p, int q) { return find(p) == find(q); } public void connect(int p, int q) { int i = find(p); int j = find(q); parent[i] = j; // ÂêàÂπ∂‰∏§‰∏™Ê†ë } } ","date":"2024-07-13","objectID":"/61b-20/:2:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"weighted quick-union Â∏åÊúõÂπ≥Ë°°ÊùÉÈáç ÊùÉÈáçÂèØ‰ª•ÊòØÊ†ëÁöÑÂ§ßÂ∞èÔºå‰πüÂèØ‰ª•ÊòØÊ†ëÁöÑÊ∑±Â∫¶„ÄÇ ‰ª•‰∏ãËÄÉËôëÂÖÉÁ¥†‰∏™Êï∞ÔºàÊ†ëÁöÑÂ§ßÂ∞èÔºâ New ruleÔºàÁõÆÂâçÊòØ‰∏çÂä†ËØÅÊòéÁöÑÁªèÈ™åÂÖ¨ÂºèÔºâ: Always link root of smaller tree to larger tree. public class WeightedQuickUnionDS implements DisjointSets { private int[] parent; private int[] size; // size of each tree public WeightedQuickUnionDS(int N) { parent = new int[N]; size = new int[N]; // Â¢ûÂä†‰∫Üsize arrayËÆ∞ÂΩï for (int i = 0; i \u003c N; i++) { parent[i] = i; size[i] = 1; // each tree is of size 1 } } // find and isConnected are the same as before! private int find(int p) { while (p != parent[p]) p = parent[p]; // p[i] and i ÂæàÈáçË¶ÅÔºÅ return p; } public boolean isConnected(int p, int q) { return find(p) == find(q); } public void connect(int p, int q) { int i = find(p); int j = find(q); if (size[i] \u003c size[j]) { parent[i] = j; size[j] += size[i]; // add size of i to j } else { parent[j] = i; size[i] += size[j]; // add size of j to i } } } ","date":"2024-07-13","objectID":"/61b-20/:3:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"path compressionÔºàUCB-CS170üòãÔºâ Ë∑ØÂæÑÂéãÁº©ÔºöÂ∞ÜÊ†ëÁöÑÊ†πËäÇÁÇπÊåáÂêëÊ†ëÁöÑÊ†πËäÇÁÇπÔºåÂáèÂ∞ëÊ†ëÁöÑÈ´òÂ∫¶„ÄÇ Ë∑ØÂæÑÂéãÁº©ÁöÑÂ•ΩÂ§ÑÔºö ÂáèÂ∞ëÊ†ëÁöÑÈ´òÂ∫¶Ôºå‰ΩøÂæófindÂíåisConnectedÁöÑÊïàÁéáÊõ¥È´ò„ÄÇ ÂáèÂ∞ëÂÜÖÂ≠òÊ∂àËÄó„ÄÇ log*(n) is the iterated log - it‚Äôs the number of times you need to apply log to n to go below 1. Note that 2^65536 is higher than the number of atoms in the universe. ","date":"2024-07-13","objectID":"/61b-20/:4:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"‰∏çÂä†ËØÅÊòéÁªôÂá∫ÁõÆÂâçÊúÄÊûÅÈôêÁöÑÊÉÖÂÜµ $\\alpha(N)$ public class WeightedQuickUnionDSWithPathCompression implements DisjointSets { private int[] parent; private int[] size; public WeightedQuickUnionDSWithPathCompression(int N) { parent = new int[N]; size = new int[N]; for (int i = 0; i \u003c N; i++) { parent[i] = i; size[i] = 1; } } // find Âπ∂‰∏ç‰ºöÂ§™Èöæ ‰πê private int find(int p) { if (p == parent[p]) { return p; } else { parent[p] = find(parent[p]); return parent[p]; } } public boolean isConnected(int p, int q) { return find(p) == find(q); } public void connect(int p, int q) { int i = find(p); int j = find(q); if (i == j) return; if (size[i] \u003c size[j]) { parent[i] = j; size[j] += size[i]; } else { parent[j] = i; size[i] += size[j]; } } } ","date":"2024-07-13","objectID":"/61b-20/:4:1","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"references Nazca Lines: http://redicecreations.com/ul_img/24592nazca_bird.jpg Implementation code adapted from Algorithms, 4th edition and Professor Jonathan Shewchuk‚Äôs lecture notes on disjoint sets, where he presents a faster one-array solution. I would recommend taking a look. (http://www.cs.berkeley.edu/~jrs/61b/lec/33) The proof of the inverse ackermann runtime for disjoint sets is given here: http://www.uni-trier.de/fileadmin/fb4/prof/INF/DEA/Uebungen_LVA-Ankuendigungen/ws07/KAuD/effi.pdf as originally proved by Tarjan here at UC Berkeley in 1975. ","date":"2024-07-13","objectID":"/61b-20/:5:0","tags":null,"title":"61B-20: Disjoint Sets","uri":"/61b-20/"},{"categories":["UCB-CS61B"],"content":"Ê≤°ÊúâÊç∑ÂæÑÔºåÂÖ®Èù†‰ªîÁªÜ for loops ","date":"2024-07-13","objectID":"/61b-18/:1:0","tags":null,"title":"61B-18: Asymptotics II","uri":"/61b-18/"},{"categories":["UCB-CS61B"],"content":"recursion ÂΩ¢Â¶Ç$\\Theta(n^k)$, $k$ ÊòØÈÄíÂΩíÁöÑÊ∑±Â∫¶ ","date":"2024-07-13","objectID":"/61b-18/:2:0","tags":null,"title":"61B-18: Asymptotics II","uri":"/61b-18/"},{"categories":["UCB-CS61B"],"content":"binary search ÂΩ¢Â¶Ç$\\Theta(\\log n)$ C(N) = ‚åälog2(N)‚åã+1 ","date":"2024-07-13","objectID":"/61b-18/:3:0","tags":null,"title":"61B-18: Asymptotics II","uri":"/61b-18/"},{"categories":["UCB-CS61B"],"content":"merge sort ÂΩ¢Â¶Ç$\\Theta(n\\log n)$ ","date":"2024-07-13","objectID":"/61b-18/:4:0","tags":null,"title":"61B-18: Asymptotics II","uri":"/61b-18/"},{"categories":["UCB-CS61B"],"content":"Runtime Characterizations In most cases, we care only about asymptotic behavior, i.e. what happens for very large N. ","date":"2024-07-13","objectID":"/61b-17/:1:0","tags":null,"title":"61B-17: Asymptotics I","uri":"/61b-17/"},{"categories":["UCB-CS61B"],"content":"Intuitive Simplification Consider only the worst case. Restrict Attention to One Operation. ÊâæÂæóÂ•ΩÂπ∂‰∏îÂ∑ßÁöÑËØùÂèØÂæàÂø´ÁúãÂá∫ÔºåÈÄÄËÄåÊ±ÇÂÖ∂Ê¨°ÁöÑËØùÂèØ‰ª•ËÄÉËôëÁîªÂõæÂàÜÊûê Eliminate low order terms. Eliminate multiplicative constants. ","date":"2024-07-13","objectID":"/61b-17/:2:0","tags":null,"title":"61B-17: Asymptotics I","uri":"/61b-17/"},{"categories":["UCB-CS61B"],"content":"Big-Theta Notation $\\Theta(f(n))$ The only difference is that we use the Œò symbol anywhere we would have said ‚Äúorder of growth‚Äù. ","date":"2024-07-13","objectID":"/61b-17/:3:0","tags":null,"title":"61B-17: Asymptotics I","uri":"/61b-17/"},{"categories":["DATA100"],"content":" # Initialize Otter import otter grader = otter.Notebook(\"lab01.ipynb\") Lab 01 Welcome to the first lab of Data 100! This lab is meant to help you familiarize yourself with JupyterHub, review Python and numpy, and introduce you to matplotlib, a Python visualization library. To receive credit for a lab, answer all questions correctly and submit before the deadline. This lab is due Tuesday, January 25 at 11:59 PM. ","date":"2024-07-13","objectID":"/datalab01/:0:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Lab Walk-Through In addition to the lab notebook, we have also released a prerecorded walk-through video of the lab. We encourage you to reference this video as you work through the lab. Run the cell below to display the video. # from IPython.display import YouTubeVideo # YouTubeVideo(\"PS7lPZUnNBo\", list = 'PLQCcNQgUcDfrhStFqvgpvLNhOS43bnSQq', listType = 'playlist') ","date":"2024-07-13","objectID":"/datalab01/:0:1","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Collaboration Policy Data science is a collaborative activity. While you may talk with others about the labs, we ask that you write your solutions individually. If you do discuss the assignments with others please include their names below. (That‚Äôs a good way to learn your classmates‚Äô names.) Collaborators: list collaborators here ","date":"2024-07-13","objectID":"/datalab01/:0:2","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Part 1: Jupyter Tips ","date":"2024-07-13","objectID":"/datalab01/:1:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Viewing Documentation To output the documentation for a function, use the help function. # help(print) ?print \u001b[1;31mSignature:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m \u001b[1;31mDocstring:\u001b[0m Prints the values to a stream, or to sys.stdout by default. sep string inserted between values, default a space. end string appended after the last value, default a newline. file a file-like object (stream); defaults to the current sys.stdout. flush whether to forcibly flush the stream. \u001b[1;31mType:\u001b[0m builtin_function_or_method You can also use Jupyter to view function documentation inside your notebook. The function must already be defined in the kernel for this to work. Below, click your mouse anywhere on the print block below and use Shift + Tab to view the function‚Äôs documentation. print('Welcome to Data 100.') Welcome to Data 100. ","date":"2024-07-13","objectID":"/datalab01/:1:1","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Importing Libraries and Magic Commands In Data 100, we will be using common Python libraries to help us process data. By convention, we import all libraries at the very top of the notebook. There are also a set of standard aliases that are used to shorten the library names. Below are some of the libraries that you may encounter throughout the course, along with their respective aliases. import pandas as pd import numpy as np import matplotlib.pyplot as plt plt.style.use('fivethirtyeight') %matplotlib inline %matplotlib inline is a Jupyter magic command that configures the notebook so that Matplotlib displays any plots that you draw directly in the notebook rather than to a file, allowing you to view the plots upon executing your code. (Note: In practice, this is no longer necessary, but we‚Äôre showing it to you now anyway.) Another useful magic command is %%time, which times the execution of that cell. You can use this by writing it as the first line of a cell. (Note that %% is used for cell magic commands that apply to the entire cell, whereas % is used for line magic commands that only apply to a single line.) %%time lst = [] for i in range(100): lst.append(i) CPU times: total: 0 ns Wall time: 0 ns ","date":"2024-07-13","objectID":"/datalab01/:1:2","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Keyboard Shortcuts Even if you are familiar with Jupyter, we strongly encourage you to become proficient with keyboard shortcuts (this will save you time in the future). To learn about keyboard shortcuts, go to Help ‚Äì\u003e Keyboard Shortcuts in the menu above. Here are a few that we like: Ctrl + Return (or Cmd + Return on Mac): Evaluate the current cell Shift + Return: Evaluate the current cell and move to the next ESC : command mode (may need to press before using any of the commands below) a : create a cell above b : create a cell below dd : delete a cell z : undo the last cell operation m : convert a cell to markdown y : convert a cell to code ","date":"2024-07-13","objectID":"/datalab01/:1:3","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Part 2: Prerequisites It‚Äôs time to answer some review questions. Each question has a response cell directly below it. Most response cells are followed by a test cell that runs automated tests to check your work. Please don‚Äôt delete questions, response cells, or test cells. You won‚Äôt get credit for your work if you do. If you have extra content in a response cell, such as an example call to a function you‚Äôre implementing, that‚Äôs fine. Also, feel free to add cells between the question cells and test cells (or the next cell, for questions without test cases). Any extra cells you add will be considered part of your submission. Finally, when you finish an assignment, make sure to ‚Äúrestart and run all cells‚Äù to ensure everything works properly. Note that for labs, ontime submissions that pass all the test cases will receive full credit. However for homeworks, test cells don‚Äôt always confirm that your response is correct. They are meant to give you some useful feedback, but it‚Äôs your responsibility to ensure your response answers the question correctly. There may be other tests that we run when scoring your notebooks. We strongly recommend that you check your solutions yourself rather than just relying on the test cells. ","date":"2024-07-13","objectID":"/datalab01/:2:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Python Python is the main programming language we‚Äôll use in the course. We expect that you‚Äôve taken CS 61A, Data 8, or an equivalent class, so we will not be covering general Python syntax. If any of the following exercises are challenging (or if you would like to refresh your Python knowledge), please review one or more of the following materials. Python Tutorial: Introduction to Python from the creators of Python. Composing Programs Chapter 1: This is more of a introduction to programming with Python. Advanced Crash Course: A fast crash course which assumes some programming background. ","date":"2024-07-13","objectID":"/datalab01/:2:1","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"NumPy NumPy is the numerical computing module introduced in Data 8, which is a prerequisite for this course. Here‚Äôs a quick recap of NumPy. For more review, read the following materials. NumPy Quick Start Tutorial DS100 NumPy Review Stanford CS231n NumPy Tutorial The Data 8 Textbook Chapter on NumPy ","date":"2024-07-13","objectID":"/datalab01/:2:2","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 1 The core of NumPy is the array. Like Python lists, arrays store data; however, they store data in a more efficient manner. In many cases, this allows for faster computation and data manipulation. In Data 8, we used make_array from the datascience module, but that‚Äôs not the most typical way. Instead, use np.array to create an array. It takes a sequence, such as a list or range. Below, create an array arr containing the values 1, 2, 3, 4, and 5 (in that order). arr = np.array([1,2,3,4,5]) grader.check(\"q1\") q1 passed! üåü In addition to values in the array, we can access attributes such as shape and data type. A full list of attributes can be found here. arr[3] np.int64(4) arr[2:4] # Â∑¶Èó≠Âè≥ÂºÄ array([3, 4]) arr.shape # ‰∏ÄÁª¥ÈïøÂ∫¶‰∏∫5 (5,) arr.dtype dtype('int64') Arrays, unlike Python lists, cannot store items of different data types. # A regular Python list can store items of different data types [1, '3'] [1, '3'] # Arrays will convert everything to the same data type np.array([1, '3']) array(['1', '3'], dtype='\u003cU21') # Another example of array type conversion np.array([5, 8.3]) array([5. , 8.3]) Arrays are also useful in performing vectorized operations. Given two or more arrays of equal length, arithmetic will perform element-wise computations across the arrays. For example, observe the following: # Python list addition will concatenate the two lists [1, 2, 3] + [4, 5, 6] [1, 2, 3, 4, 5, 6] # NumPy array addition will add them element-wise np.array([1, 2, 3]) + np.array([4, 5, 6]) array([5, 7, 9]) ","date":"2024-07-13","objectID":"/datalab01/:2:3","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 2 Question 2a Write a function summation that evaluates the following summation for $n \\geq 1$: $$\\sum_{i=1}^{n} i^3 + 3 i^2$$ Note: You should not use for loops in your solution. Check the NumPy documentation. If you‚Äôre stuck, try a search engine! Searching the web for examples of how to use modules is very common in data science. # Áî®Â•ΩnpÂêëÈáèÂåñ def summation(n): \"\"\"Compute the summation i^3 + 3 * i^2 for 1 \u003c= i \u003c= n.\"\"\" arr = np.arange(1, n+1) newArr = arr**3 + 3 * arr**2 return int(np.sum(newArr)) grader.check(\"q2a\") q2a passed! üíØ Question 2b Write a function elementwise_array_sum that computes the square of each value in list_1, the cube of each value in list_2, then returns a list containing the element-wise sum of these results. Assume that list_1 and list_2 have the same number of elements, do not use for loops. The input parameters will both be python lists, so you may need to convert the lists into arrays before performing your operations. The output should be a numpy array. def elementwise_array_sum(list_1, list_2): \"\"\"Compute x^2 + y^3 for each x, y in list_1, list_2. Assume list_1 and list_2 have the same length. Return a NumPy array. \"\"\" assert len(list_1) == len(list_2), \"both args must have the same number of elements\" # create a NumPy array from the two lists arr1 = np.array(list_1) arr2 = np.array(list_2) arr_sum = arr1 ** 2 + arr2 ** 3 return arr_sum grader.check(\"q2b\") q2b passed! üåü You might have been told that Python is slow, but array arithmetic is carried out very fast, even for large arrays. Below is an implementation of the above code that does not use NumPy arrays. def elementwise_list_sum(list_1, list_2): \"\"\"Compute x^2 + y^3 for each x, y in list_1, list_2. Assume list_1 and list_2 have the same length. \"\"\" return [x ** 2 + y ** 3 for x, y in zip(list_1, list_2)] For ten numbers, elementwise_list_sum and elementwise_array_sum both take a similar amount of time. sample_list_1 = list(range(10)) sample_array_1 = np.arange(10) %%time elementwise_list_sum(sample_list_1, sample_list_1) CPU times: total: 0 ns Wall time: 0 ns [0, 2, 12, 36, 80, 150, 252, 392, 576, 810] %%time elementwise_array_sum(sample_array_1, sample_array_1) CPU times: total: 0 ns Wall time: 0 ns array([ 0, 2, 12, 36, 80, 150, 252, 392, 576, 810]) The time difference seems negligible for a list/array of size 10; depending on your setup, you may even observe that elementwise_list_sum executes faster than elementwise_array_sum! However, we will commonly be working with much larger datasets: sample_list_2 = list(range(100000)) sample_array_2 = np.arange(100000) %%time elementwise_list_sum(sample_list_2, sample_list_2) ; # The semicolon hides the output CPU times: total: 15.6 ms Wall time: 33.2 ms %%time elementwise_array_sum(sample_array_2, sample_array_2) CPU times: total: 0 ns Wall time: 557 Œºs array([ 0, 2, 12, ..., 999920002099982, 999950000799996, 999980000100000]) With the larger dataset, we see that using NumPy results in code that executes over 50 times faster! Throughout this course (and in the real world), you will find that writing efficient code will be important; arrays and vectorized operations are the most common way of making Python programs run quickly. Question 2c Recall the formula for population variance below: $$\\sigma^2 = \\frac{\\sum_{i=1}^N (x_i - \\mu)^2}{N}$$ Complete the functions below to compute the population variance of population, an array of numbers. For this question, do not use built in NumPy functions, such as np.var. Again, avoid using for loops! def mean(population): \"\"\" Returns the mean of population (mu) Keyword arguments: population -- a numpy array of numbers \"\"\" # Calculate the mean of a population return sum(population)/float(len(population)) def variance(population): \"\"\" Returns the variance of population (sigma squared) Keyword arguments: population -- a numpy array of numbers \"\"\" # Calculate the variance of a population mu = mean(population) return sum((population-mu) ** 2)/float(len(populati","date":"2024-07-13","objectID":"/datalab01/:2:4","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Part 3: Plotting Here we explore plotting using matplotlib and numpy. ","date":"2024-07-13","objectID":"/datalab01/:3:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 3 Consider the function $f(x) = x^2$ for $-\\infty \u003c x \u003c \\infty$. Question 3a Find the equation of the tangent line to $f$ at $x = 0$. Use LaTeX to type your solution, such that it looks like the serif font used to display the math expressions in the sentences above. HINT: You can click any text cell to see the raw Markdown syntax. $tangent line: ÂàáÁ∫ø$ $y = 0$ Question 3b Find the equation of the tangent line to $f$ at $x = 8$. Please use LaTeX to type your solution. $y = 16x$ Question 3c Write code to plot the function $f$, the tangent line at $x=8$, and the tangent line at $x=0$. Set the range of the x-axis to (-15, 15) and the range of the y-axis to (-100, 300) and the figure size to (4,4). Your resulting plot should look like this (it‚Äôs okay if the colors in your plot don‚Äôt match with ours, as long as they‚Äôre all different colors): You should use the plt.plot function to plot lines. You may find the following functions useful: plt.plot(..) plt.figure(figsize=..) plt.ylim(..) plt.axhline(..) def f(x): return x ** 2 def df(x): return 2*x def plot(f, df): plt.figure(figsize=(4, 4)) x = np.array([-15, 15]) plt.plot(x,f(x),color='blue') plt.plot(x,df(x),color='green') plt.axhline(0,color='red') plt.ylim(-100, 300) plot(f, df) ","date":"2024-07-13","objectID":"/datalab01/:3:1","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 4 (Ungraded) Data science is a rapidly expanding field and no degree program can hope to teach you everything that will be helpful to you as a data scientist. So it‚Äôs important that you become familiar with looking up documentation and learning how to read it. Below is a section of code that plots a three-dimensional ‚Äúwireframe‚Äù plot. You‚Äôll see what that means when you draw it. Replace each # Your answer here with a description of what the line above does, what the arguments being passed in are, and how the arguments are used in the function. For example, np.arange(2, 5, 0.2) # This returns an array of numbers from 2 to 5 with an interval size of 0.2 Hint: The Shift + Tab tip from earlier in the notebook may help here. Remember that objects must be defined in order for the documentation shortcut to work; for example, all of the documentation will show for method calls from np since we‚Äôve already executed import numpy as np. However, since z is not yet defined in the kernel, z.reshape(x.shape) will not show documentation until you run the line z = np.cos(squared). from mpl_toolkits.mplot3d import axes3d u = np.linspace(1.5 * np.pi, -1.5 * np.pi, 100) # Your answer here [x, y] = np.meshgrid(u, u) # Your answer here squared = np.sqrt(x.flatten() ** 2 + y.flatten() ** 2) z = np.cos(squared) # Your answer here z = z.reshape(x.shape) # Your answer here fig = plt.figure(figsize = (6, 6)) ax = fig.add_subplot(111, projection = '3d') # Your answer here ax.plot_wireframe(x, y, z, rstride = 5, cstride = 5, lw = 2) # Your answer here ax.view_init(elev = 60, azim = 25) # Your answer here plt.savefig(\"figure1.png\") # Your answer here ","date":"2024-07-13","objectID":"/datalab01/:3:2","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Question 5 (Ungraded) Do you think that eating french fries with mayonnaise is a crime? Tell us what you think in the following Markdown cell. :) 6 Ê≥®ÊÑènumpyÁâàÊú¨Âπ∂‰∏çÊòØ‰∏Ä‰∏ÄÂØπÂ∫îÔºåËøîÂõûÁßçÁ±ªÂèëÁîüÂèòÂåñ To double-check your work, the cell below will rerun all of the autograder tests. grader.check_all() q1 results: All test cases passed! q2a results: All test cases passed! q2b results: All test cases passed! q2c results: q2c - 1 result: ‚ùå Test case failed Trying: population_0 = np.random.randn(100) Expecting nothing ok Trying: np.isclose(mean(population_0), np.mean(population_0), atol=1e-6) Expecting: True ********************************************************************** Line 2, in q2c 0 Failed example: np.isclose(mean(population_0), np.mean(population_0), atol=1e-6) Expected: True Got: np.True_ q2c - 2 result: ‚ùå Test case failed Trying: population_0 = np.random.randn(100) Expecting nothing ok Trying: np.isclose(variance(population_0), np.var(population_0), atol=1e-6) Expecting: True ********************************************************************** Line 2, in q2c 1 Failed example: np.isclose(variance(population_0), np.var(population_0), atol=1e-6) Expected: True Got: np.True_ q2d results: All test cases passed! ","date":"2024-07-13","objectID":"/datalab01/:3:3","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"Submission Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. Please save before exporting! # Save your notebook first, then run this cell to export your submission. grader.export(pdf=False) ","date":"2024-07-13","objectID":"/datalab01/:4:0","tags":["Data 100","JupyterHub","Python","numpy","matplotlib"],"title":"DATA100-lab01","uri":"/datalab01/"},{"categories":["DATA100"],"content":"two common errors chance error: randomness can vary bias error: systematic error in one direction ","date":"2024-07-13","objectID":"/datal2/:1:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["DATA100"],"content":"bias ","date":"2024-07-13","objectID":"/datal2/:2:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["DATA100"],"content":"common non-random samples convenience samples: samples that are easy to obtain but may not be representative of the population quota samples: samples that are drawn from a limited number of individuals or groups ","date":"2024-07-13","objectID":"/datal2/:3:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["DATA100"],"content":"random samples random can produce biases but we can estimate the bias and chance error properties of random samples: ÊòéÁ°ÆÊ¶ÇÁéá no need to be same chance üòã scheme of random sampling: ‚ÄúRandom sample with replacement‚Äù ÊòØÁªüËÆ°Â≠¶‰∏≠ÁöÑ‰∏Ä‰∏™ÊúØËØ≠ÔºåÊåáÁöÑÊòØÂú®ËøõË°åÊäΩÊ†∑Êó∂ÔºåÊØèÊ¨°ÊäΩÂèñÁöÑÊ†∑Êú¨Âú®ÊîæÂõûÂéüÊÄª‰Ωì‰πãÂêéÔºåÂÜçËøõË°å‰∏ã‰∏ÄÊ¨°ÊäΩÂèñ„ÄÇËøôÊÑèÂë≥ÁùÄÂêå‰∏Ä‰∏™‰∏™‰ΩìÊàñÂÖÉÁ¥†ÊúâÂèØËÉΩË¢´Â§öÊ¨°ÊäΩÂèñ„ÄÇ ËøôÁßçÊäΩÊ†∑ÊñπÊ≥ïÁöÑÁâπÁÇπÂåÖÊã¨Ôºö ÊØèÊ¨°ÊäΩÂèñÈÉΩÊòØÁã¨Á´ãÁöÑÔºåÂç≥Ââç‰∏ÄÊ¨°ÁöÑÊäΩÂèñÁªìÊûú‰∏ç‰ºöÂΩ±ÂìçÂêé‰∏ÄÊ¨°ÁöÑÊäΩÂèñ„ÄÇ ÊÄª‰Ωì‰∏≠ÁöÑÊØè‰∏™ÂÖÉÁ¥†Âú®ÊØèÊ¨°ÊäΩÂèñ‰∏≠Ë¢´ÈÄâ‰∏≠ÁöÑÊ¶ÇÁéáÊòØÁõ∏ÂêåÁöÑ„ÄÇ Áî±‰∫éÊ†∑Êú¨Ë¢´ÊîæÂõûÔºåÊ†∑Êú¨ÁöÑÂ§ßÂ∞èÂèØ‰ª•Á≠â‰∫éÊàñÂ∞è‰∫éÊÄª‰ΩìÁöÑÂ§ßÂ∞è„ÄÇ ‰∏é‰πãÁõ∏ÂØπÁöÑÊòØ ‚ÄúRandom sample without replacement‚ÄùÔºåÂç≥‰∏çÊîæÂõûÊäΩÊ†∑ÔºåËøôÁßçÊÉÖÂÜµ‰∏ãÔºå‰∏ÄÊó¶‰∏Ä‰∏™ÂÖÉÁ¥†Ë¢´ÊäΩÂèñÔºåÂÆÉÂ∞±‰∏ç‰ºöÂÜçÊ¨°Ë¢´ÊäΩÂèñÔºåÂõ†Ê≠§ÊäΩÂèñÁöÑÊ†∑Êú¨ÈáèÊÄªÊòØÂ∞è‰∫éÊÄª‰ΩìÁöÑÂ§ßÂ∞è„ÄÇüòâ SRSÔºöü§îÊ≥®ÊÑèÊòØÊØè‰∏™\"pair\"ÔºÅ ","date":"2024-07-13","objectID":"/datal2/:4:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["DATA100"],"content":"Â§öÈ°πÂºèÂíå‰∫åÈ°πÂºèÂàÜÂ∏ÉÈááÊ†∑ ","date":"2024-07-13","objectID":"/datal2/:5:0","tags":null,"title":"DATA100-L2: Data Sampling and Probability","uri":"/datal2/"},{"categories":["NNDL"],"content":"neuronal networks and deep learning‚Ä¶ coming soon ","date":"2024-07-12","objectID":"/nndl/:0:0","tags":null,"title":"NNDL0","uri":"/nndl/"},{"categories":["CSIEC"],"content":"COLLEGE STUDENTS INNOVATION AND ENTREPRENEURSHIP COMPETITION (CSIEC) ","date":"2024-07-12","objectID":"/experiences/csiec/csiec0/:0:0","tags":null,"title":"CSIEC0","uri":"/experiences/csiec/csiec0/"},{"categories":["DATA100"],"content":"cycle of data science ","date":"2024-07-12","objectID":"/datal1/:1:0","tags":null,"title":"DATA100-L1: course overview","uri":"/datal1/"},{"categories":["UCB-CS61B"],"content":"math problems $$ N! ‚àà \\Omega (N^{N}) ? $$ ‚àö $$ log(N!) ‚àà \\Omega (NlogN) ? $$ ‚àö $$ NlogN‚àà \\Omega (log(N!)) ? $$ ‚àö ÊâÄ‰ª•ÂèØ‰ª•Êé®Âá∫Ôºö $$ NlogN ‚àà \\Theta (logN!) $$ $$ log(N!) ‚àà \\Theta (NlogN) $$ ","date":"2024-07-11","objectID":"/61b-35/:1:0","tags":null,"title":"61B-35","uri":"/61b-35/"},{"categories":["UCB-CS61B"],"content":"TUCSÁî®Êó∂ ‰∏ä‰∏ãÁïåÔºü the ultimate comparison sort run time $$ \\Omega(NlogN) $$ $$ O(NlogN) $$ ‰∏ãÈù¢ÂºÄÂßãËØÅÊòéÔºö ËÄÉËôë‰∏ãÁïåÔºåÂØπn‰∏™Áâ©‰ΩìËøõË°åÊéíÂ∫èÔºåÊúâNÔºÅÁßçÂèØËÉΩÔºåÁî®‰∏§‰∏§ÊØîÂ§ßÂ∞èÔºåËÄÉËôëÂÜ≥Á≠ñÊ†ëÁöÑÈ´òÂ∫¶$$ H = \\log_2 N! $$ Âõ†Ê≠§‰∏ãÁïå‰∏∫ $$ \\Omega (log(N!)) $$ ÊàñËÄÖ $$ \\Omega (NlogN) $$ ‰∏äÁïåÈÄöËøáTUCSÁöÑÊÄßË¥®ÂèØ‰ª•ÈÄöËøáÂÖ∑‰ΩìÁ§∫‰æãÂèçËØÅÂæóÂà∞ÔºåÊØîÂ¶ÇÁî®merge sort ","date":"2024-07-11","objectID":"/61b-35/:2:0","tags":null,"title":"61B-35","uri":"/61b-35/"},{"categories":["UCB-CS61B"],"content":"More quick sort, Stability, Shuffling ","date":"2024-07-11","objectID":"/61b-34/:0:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"quick sort VS merge sort QuicksortL3S = left + 3-scan + shuffle Quicksort_LTHS: Tony Hoare partition scheme: L ptr ‰ªÖ‰ªÖÊåáÂêëÂ∞èÁöÑ G ptr ‰ªÖ‰ªÖÊåáÂêëÂ§ßÁöÑ ptr walk towards to each other, stopping on a hated item ‰∏§‰∏™ÈÉΩÂÅú‰∏ãÊù•ÁöÑËØùÔºå ‰∫§Êç¢‰∏Ä‰∏ãÔºå ÁÑ∂ÂêéÁßªÂä®ÂÖ∂‰∏≠‰∏Ä‰∏™ when ptrs cross, done. ÂíåG‰∫§Êç¢pivot ","date":"2024-07-11","objectID":"/61b-34/:1:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"Not random smarter pivot selection: median Quicksort_PickTH ËÄÉËôë‰∫ÜÂ¶Ç‰ΩïËÆ°ÁÆóÊï∞ÁªÑÂú∞ÂùÄÁöÑÂ§çÊùÇÂ∫¶Ôºå ‰ª•ÂèäÂ¶Ç‰ΩïÈÄâÊã©pivotÁöÑÂ§çÊùÇÂ∫¶„ÄÇ worst case: $$ \\Theta(NlogN) $$ ‰ΩÜÂÆûÈôÖ‰∏äÂπ∂Ê≤°ÊúâÈÇ£‰πàÂ•ΩÔºåÂõ†‰∏∫ËÆ°ÁÆó‰∏≠‰ΩçÊï∞ÁöÑÂ§çÊùÇÂ∫¶ÊòØ$$\\Theta(N)$$„ÄÇËÄóË¥π‰∫ÜÊõ¥Â§öÊó∂Èó¥„ÄÇ ","date":"2024-07-11","objectID":"/61b-34/:2:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"quick select‚Äìusing partitioning worst case: a sorted array $$ \\Theta(N^2) $$ on average: $$ N + N/2 + N/4 +‚Ä¶ + 1 = \\Theta(N) $$ ","date":"2024-07-11","objectID":"/61b-34/:3:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"stability for stable sort, we need to keep the relative order of equal elements Is insertion sort stable? yes, it is stable. Is quick sort stable? depends on the partitioning scheme. ","date":"2024-07-11","objectID":"/61b-34/:4:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"adaptive array.sort() is adaptive Êü•ÁúãjavaÂÆòÊñπÊñáÊ°£ ","date":"2024-07-11","objectID":"/61b-34/:5:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"shuffling random number and then sort ","date":"2024-07-11","objectID":"/61b-34/:6:0","tags":null,"title":"61B-34","uri":"/61b-34/"},{"categories":["UCB-CS61B"],"content":"‰ø°ÊÅØÊó†ÊçüÊÄß Ê®°Á≥äÊÄß ","date":"2024-07-11","objectID":"/61b-38/:0:0","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"prefix-free codes ","date":"2024-07-11","objectID":"/61b-38/:1:0","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"Huffman codes ","date":"2024-07-11","objectID":"/61b-38/:1:1","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"shannon-fano codes using tries to convert compressed data into a original data longest prefix matching ","date":"2024-07-11","objectID":"/61b-38/:1:2","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"self-extracting bits ","date":"2024-07-11","objectID":"/61b-38/:2:0","tags":null,"title":"61B-38: Compression","uri":"/61b-38/"},{"categories":["UCB-CS61B"],"content":"Overview ","date":"2024-07-11","objectID":"/61b-37/:1:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"Tries‚Äî‚ÄîÂâçÁºÄÊ†ë/Â≠óÂÖ∏Ê†ë usages: prefix matching approximate matching keysWithPrefix(String prefix) // returns all keys in the trie that start with the given prefix longestPrefixOf(String query) // returns the longest key in the trie that is a prefix of the query ","date":"2024-07-11","objectID":"/61b-37/:2:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"implementation private class Node{ boolean exists; Map\u003cCharacter, Node\u003e links; public Node(){ links = new TreeMap\u003c\u003e(); exists = false; } } ","date":"2024-07-11","objectID":"/61b-37/:3:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"T9 keyboard ","date":"2024-07-11","objectID":"/61b-37/:4:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"Ternary search Tries public class TSTSet\u003cValue\u003e{ private Node\u003cValue\u003e root; private static class Node\u003cValue\u003e{ private char c; private Node\u003cValue\u003e lo, mid, hi; } } ‰ΩÜÊòØËøôÁßçÂÆûÁé∞ÊñπÂºèË°®Áé∞‰∏ç‰Ω≥ ","date":"2024-07-11","objectID":"/61b-37/:5:0","tags":null,"title":"61B-37:overview, Tries","uri":"/61b-37/"},{"categories":["UCB-CS61B"],"content":"radix sort ‰∏çÁî®comparisonsÁöÑÊéíÂ∫èÁÆóÊ≥ïÔºåÊó∂Èó¥Â§çÊùÇÂ∫¶O(dn)Ôºåd‰∏∫ÊúÄÂ§ßÊï∞ÁöÑ‰ΩçÊï∞Ôºån‰∏∫ÂæÖÊéíÂ∫èÊï∞ÁöÑ‰∏™Êï∞„ÄÇ Á©∫Èó¥Êç¢Êó∂Èó¥ bucket sort counting sort: ÊâæÂá∫ÂæÖÊéíÂ∫èÊï∞ÁöÑÊúÄÂ§ßÂÄºmaxÔºåÁ°ÆÂÆöËÆ°Êï∞Êï∞ÁªÑÁöÑÈïøÂ∫¶‰∏∫max+1„ÄÇ ÈÅçÂéÜÂæÖÊéíÂ∫èÊï∞ÔºåÂ∞ÜÊØè‰∏™Êï∞ÁöÑ‰∏™‰ΩçÊï∞ÂÄº‰Ωú‰∏∫Á¥¢ÂºïÔºåÂ∞ÜËØ•Á¥¢ÂºïÂØπÂ∫îÁöÑËÆ°Êï∞Êï∞ÁªÑÂÖÉÁ¥†Âä†1„ÄÇ ÈÅçÂéÜËÆ°Êï∞Êï∞ÁªÑÔºåÂ∞ÜÊØè‰∏™ÂÖÉÁ¥†ÁöÑÂÄº‰Ωú‰∏∫Á¥¢ÂºïÔºåÂ∞ÜËØ•Á¥¢ÂºïÂØπÂ∫îÁöÑÂÖÉÁ¥†ÂÄºËæìÂá∫Âà∞ÁªìÊûúÊï∞ÁªÑ‰∏≠„ÄÇ runtime: O(n+k) LSD radix sort: least significant digit radix sort ÊâæÂá∫ÂæÖÊéíÂ∫èÊï∞ÁöÑÊúÄÂ§ßÂÄºmaxÔºåÁ°ÆÂÆöËÆ°Êï∞Êï∞ÁªÑÁöÑÈïøÂ∫¶‰∏∫10„ÄÇ ÈÅçÂéÜÂæÖÊéíÂ∫èÊï∞ÔºåÂ∞ÜÊØè‰∏™Êï∞ÁöÑ‰∏™‰ΩçÊï∞ÂÄº‰Ωú‰∏∫Á¥¢ÂºïÔºåÂ∞ÜËØ•Á¥¢ÂºïÂØπÂ∫îÁöÑËÆ°Êï∞Êï∞ÁªÑÂÖÉÁ¥†Âä†1„ÄÇ LSD sort vs merge sort: similar strings:LSD sort is better dissimilar strings:merge sort is better MSD radix sort: most significant digit radix sort ÊâæÂá∫ÂæÖÊéíÂ∫èÊï∞ÁöÑÊúÄÂ§ßÂÄºmaxÔºåÁ°ÆÂÆöËÆ°Êï∞Êï∞ÁªÑÁöÑÈïøÂ∫¶‰∏∫10„ÄÇ ÈÅçÂéÜÂæÖÊéíÂ∫èÊï∞ÔºåÂ∞ÜÊØè‰∏™Êï∞ÁöÑ‰∏™‰ΩçÊï∞ÂÄº‰Ωú‰∏∫Á¥¢ÂºïÔºåÂ∞ÜËØ•Á¥¢ÂºïÂØπÂ∫îÁöÑËÆ°Êï∞Êï∞ÁªÑÂÖÉÁ¥†Âä†1„ÄÇ ÈÅçÂéÜËÆ°Êï∞Êï∞ÁªÑÔºåÂ∞ÜÊØè‰∏™ÂÖÉÁ¥†ÁöÑÂÄº‰Ωú‰∏∫Á¥¢ÂºïÔºåÂ∞ÜËØ•Á¥¢ÂºïÂØπÂ∫îÁöÑÂÖÉÁ¥†ÂÄºËæìÂá∫Âà∞ÁªìÊûúÊï∞ÁªÑ‰∏≠„ÄÇ runtime: O(n+k) ","date":"2024-07-10","objectID":"/61b-36/:0:0","tags":null,"title":"61B-36","uri":"/61b-36/"},{"categories":["TOOLS"],"content":"Êñá‰ª∂Áä∂ÊÄÅ Êú™Ë∑üË∏™-Êú™‰øÆÊîπ-Â∑≤‰øÆÊîπ-ÊöÇÂ≠ò git add \u003cname\u003e - *-\u003eÊöÇÂ≠ò git commit -m \"message\" - ÊöÇÂ≠ò-\u003eÊú™‰øÆÊîπ git rm \u003cname\u003e - Êú™‰øÆÊîπ-\u003eÊú™Ë∑üË∏™ ","date":"2024-06-29","objectID":"/tools/git/git/:1:0","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"Êü•ÁúãÁä∂ÊÄÅ git status Êõ¥Âä†ÁªÜËá¥Âá†Ë°åÂá†Âàó git diff Êü•ÁúãÂéÜÂè≤Êó•Âøó git log --pretty=oneline git log --graph --oneline --decorate ","date":"2024-06-29","objectID":"/tools/git/git/:1:1","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"Âü∫Êú¨Êìç‰Ωú ","date":"2024-06-29","objectID":"/tools/git/git/:2:0","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"Âü∫Á°ÄÈÖçÁΩÆ git config --global user.name \"your name\" git config --global user.email \"your email\" ","date":"2024-06-29","objectID":"/tools/git/git/:2:1","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"ÂàõÂª∫ÁâàÊú¨Â∫ì mkdir myproject cd myproject git init ","date":"2024-06-29","objectID":"/tools/git/git/:2:2","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"ÂÖãÈöÜÁâàÊú¨Â∫ì git clone https://github.com/username/repository.git ","date":"2024-06-29","objectID":"/tools/git/git/:2:3","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"Ë∑üË∏™Êñá‰ª∂orÊñá‰ª∂Â§π git add \u003cfilename\u003e git rm \u003cfilename\u003e git rm --cache \u003cfilename\u003e ","date":"2024-06-29","objectID":"/tools/git/git/:2:4","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"ËÆæÁΩÆÁºìÂ≠òÁä∂ÊÄÅ git add git reset HEAD \u003cfilename\u003e ","date":"2024-06-29","objectID":"/tools/git/git/:2:5","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"Êèê‰∫§‰øÆÊîπ git commit -m \"commit message str\" Êí§ÈîÄÈùûÈ¶ñÊ¨°‰øÆÊîπ git reset head~ --soft ","date":"2024-06-29","objectID":"/tools/git/git/:2:6","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"ÂíågithubËÅîÁ≥ª git remote add origin https://github.com/username/repository.git git remote git remote rename origin old_name Êé®Âà∞ËøúÁ®ã‰ªìÂ∫ì git push origin master sshËøûÊé•Ôºü ","date":"2024-06-29","objectID":"/tools/git/git/:2:7","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"ÂàÜÊîØÁÆ°ÁêÜ ÂàõÂª∫ÂàÜÊîØ git branch --list git branch hhzz git checkout hhzz git checkout -b hhzz ÂêàÂπ∂ÂàÜÊîØ git merge hhzz Âà†Èô§ÂàÜÊîØ git branch -d hhzz ","date":"2024-06-29","objectID":"/tools/git/git/:2:8","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"Ë¥ÆËóèÂäüËÉΩ stash ÂæÖÊñΩÂ∑• ","date":"2024-06-29","objectID":"/tools/git/git/:2:9","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"ÈáçÁΩÆ„ÄÅÊç¢Âü∫ÂäüËÉΩ ÂæÖÊñΩÂ∑• ","date":"2024-06-29","objectID":"/tools/git/git/:2:10","tags":null,"title":"Git","uri":"/tools/git/git/"},{"categories":["TOOLS"],"content":"Regular Expressions ","date":"2024-06-29","objectID":"/tools/reg/:0:0","tags":null,"title":"Ê≠£ÂàôË°®ËææÂºèÁ¨îËÆ∞","uri":"/tools/reg/"},{"categories":["TOOLS"],"content":"Ê≥®ÊÑèÁâàÊú¨ÂíåÊñáÊ°£ÔºÅ ","date":"2024-06-29","objectID":"/tools/reg/:1:0","tags":null,"title":"Ê≠£ÂàôË°®ËææÂºèÁ¨îËÆ∞","uri":"/tools/reg/"},{"categories":["TOOLS"],"content":"Â∏∏Áî®Â∑•ÂÖ∑ https://regex101.com/ https://regexr.com/ python reÊ®°Âùó Â≠óÁ¨¶ . ÂåπÈÖç‰ªªÊÑè‰∏Ä‰∏™Â≠óÁ¨¶ [] ÂåπÈÖçÊã¨Âè∑‰∏≠ÁöÑ‰ªªÊÑè‰∏Ä‰∏™Â≠óÁ¨¶,Â¶Ç [a-zA-Z1-3] ÂåπÈÖçÂ§ßÂÜôÂ≠óÊØçÊàñÂ∞èÂÜôÂ≠óÊØçÊàñÊï∞Â≠ó1-3, [^] ÂåπÈÖçÈô§‰∫ÜÊã¨Âè∑‰∏≠ÁöÑÂ≠óÁ¨¶ È¢ÑÂÆöÂ≠óÁ¨¶Á±ª \\d ÂåπÈÖçÊï∞Â≠ó \\D ÂåπÈÖçÈùûÊï∞Â≠ó \\w ÂåπÈÖçÂ≠óÊØç„ÄÅÊï∞Â≠óÊàñ‰∏ãÂàíÁ∫ø \\W ÂåπÈÖçÈùûÂ≠óÊØç„ÄÅÊï∞Â≠óÊàñ‰∏ãÂàíÁ∫ø \\s ÂåπÈÖçÁ©∫ÁôΩÂ≠óÁ¨¶ÊàñËÄÖtab \\S ÂåπÈÖçÈùûÁ©∫ÁôΩÂ≠óÁ¨¶ ËæπÁïåÂåπÈÖç ^ ÂåπÈÖçÂ≠óÁ¨¶‰∏≤ÁöÑÂºÄÂ§¥ $ ÂåπÈÖçÂ≠óÁ¨¶‰∏≤ÁöÑÁªìÂ∞æ \\b ÂåπÈÖçÂçïËØçÁöÑËæπÁïå, Â¶Ç \\bthe\\b ÂåπÈÖçthe \\B ÂåπÈÖçÈùûÂçïËØçËæπÁïå Êï∞ÈáèËØç * ÂåπÈÖçÂâçÈù¢ÁöÑÂ≠óÁ¨¶0Ê¨°ÊàñÂ§öÊ¨° + ÂåπÈÖçÂâçÈù¢ÁöÑÂ≠óÁ¨¶1Ê¨°ÊàñÂ§öÊ¨° ? ÂåπÈÖçÂâçÈù¢ÁöÑÂ≠óÁ¨¶0Ê¨°Êàñ1Ê¨° {n} ÂåπÈÖçÂâçÈù¢ÁöÑÂ≠óÁ¨¶nÊ¨° {n,} ÂåπÈÖçÂâçÈù¢ÁöÑÂ≠óÁ¨¶Ëá≥Â∞ënÊ¨° {n,m} ÂåπÈÖçÂâçÈù¢ÁöÑÂ≠óÁ¨¶Ëá≥Â∞ënÊ¨°, Ëá≥Â§ömÊ¨° ÈùûË¥™Â©™ÂåπÈÖç ÈáèËØçÈªòËÆ§ÊòØË¥™Â©™ÂåπÈÖç, Âç≥Â∞ΩÂèØËÉΩÂ§öÁöÑÂåπÈÖçÂ≠óÁ¨¶, Â¶Ç a.*b ‰ºöÂåπÈÖçÂà∞ÊúÄÈïøÁöÑ‰ª•aÂºÄÂ§¥ÁöÑb ÂêéÈù¢ÁöÑÈáèËØçÂä†‰∏ä? Âàô‰∏∫ÈùûË¥™Â©™ÂåπÈÖç, Âç≥Â∞ΩÂèØËÉΩÂ∞ëÁöÑÂåπÈÖçÂ≠óÁ¨¶, Â¶Ç a.*?b ‰ºöÂåπÈÖçÂà∞ÊúÄÁü≠ÁöÑ‰ª•aÂºÄÂ§¥ÁöÑb ÂàÜÁªÑ‰∏éÊçïËé∑ () Áî®Êù•ÂàõÂª∫ÂàÜÁªÑ, ÊçïËé∑Êã¨Âè∑‰∏≠ÁöÑÂ≠óÁ¨¶, Âπ∂Âú®ÂåπÈÖçÊó∂ËøîÂõûÂåπÈÖçÂà∞ÁöÑÂÜÖÂÆπ [] Áî®Êù•ÂàõÂª∫Â≠óÁ¨¶Á±ª, Â¶Ç [Pp] ÂåπÈÖçPÊàñp | Áî®Êù•ÂàõÂª∫ÊàñÂÖ≥Á≥ª, Â¶Ç a(bc|de) ÂåπÈÖçaÂêéÈù¢ÊòØbcÊàñde \\n ÂºïÁî®ÂàÜÁªÑ, Â¶Ç \\1 ÂºïÁî®Á¨¨‰∏Ä‰∏™ÂàÜÁªÑ $n ÂºïÁî®Á¨¨n‰∏™ÂàÜÁªÑ ?: ÈùûÊçïËé∑ÂàÜÁªÑ, Â¶Ç (?:abc) ÂåπÈÖçabc, ‰∏çÊçïËé∑ÂåπÈÖçÂà∞ÁöÑÂÜÖÂÆπ ÂâçÁûªÂíåÂêéÈ°æ Ê≠£ÂêëÂâçÁûª (?=abc) ÂåπÈÖçabcÂâçÈù¢ÁöÑÂ≠óÁ¨¶ ÂèçÂêëÂâçÁûª (?!abc) ÂåπÈÖçabcÂâçÈù¢ÁöÑÂ≠óÁ¨¶ Ê≠£ÂêëÂêéÈ°æ (?\u003c=abc) ÂåπÈÖçabcÂêéÈù¢ÁöÑÂ≠óÁ¨¶ ÂèçÂêëÂêéÈ°æ (?\u003c!abc) ÂåπÈÖçabcÂêéÈù¢ÁöÑÂ≠óÁ¨¶ ","date":"2024-06-29","objectID":"/tools/reg/:2:0","tags":null,"title":"Ê≠£ÂàôË°®ËææÂºèÁ¨îËÆ∞","uri":"/tools/reg/"},{"categories":["PRP"],"content":"PRPÁ≥ªÂàóÂ∞ÜÁî®‰∫éËÆ∞ÂΩïÁ†îÁ©∂È°πÁõÆÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éËØæÈ¢ò„ÄÅÁ†îÁ©∂ÊñπÊ≥ï„ÄÅÁ†îÁ©∂ÊàêÊûú„ÄÅÁ†îÁ©∂ÂøÉÂæó„ÄÅÁ†îÁ©∂ÁªèÈ™å„ÄÅÁ†îÁ©∂ÂøÉË∑ØÂéÜÁ®ãÁ≠â„ÄÇ ","date":"2024-05-21","objectID":"/experiences/prp/prp0/:0:0","tags":null,"title":"PRP0","uri":"/experiences/prp/prp0/"},{"categories":["C++"],"content":"learning pointer(advanced version) ‰∏∫‰∫ÜÈò≤Ê≠¢ÊêûÊ∑∑ËÄåÂÜô ","date":"2024-05-05","objectID":"/crash/cpp1/:0:0","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"‰∏ãÊ†á‰∏∫0?È¶ñÂú∞ÂùÄ? void test0(){ int arr[] = {1, 2, 3}; cout \u003c\u003c \u0026arr[0] \u003c\u003c endl; cout \u003c\u003c \u0026arr \u003c\u003c endl; cout \u003c\u003c arr \u003c\u003c endl; } arr \u0026arr \u0026arr[0] Â≠òÂÇ®ÁöÑÈÉΩÊòØÁõ∏ÂêåÁöÑÂú∞ÂùÄ arr Â∏∏ÈáèÊåáÈíà‰∏çËÉΩË¢´ÊîπÂèò ","date":"2024-05-05","objectID":"/crash/cpp1/:0:1","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"ÊåáÂêëÊï∞ÁªÑÂÖÉÁ¥†ÁöÑÊåáÈíà(‰∏ç‰∏ÄÂÆöÊòØÈ¶ñÂÖÉÁ¥†)‰ª•Áî®[]Êù•ËÆøÈóÆÊï∞ÁªÑÂÖÉÁ¥† void test2() { int a[3] = {1,2,3}; int *p = a; p++; cout \u003c\u003c p[0] \u003c\u003c endl; // 2 } ","date":"2024-05-05","objectID":"/crash/cpp1/:0:2","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"Êï∞ÁªÑÁ±ªÂûãÁöÑÊåáÈíà void test2(){ int arr[] = {1, 2, 3}; int (*p)[] = \u0026arr; // ÂÆö‰πâ‰∏Ä‰∏™ÊåáÂêëÊï∞ÁªÑÁöÑÊåáÈíà cout \u003c\u003c (*p)[0] \u003c\u003c endl; // ËæìÂá∫Êï∞ÁªÑÈ¶ñÂú∞ÂùÄ cout \u003c\u003c p[0] \u003c\u003c endl; // ËæìÂá∫Êï∞ÁªÑÈ¶ñÂú∞ÂùÄ cout \u003c\u003c p[0][0] \u003c\u003c endl; // ËæìÂá∫Êï∞ÁªÑÈ¶ñÂÖÉÁ¥† } int *p[] = \u0026arr vs int (*p)[] = \u0026arr???? [ ]‰ºòÂÖàÁ∫ßÈ´ò‰∫é* int (*p)[] = \u0026arr; *p --\u003e ‰∏Ä‰∏™ÊåáÈíà Ôºà*pÔºâ[] --\u003e ÊåáÂêëÊï∞ÁªÑÁöÑÊåáÈíà int (*p)[] --\u003e ÊåáÂêëÁöÑÊï∞ÁªÑÁöÑÂÖÉÁ¥†ÊòØintÁ±ªÂûã p = \u0026arr ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ÊåáÂêëÊï∞ÁªÑÁöÑÊåáÈíàÔºå(*p) = arr Ëß£ÂºïÁî®ÊåáÈíàÂæóÂà∞Êï∞ÁªÑÈ¶ñÂú∞ÂùÄÔºå(*p)[0] = arr[0] ËÆøÈóÆÊï∞ÁªÑÈ¶ñÂÖÉÁ¥† p[0] = arr ËÆøÈóÆÊï∞ÁªÑÈ¶ñÂú∞ÂùÄÔºåp[0][0] = arr[0] ËÆøÈóÆÊï∞ÁªÑÈ¶ñÂÖÉÁ¥† ","date":"2024-05-05","objectID":"/crash/cpp1/:0:3","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"ÈÇ£‰πàint *(*p)[] = { };Ê∞¥Âà∞Ê∏†Êàê‰∫Ü ","date":"2024-05-05","objectID":"/crash/cpp1/:0:4","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"ÂÜÖÂ≠òÊò†ÂÉèÂõæ ÂÜÖÂ≠òÊò†ÂÉèÂõæ 1 2 ‚Ä¶ ÂÜÖÂ≠òÂú∞ÂùÄ‰ªé‰∏äÂæÄ‰∏ãÈÄíÂ¢û ÂíåCSAPPÈáåÈù¢ÁöÑÊ†àÁîªÊ≥ïÊúâÁÇπ‰∏ç‰∏ÄÊ†∑ ","date":"2024-05-05","objectID":"/crash/cpp1/:0:5","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"delete Áî≥ËØ∑‰∏Ä‰∏™ËøûÁª≠ÁöÑÂÜÖÂ≠òÂùóÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂ËßÜ‰∏∫‰∫åÁª¥Êï∞ÁªÑÔºö int** arr = new int*[rows]; for (int i = 0; i \u003c rows; ++i) { arr[i] = new int[cols]; } ÈáäÊîæÊó∂Ôºå‰Ω†ÈúÄË¶ÅÂÖàÈáäÊîæÊØè‰∏ÄË°åÁöÑÂÜÖÂ≠òÔºåÁÑ∂ÂêéÈáäÊîæË°åÊåáÈíàÊï∞ÁªÑÔºö for (int i = 0; i \u003c rows; ++i) { delete[] arr[i]; } delete[] arr; Áî≥ËØ∑‰∏Ä‰∏™Ë∂≥Â§üÂ§ßÁöÑËøûÁª≠ÂÜÖÂ≠òÂùóÔºåÁÑ∂ÂêéÂ∞ÜÂÖ∂ËßÜ‰∏∫‰∫åÁª¥Êï∞ÁªÑÔºö int* arr = new int[rows * cols]; Âú®ËøôÁßçÊÉÖÂÜµ‰∏ãÔºå‰Ω†Âè™ÈúÄË¶ÅÈáäÊîæ‰∏ÄÊ¨°Ôºö delete[] arr; Ê≥®ÊÑèÔºåËøôÁßçÊñπÂºè‰∏ãÔºåarrÂÆûÈôÖ‰∏äÊòØ‰∏Ä‰∏™‰∏ÄÁª¥Êï∞ÁªÑÔºå‰ΩÜÊòØ‰Ω†ÂèØ‰ª•ÂÉèËÆøÈóÆ‰∫åÁª¥Êï∞ÁªÑ‰∏ÄÊ†∑‰ΩøÁî®ÂÆÉÔºà‰æãÂ¶ÇÔºåarr[i][j]ÂÆûÈôÖ‰∏äÊòØarr[i * cols + j]Ôºâ„ÄÇ Á°Æ‰øùÂú®ÈáäÊîæÂÜÖÂ≠òÂêéÂ∞ÜÊåáÈíàËÆæÁΩÆ‰∏∫nullptrÔºå‰ª•ÈÅøÂÖçÊÇ¨ÂûÇÊåáÈíàÈóÆÈ¢òÔºö delete[] arr; arr = nullptr; // ÊàñËÄÖ‰ΩøÁî®Êô∫ËÉΩÊåáÈíàËá™Âä®ÁÆ°ÁêÜÂÜÖÂ≠ò ","date":"2024-05-05","objectID":"/crash/cpp1/:0:6","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["C++"],"content":"char? int main() { char **p, *city[] = {\"aaa\",\"bbb\"}; for (p = city; p \u003c city + 2; ++p) { cout \u003c\u003c *p \u003c\u003c endl; } return 0; } ÁªìÊûú‰∏∫Ôºö aaa bbb ","date":"2024-05-05","objectID":"/crash/cpp1/:0:7","tags":["C++"],"title":"C++ ptr","uri":"/crash/cpp1/"},{"categories":["csapp"],"content":"ÂÆûÈ™å‰∏ÄÔºöÊ†àÊ∫¢Âá∫ÊîªÂáªÂÆûÈ™å ","date":"2024-04-22","objectID":"/csapp_attacklab/:1:0","tags":null,"title":"CSAPP_attacklab","uri":"/csapp_attacklab/"},{"categories":["csapp"],"content":"Ê†àÁöÑÂü∫Êú¨ÁªìÊûÑ ","date":"2024-04-22","objectID":"/csapp_attacklab/:1:1","tags":null,"title":"CSAPP_attacklab","uri":"/csapp_attacklab/"},{"categories":["csapp"],"content":"ÂÆûÈ™å‰∫åÔºöROPÊîªÂáªÂÆûÈ™å ","date":"2024-04-22","objectID":"/csapp_attacklab/:2:0","tags":null,"title":"CSAPP_attacklab","uri":"/csapp_attacklab/"},{"categories":["csapp"],"content":"csapp_bomblab ÈÉΩÊòØÊ±áÁºñËØ≠Ë®ÄÔºåÊ≤°Êúâ‰ªÄ‰πàÂ•ΩËØ¥ÁöÑ Ê≥®ÊÑèGDBË∞ÉËØï ","date":"2024-04-22","objectID":"/csapp_bomblab/:0:0","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["csapp"],"content":"Ê†∏ÂøÉÊ¶ÇÂøµ‰πã‰∏ÄÔºöÂØªÂùÄ Â¶Ç‰ΩïÂØªÂùÄÔºü $Imm(r_1,r_2,factor)$ Ê≥®ÊÑèÂÄºËøòÊòØÂú∞ÂùÄÔºü (%rdx)ÂèñmemoryÊó∂Ôºå$M[R_i]$ ‰∏≠M‰∏ÄÁõ¥Âú®ÊúÄÂ§ñÂ±Ç ","date":"2024-04-22","objectID":"/csapp_bomblab/:1:0","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["csapp"],"content":"Ê†∏ÂøÉÊ¶ÇÂøµ‰πã‰∫åÔºöGDBË∞ÉËØï ","date":"2024-04-22","objectID":"/csapp_bomblab/:2:0","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["csapp"],"content":"Â∏∏Áî®ÂëΩ‰ª§ run ËøêË°åÁ®ãÂ∫èÔºàÊ≥®ÊÑèÁªìÂêàÊï∞ÊçÆÊµÅpipelineÔºâ b +$Addr$ ËÆæÁΩÆÊñ≠ÁÇπ delete Âà†Èô§Êñ≠ÁÇπ next ÂçïÊ≠•ÊâßË°å step stepi``finishËøõÂÖ•ÂáΩÊï∞ p $eax ÊâìÂç∞ÂèòÈáè x /$nxb $Addr$ ÊâìÂç∞ÂÜÖÂ≠ò layout asm ÂàáÊç¢Âà∞Ê±áÁºñÊ®°ÂºèÊúâÂ•ΩÁúãÁöÑÁ™óÂè£ info registers ÊâìÂç∞ÂØÑÂ≠òÂô® info frame ÊâìÂç∞Ê†àÂ∏ß info args ÊâìÂç∞ÂáΩÊï∞ÂèÇÊï∞ info locals ÊâìÂç∞Â±ÄÈÉ®ÂèòÈáè info breakpoints ÊâìÂç∞Êñ≠ÁÇπ‰ø°ÊÅØ continue ÁªßÁª≠ËøêË°å quit stopÈÄÄÂá∫Ë∞ÉËØï ","date":"2024-04-22","objectID":"/csapp_bomblab/:2:1","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["csapp"],"content":"‰∏Ä‰∫õ‰∫õÊäÄÂ∑ß mov‰∏Ä‰∫õÂ•áÂ•áÊÄ™ÊÄ™ÁöÑÂú∞ÂùÄÊó∂ÔºåÂæàÂèØËÉΩÊòØÁ∫øÁ¥¢ÔºåÂèØ‰ª•Áî®x /$nxb $Addr$Êü•ÁúãÂÜÖÂ≠ò jne‰πãÁ±ªÁöÑËÉΩ‰∏çËÉΩÁõ¥Êé•ÂèñÁ≠âÊì¶ËæπÈÄöËøá Â∏∏ËßÅÁöÑÂü∫Á°ÄËØ≠Âè•ÔºàÊù°‰ª∂/Âæ™ÁéØÔºâÊúâ‰∏Ä‰∫õÂõ∫ÂÆöÁöÑËåÉÂºèÔºåÂèØ‰ª•Áî®x /6i $PCÁ≠âÊü•ÁúãÊåá‰ª§ ","date":"2024-04-22","objectID":"/csapp_bomblab/:3:0","tags":null,"title":"CSAPP_bomblab","uri":"/csapp_bomblab/"},{"categories":["CSAPP"],"content":"int bit-level operations ","date":"2024-04-21","objectID":"/csapp_datalab/:1:0","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"Âæ∑Êë©Ê†πÂæãÔºà‰ΩçËøêÁÆóÂíåÈõÜÂêàËÆ∫Ôºâ ‰∏éÔºö\u0026 ÈùûÔºö~ ‰∏§ËÄÖÁªÑÂêàÂ∑≤ÁªèÂèØ‰ª•Ë°®Á§∫Âõõ‰∏™Âü∫Êú¨ËøêÁÆóÔºö‰∏é„ÄÅÈùû„ÄÅÊàñ„ÄÅÂºÇÊàñ„ÄÇ ","date":"2024-04-21","objectID":"/csapp_datalab/:1:1","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"ÁßªÂä®‰ΩçËøêÁÆó Ê≥®ÊÑèÊòØÂê¶‰∏∫Êó†Á¨¶Âè∑Êï∞ÔºåÊúâÁ¨¶Âè∑Êï∞ÁöÑÁßª‰ΩçËøêÁÆóËßÑÂàô‰∏éÊó†Á¨¶Âè∑Êï∞‰∏çÂêå„ÄÇ ÊúâÁ¨¶Âè∑Êï∞ÁöÑÁßª‰ΩçËøêÁÆóËßÑÂàôÔºö Â∑¶ÁßªÔºöÁ¨¶Âè∑‰Ωç‰∏çÂèòÔºåÂè≥ËæπË°•0„ÄÇ Âè≥ÁßªÔºöÁ¨¶Âè∑‰Ωç‰∏çÂèòÔºåÂ∑¶ËæπË°•Á¨¶Âè∑‰Ωç„ÄÇ Êó†Á¨¶Âè∑Êï∞ÁöÑÁßª‰ΩçËøêÁÆóËßÑÂàôÔºö Â∑¶ÁßªÔºöÂ∑¶ËæπË°•0„ÄÇ Âè≥ÁßªÔºöÂè≥ËæπË°•0„ÄÇ ","date":"2024-04-21","objectID":"/csapp_datalab/:1:2","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"‰∏éËøêÁÆóÔºà\u0026ÔºâÂèñÁâπÂÆöÁöÑ‰ΩçÊï∞ÔºåÁî®‰∫é‰ΩçÂ±ÇÈù¢Êù°‰ª∂Âà§Êñ≠ ","date":"2024-04-21","objectID":"/csapp_datalab/:1:3","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"ÂáèÊ≥ïÁöÑÂÆûÁé∞ A + ~A = -1 ‚Äì\u003e A + (~A+1) = 0 ","date":"2024-04-21","objectID":"/csapp_datalab/:1:4","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"ÂáèÊ≥ïÁöÑÊèèËø∞ËåÉÂõ¥ÈóÆÈ¢ò ÂÅöÂ∑ÆÂèñÁ¨¶Âè∑‰Ωç ","date":"2024-04-21","objectID":"/csapp_datalab/:1:5","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"Êé©Á†ÅÊìç‰Ωú int conditional(int x, int y, int z) { int exp1 = ~(!!x) + 1; int exp2 = ~(!x) + 1; return (exp1\u0026y) + (exp2\u0026z); } ","date":"2024-04-21","objectID":"/csapp_datalab/:1:6","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"‰ΩçÂ±ÇÈù¢ÂàÜÁ±ªËÆ®ËÆ∫ /* howManyBits - return the minimum number of bits required to represent x in * two's complement(Ë°•Á†ÅÁ≥ªÁªü) * Examples: howManyBits(12) = 5 * howManyBits(298) = 10 * howManyBits(-5) = 4 Ë¥üÊï∞ÁöÑËØù ÂèñÂèç ÂêåÁêÜ * howManyBits(0) = 1 * howManyBits(-1) = 1 ÁâπÊÆäÁÇπ? * howManyBits(0x80000000) = 32 * Legal ops: ! ~ \u0026 ^ | + \u003c\u003c \u003e\u003e * Max ops: 90 * Rating: 4 */ int howManyBits(int x) { // Âèñ‰∏∫Ê≠£Êï∞Êìç‰Ωú int flag = x \u003e\u003e 31; x = (~flag \u0026 x) + (flag \u0026 (~x)); // Êé©Á†ÅÂàÜÁ±ªÊÄùÊÉ≥ // 0000 0100 0000 0000 0000 0000 0000 0000 // Flag_i = !!(x \u003e\u003e i) int bit16 = !!(x \u003e\u003e 16) \u003c\u003c 4; // log2 N x \u003e\u003e= bit16; // \u003e\u003e= Âè≥ÁßªËµãÂÄºËøêÁÆóÁ¨¶ int bit8 = !!(x \u003e\u003e 8) \u003c\u003c 3; x \u003e\u003e= bit8; int bit4 = !!(x \u003e\u003e 4) \u003c\u003c 2; x \u003e\u003e= bit4; int bit2 = !!(x \u003e\u003e 2) \u003c\u003c 1; x \u003e\u003e= bit2; int bit1 = !!(x \u003e\u003e 1) \u003c\u003c 0; x \u003e\u003e= bit1; int bit0 = x; // x = 1 return (bit0+bit1+bit2+bit4+bit8+bit16) + 1; } ","date":"2024-04-21","objectID":"/csapp_datalab/:1:7","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"float bit-level operations $$ float = (-1)^s * M * 2^E $$ ","date":"2024-04-21","objectID":"/csapp_datalab/:2:0","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"},{"categories":["CSAPP"],"content":"float to binary sign bit: $s$ exponent bits: $E$ ‚Äî\u003e $E = e - 127$ mantissa bits: $M$‚Äî\u003efrac add $1$ and $0$ to the left until $M$ has 23 bits ","date":"2024-04-21","objectID":"/csapp_datalab/:2:1","tags":null,"title":"CSAPP_datalab","uri":"/csapp_datalab/"}]