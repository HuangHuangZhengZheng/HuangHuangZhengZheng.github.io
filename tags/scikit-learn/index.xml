<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Scikit-Learn - Tag - HHZZ`s space</title>
        <link>http://example.org/tags/scikit-learn/</link>
        <description>Scikit-Learn - Tag - HHZZ`s space</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 13 Aug 2024 15:19:34 &#43;0800</lastBuildDate><atom:link href="http://example.org/tags/scikit-learn/" rel="self" type="application/rss+xml" /><item>
    <title>DATA100-lab7: Gradient Descent and Feature Engineering</title>
    <link>http://example.org/datalab7/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:34 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab7/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab07.ipynb&#34;) Lab 7: Gradient Descent and Feature Engineering In this lab, we will work through the process of:
Defining loss functions Feature engineering Minimizing loss functions using numeric methods and analytical methods Understanding what happens if we use the analytical solution for OLS on a matrix with redundant features Computing a gradient for a nonlinear model Using gradient descent to optimize the nonline model This lab will continue using the toy tips calculation dataset used in Labs 5 and 6.]]></description>
</item>
<item>
    <title>DATA100-lab8: Model Selection, Regularization, and Cross-Validation</title>
    <link>http://example.org/datalab8/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:34 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab8/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab08.ipynb&#34;) Lab 8: Model Selection, Regularization, and Cross-Validation In this lab, you will practice using scikit-learn to generate models of various complexity. You&rsquo;ll then use the holdout method and K-fold cross-validation to select the models that generalize best.
1 2 3 4 5 6 7 8 9 10 11 # Run this cell to set up your notebook import seaborn as sns import csv import numpy as np import pandas as pd import matplotlib.]]></description>
</item>
<item>
    <title>DATA100-lab6: Linear Regression</title>
    <link>http://example.org/datalab6/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:33 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab6/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab06.ipynb&#34;) Lab 6: Linear Regression Objectives In this lab, you will review the details of linear regresison as described in Lectures 10 and 11. In particular:
Matrix formulation and solution to Ordinary Least Squares sns.lmplot as a quick visual for simple linear regression scikit-learn, a real world data science tool that is more robust and flexible than analytical/scipy.optimize solutions You will also practice interpreting residual plots (vs.]]></description>
</item>
</channel>
</rss>
