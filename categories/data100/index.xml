<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>DATA100 - Category - HHZZ`s space</title>
        <link>http://example.org/categories/data100/</link>
        <description>DATA100 - Category - HHZZ`s space</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 13 Aug 2024 15:19:37 &#43;0800</lastBuildDate><atom:link href="http://example.org/categories/data100/" rel="self" type="application/rss+xml" /><item>
    <title>DATA100-lab13</title>
    <link>http://example.org/datalab13/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:37 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab13/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>DATA100-lab14</title>
    <link>http://example.org/datalab14/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:37 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab14/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>DATA100-lab11</title>
    <link>http://example.org/datalab11/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:36 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab11/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>DATA100-lab12</title>
    <link>http://example.org/datalab12/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:36 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab12/</guid>
    <description><![CDATA[]]></description>
</item>
<item>
    <title>DATA100-lab10</title>
    <link>http://example.org/datalab10/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:35 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab10/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab10.ipynb&#34;) Lab 10: SQL In this lab, we are going to practice viewing, sorting, grouping, and merging tables with SQL. We will explore two datasets:
A &ldquo;minified&rdquo; version of the Internet Movie Database (IMDb). This SQLite database (~10MB) is a tiny sample of the much larger database (more than a few GBs). As a result, disclaimer that we may get wildly different results than if we use the whole database!]]></description>
</item>
<item>
    <title>DATA100-lab9: Probability and Modeling</title>
    <link>http://example.org/datalab9/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:35 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab9/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab09.ipynb&#34;) Lab 9: Probability and Modeling In this lab, you will explore estimators and modeling in two parts:
You will explore if the &ldquo;sample max&rdquo; is a biased estimator for the true max of a population.
Given a sample (and no access to the population), you will bootstrap the sample correlation estimator to infer properties of the population correlation of two features.]]></description>
</item>
<item>
    <title>DATA100-lab7: Gradient Descent and Feature Engineering</title>
    <link>http://example.org/datalab7/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:34 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab7/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab07.ipynb&#34;) Lab 7: Gradient Descent and Feature Engineering In this lab, we will work through the process of:
Defining loss functions Feature engineering Minimizing loss functions using numeric methods and analytical methods Understanding what happens if we use the analytical solution for OLS on a matrix with redundant features Computing a gradient for a nonlinear model Using gradient descent to optimize the nonline model This lab will continue using the toy tips calculation dataset used in Labs 5 and 6.]]></description>
</item>
<item>
    <title>DATA100-lab8: Model Selection, Regularization, and Cross-Validation</title>
    <link>http://example.org/datalab8/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:34 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab8/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab08.ipynb&#34;) Lab 8: Model Selection, Regularization, and Cross-Validation In this lab, you will practice using scikit-learn to generate models of various complexity. You&rsquo;ll then use the holdout method and K-fold cross-validation to select the models that generalize best.
1 2 3 4 5 6 7 8 9 10 11 # Run this cell to set up your notebook import seaborn as sns import csv import numpy as np import pandas as pd import matplotlib.]]></description>
</item>
<item>
    <title>DATA100-lab5: Modeling, Loss Functions, and Summary Statistics</title>
    <link>http://example.org/datalab5/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:33 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab5/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab05.ipynb&#34;) Lab 5: Modeling, Loss Functions, and Summary Statistics Predicting Restaurant Tips In this lab, you will try to predict restaurant tips from a set of data in several ways:
A. Without given any additional information, use a constant model with L2 loss to predict the tip $\hat{y}$ as a summary statistic, $\theta$.
B. Given one piece of information—the total bill $x$—use a linear model with L2 loss to predict the tip $\hat{y}$ as a linear function of $x$.]]></description>
</item>
<item>
    <title>DATA100-lab6: Linear Regression</title>
    <link>http://example.org/datalab6/</link>
    <pubDate>Tue, 13 Aug 2024 15:19:33 &#43;0800</pubDate>
    <author>HHZZ</author>
    <guid>http://example.org/datalab6/</guid>
    <description><![CDATA[1 2 3 # Initialize Otter import otter grader = otter.Notebook(&#34;lab06.ipynb&#34;) Lab 6: Linear Regression Objectives In this lab, you will review the details of linear regresison as described in Lectures 10 and 11. In particular:
Matrix formulation and solution to Ordinary Least Squares sns.lmplot as a quick visual for simple linear regression scikit-learn, a real world data science tool that is more robust and flexible than analytical/scipy.optimize solutions You will also practice interpreting residual plots (vs.]]></description>
</item>
</channel>
</rss>
